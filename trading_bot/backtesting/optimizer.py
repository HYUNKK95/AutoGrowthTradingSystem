"""
íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
import logging
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from itertools import product
import json
import os

from .engine import BacktestEngine
from .performance import PerformanceEvaluator

class ParameterOptimizer:
    """íŒŒë¼ë¯¸í„° ìµœì í™” í´ëž˜ìŠ¤"""
    
    def __init__(self, config: Dict[str, Any]):
        """íŒŒë¼ë¯¸í„° ìµœì í™” ì´ˆê¸°í™”"""
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.performance_evaluator = PerformanceEvaluator()
        
        # ìµœì í™” ì„¤ì •
        self.optimization_metric = config.get('optimization_metric', 'sharpe_ratio')
        self.max_combinations = config.get('max_combinations', 1000)
        
        # ìµœì í™” ê²°ê³¼ ì €ìž¥
        self.results = []
        self.best_params = {}
        self.best_score = float('-inf')
        
    def optimize_parameters(self, symbol: str, start_date: str, end_date: str,
                          param_ranges: Dict[str, List]) -> Dict[str, Any]:
        """íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤í–‰"""
        try:
            self.logger.info(f"{symbol} íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œìž‘")
            
            # íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±
            param_combinations = self._generate_param_combinations(param_ranges)
            
            if len(param_combinations) > self.max_combinations:
                self.logger.warning(f"ì¡°í•© ìˆ˜ê°€ ë„ˆë¬´ ë§ŽìŒ: {len(param_combinations)} > {self.max_combinations}")
                param_combinations = param_combinations[:self.max_combinations]
            
            self.logger.info(f"ì´ {len(param_combinations)}ê°œ ì¡°í•© í…ŒìŠ¤íŠ¸")
            
            # ê° ì¡°í•© í…ŒìŠ¤íŠ¸
            for i, params in enumerate(param_combinations):
                self.logger.info(f"í…ŒìŠ¤íŠ¸ ì§„í–‰: {i+1}/{len(param_combinations)}")
                
                # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
                result = self._run_backtest_with_params(symbol, start_date, end_date, params)
                
                if result and 'error' not in result:
                    # ì„±ëŠ¥ ì§€í‘œ ê³„ì‚°
                    performance = self._calculate_performance_score(result)
                    
                    # ê²°ê³¼ ì €ìž¥
                    self.results.append({
                        'params': params,
                        'performance': performance,
                        'backtest_result': result
                    })
                    
                    # ìµœê³  ì„±ëŠ¥ ì—…ë°ì´íŠ¸
                    if performance > self.best_score:
                        self.best_score = performance
                        self.best_params = params
                        self.logger.info(f"ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥: {performance:.4f}")
            
            # ìµœì í™” ê²°ê³¼ ì •ë¦¬
            optimization_result = self._summarize_optimization_results()
            
            # ê²°ê³¼ ì €ìž¥
            self._save_optimization_results(symbol, optimization_result)
            
            self.logger.info(f"{symbol} íŒŒë¼ë¯¸í„° ìµœì í™” ì™„ë£Œ")
            return optimization_result
            
        except Exception as e:
            self.logger.error(f"íŒŒë¼ë¯¸í„° ìµœì í™” ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _generate_param_combinations(self, param_ranges: Dict[str, List]) -> List[Dict]:
        """íŒŒë¼ë¯¸í„° ì¡°í•© ìƒì„±"""
        param_names = list(param_ranges.keys())
        param_values = list(param_ranges.values())
        
        combinations = []
        for combination in product(*param_values):
            param_dict = dict(zip(param_names, combination))
            combinations.append(param_dict)
        
        return combinations
    
    def _run_backtest_with_params(self, symbol: str, start_date: str, end_date: str,
                                 params: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • íŒŒë¼ë¯¸í„°ë¡œ ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰"""
        try:
            # ë°±í…ŒìŠ¤íŒ… ì—”ì§„ ì´ˆê¸°í™” (íŒŒë¼ë¯¸í„° í¬í•¨)
            engine_config = self.config.copy()
            engine_config.update(params)
            
            engine = BacktestEngine(engine_config)
            
            # ë°±í…ŒìŠ¤íŒ… ì‹¤í–‰
            result = engine.run_backtest(symbol, start_date, end_date, 'integrated')
            
            return result
            
        except Exception as e:
            self.logger.error(f"ë°±í…ŒìŠ¤íŒ… ì‹¤íŒ¨ (íŒŒë¼ë¯¸í„°: {params}): {e}")
            return None
    
    def _calculate_performance_score(self, backtest_result: Dict[str, Any]) -> float:
        """ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚°"""
        try:
            if 'performance' not in backtest_result:
                return float('-inf')
            
            perf = backtest_result['performance']
            
            if self.optimization_metric == 'sharpe_ratio':
                return perf.get('risk_metrics', {}).get('sharpe_ratio', 0.0)
            elif self.optimization_metric == 'total_return':
                return backtest_result.get('total_return', 0.0)
            elif self.optimization_metric == 'calmar_ratio':
                return perf.get('risk_metrics', {}).get('calmar_ratio', 0.0)
            elif self.optimization_metric == 'profit_factor':
                return perf.get('trade_metrics', {}).get('profit_factor', 0.0)
            elif self.optimization_metric == 'win_rate':
                return perf.get('trade_metrics', {}).get('win_rate', 0.0)
            else:
                # ë³µí•© ì ìˆ˜ (ìƒ¤í”„ë¹„ìœ¨ + ìˆ˜ìµë¥  - ìµœëŒ€ë“œë¡œë‹¤ìš´)
                sharpe = perf.get('risk_metrics', {}).get('sharpe_ratio', 0.0)
                total_return = backtest_result.get('total_return', 0.0)
                max_dd = abs(perf.get('risk_metrics', {}).get('max_drawdown', 0.0))
                
                return sharpe + total_return - max_dd
                
        except Exception as e:
            self.logger.error(f"ì„±ëŠ¥ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return float('-inf')
    
    def _summarize_optimization_results(self) -> Dict[str, Any]:
        """ìµœì í™” ê²°ê³¼ ìš”ì•½"""
        if not self.results:
            return {'error': 'ìµœì í™” ê²°ê³¼ ì—†ìŒ'}
        
        # ê²°ê³¼ ì •ë ¬ (ì„±ëŠ¥ ê¸°ì¤€)
        sorted_results = sorted(self.results, key=lambda x: x['performance'], reverse=True)
        
        # ìƒìœ„ 10ê°œ ê²°ê³¼
        top_results = sorted_results[:10]
        
        # í†µê³„ ê³„ì‚°
        performances = [r['performance'] for r in self.results]
        
        summary = {
            'best_params': self.best_params,
            'best_score': self.best_score,
            'total_tests': len(self.results),
            'top_results': top_results,
            'performance_stats': {
                'mean': np.mean(performances),
                'std': np.std(performances),
                'min': np.min(performances),
                'max': np.max(performances)
            }
        }
        
        return summary
    
    def _save_optimization_results(self, symbol: str, results: Dict[str, Any]):
        """ìµœì í™” ê²°ê³¼ ì €ìž¥"""
        try:
            # ê²°ê³¼ ë””ë ‰í† ë¦¬ ìƒì„±
            results_dir = 'optimization_results'
            os.makedirs(results_dir, exist_ok=True)
            
            # íŒŒì¼ëª… ìƒì„±
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"{results_dir}/{symbol}_optimization_{timestamp}.json"
            
            # JSONìœ¼ë¡œ ì €ìž¥
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"ìµœì í™” ê²°ê³¼ ì €ìž¥: {filename}")
            
        except Exception as e:
            self.logger.error(f"ìµœì í™” ê²°ê³¼ ì €ìž¥ ì‹¤íŒ¨: {e}")
    
    def generate_optimization_report(self, symbol: str, results: Dict[str, Any]) -> str:
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        try:
            report = []
            report.append("=" * 60)
            report.append(f"ðŸ”§ {symbol} íŒŒë¼ë¯¸í„° ìµœì í™” ë¦¬í¬íŠ¸")
            report.append("=" * 60)
            
            if 'error' in results:
                report.append(f"âŒ ìµœì í™” ì‹¤íŒ¨: {results['error']}")
                return "\n".join(report)
            
            # ìµœì  íŒŒë¼ë¯¸í„°
            best_params = results.get('best_params', {})
            best_score = results.get('best_score', 0)
            
            report.append(f"ðŸ† ìµœì  íŒŒë¼ë¯¸í„°")
            for param, value in best_params.items():
                report.append(f"  - {param}: {value}")
            report.append(f"  - ìµœì  ì„±ëŠ¥ ì ìˆ˜: {best_score:.4f}")
            report.append("")
            
            # í†µê³„ ì •ë³´
            stats = results.get('performance_stats', {})
            report.append(f"ðŸ“Š ì„±ëŠ¥ í†µê³„")
            report.append(f"  - ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {results.get('total_tests', 0)}")
            report.append(f"  - í‰ê·  ì„±ëŠ¥: {stats.get('mean', 0):.4f}")
            report.append(f"  - í‘œì¤€íŽ¸ì°¨: {stats.get('std', 0):.4f}")
            report.append(f"  - ìµœì†Œ ì„±ëŠ¥: {stats.get('min', 0):.4f}")
            report.append(f"  - ìµœëŒ€ ì„±ëŠ¥: {stats.get('max', 0):.4f}")
            report.append("")
            
            # ìƒìœ„ ê²°ê³¼
            top_results = results.get('top_results', [])
            if top_results:
                report.append(f"ðŸ¥‡ ìƒìœ„ 5ê°œ ê²°ê³¼")
                for i, result in enumerate(top_results[:5], 1):
                    params = result['params']
                    performance = result['performance']
                    report.append(f"  {i}. ì„±ëŠ¥: {performance:.4f}")
                    for param, value in params.items():
                        report.append(f"     - {param}: {value}")
                    report.append("")
            
            report.append("=" * 60)
            
            return "\n".join(report)
            
        except Exception as e:
            self.logger.error(f"ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return f"ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}"
    
    def optimize_multiple_symbols(self, symbols: List[str], start_date: str, end_date: str,
                                 param_ranges: Dict[str, List]) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ì‹¬ë³¼ íŒŒë¼ë¯¸í„° ìµœì í™”"""
        try:
            self.logger.info(f"ë‹¤ì¤‘ ì‹¬ë³¼ íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œìž‘: {len(symbols)}ê°œ ì‹¬ë³¼")
            
            all_results = {}
            
            for symbol in symbols:
                self.logger.info(f"ìµœì í™” ì§„í–‰: {symbol}")
                
                # ê°œë³„ ì‹¬ë³¼ ìµœì í™”
                result = self.optimize_parameters(symbol, start_date, end_date, param_ranges)
                all_results[symbol] = result
            
            # ì „ì²´ ìš”ì•½
            summary = self._summarize_multi_symbol_results(all_results)
            
            return {
                'individual_results': all_results,
                'summary': summary
            }
            
        except Exception as e:
            self.logger.error(f"ë‹¤ì¤‘ ì‹¬ë³¼ ìµœì í™” ì‹¤íŒ¨: {e}")
            return {'error': str(e)}
    
    def _summarize_multi_symbol_results(self, all_results: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¤ì¤‘ ì‹¬ë³¼ ê²°ê³¼ ìš”ì•½"""
        successful_results = {k: v for k, v in all_results.items() if 'error' not in v}
        
        if not successful_results:
            return {'error': 'ì„±ê³µí•œ ìµœì í™” ê²°ê³¼ ì—†ìŒ'}
        
        # ì „ì²´ í†µê³„
        all_scores = []
        best_symbol = None
        best_score = float('-inf')
        
        for symbol, result in successful_results.items():
            score = result.get('best_score', 0)
            all_scores.append(score)
            
            if score > best_score:
                best_score = score
                best_symbol = symbol
        
        summary = {
            'total_symbols': len(all_results),
            'successful_symbols': len(successful_results),
            'best_symbol': best_symbol,
            'best_overall_score': best_score,
            'average_score': np.mean(all_scores),
            'score_std': np.std(all_scores)
        }
        
        return summary 