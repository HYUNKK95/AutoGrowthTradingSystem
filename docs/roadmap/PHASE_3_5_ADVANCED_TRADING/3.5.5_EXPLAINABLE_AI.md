# 🔍 Phase 3.5.5: 설명 가능한 AI (XAI) 시스템 (XAI + 위험관리 + 백테스팅 통합)

## 📋 **개요**

### 🎯 **목표**
- **SHAP 분석**: 딥러닝 모델의 특성 중요도 및 기여도 분석
- **LIME 설명**: 개별 예측에 대한 지역적 설명 생성
- **특성 중요도**: 모델이 어떤 지표와 뉴스에 반응하는지 시각화
- **거래 결정 시각화**: 거래 신호의 근거와 신뢰도 표시
- **모델 투명성**: AI 모델의 결정 과정을 인간이 이해할 수 있도록 설명
- **고급 위험 관리**: VaR, CVaR, 스트레스 테스트, 포트폴리오 위험 관리
- **정교한 백테스팅**: 고급 백테스팅 엔진, 워크포워드 테스트, 몬테카를로 시뮬레이션
- **사용자 인터페이스**: 대시보드, 분석 도구, 실시간 모니터링

### 📊 **성능 목표**
- **SHAP 분석 시간**: < 10초 특성 중요도 계산
- **LIME 설명 생성**: < 1초 개별 예측 설명
- **시각화 생성**: < 2초 차트 및 그래프 생성
- **실시간 설명**: < 100ms 거래 신호 설명
- **위험 계산**: < 1초 VaR/CVaR 계산
- **백테스팅**: < 5분 전체 백테스트 완료
- **페이지 로딩**: < 2초 대시보드 로딩
- **정확도**: > 90% 설명 정확도

## 🏗️ **설명 가능한 AI 시스템 아키텍처**

### 📁 **시스템 구조**
```
explainable-ai/
├── shap-analysis/                        # SHAP 분석
│   ├── feature-importance/              # 특성 중요도
│   ├── interaction-effects/             # 상호작용 효과
│   ├── global-explanations/             # 전역적 설명
│   └── local-explanations/              # 지역적 설명
├── lime-explanation/                     # LIME 설명
│   ├── local-interpretation/            # 지역적 해석
│   ├── feature-selection/               # 특성 선택
│   ├── explanation-generator/           # 설명 생성기
│   └── confidence-scorer/               # 신뢰도 스코어링
├── feature-importance/                   # 특성 중요도
│   ├── permutation-importance/          # 순열 중요도
│   ├── tree-importance/                 # 트리 중요도
│   ├── correlation-analysis/            # 상관관계 분석
│   └── temporal-importance/             # 시간적 중요도
├── decision-visualization/               # 결정 시각화
│   ├── decision-trees/                  # 결정 트리
│   ├── feature-attribution/             # 특성 기여도
│   ├── confidence-intervals/            # 신뢰 구간
│   └── uncertainty-quantification/      # 불확실성 정량화
├── model-transparency/                   # 모델 투명성
│   ├── model-interpretability/          # 모델 해석성
│   ├── bias-detection/                  # 편향 감지
│   ├── fairness-assessment/             # 공정성 평가
│   └── robustness-testing/              # 견고성 테스트
├── explanation-dashboard/                # 설명 대시보드
    ├── real-time-monitoring/            # 실시간 모니터링
    ├── historical-analysis/             # 히스토리 분석
    ├── alert-system/                    # 알림 시스템
    └── report-generator/                # 리포트 생성기
├── advanced-risk-management/             # 고급 위험 관리
    ├── var-cvar-calculator/             # VaR/CVaR 계산기
    ├── stress-testing/                  # 스트레스 테스트
    ├── portfolio-risk/                  # 포트폴리오 위험
    ├── drawdown-analysis/               # 드로우다운 분석
    └── risk-dashboard/                  # 위험 대시보드
├── sophisticated-backtesting/            # 정교한 백테스팅
    ├── backtest-engine/                 # 백테스트 엔진
    ├── walk-forward-testing/            # 워크포워드 테스트
    ├── monte-carlo-simulation/          # 몬테카를로 시뮬레이션
    ├── performance-metrics/             # 성과 지표
    └── strategy-validation/             # 전략 검증
└── user-interface/                       # 사용자 인터페이스
    ├── trading-dashboard/               # 거래 대시보드
    ├── analysis-tools/                  # 분석 도구
    ├── real-time-monitoring/            # 실시간 모니터링
    └── reporting-system/                # 리포팅 시스템
```

## 🔧 **SHAP 분석 시스템**

### 📦 **SHAP 분석기**

```python
# explainable-ai/shap-analysis/shap_analyzer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime
import logging
import shap
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

@dataclass
class SHAPExplanation:
    """SHAP 설명"""
    explanation_id: str
    feature_names: List[str]
    feature_values: List[float]
    shap_values: np.ndarray
    base_value: float
    prediction: float
    timestamp: datetime
    model_type: str
    explanation_type: str  # 'local', 'global'

@dataclass
class FeatureImportance:
    """특성 중요도"""
    feature_name: str
    importance_score: float
    rank: int
    contribution_type: str  # 'positive', 'negative', 'neutral'
    confidence_interval: Tuple[float, float]

class SHAPAnalyzer:
    """SHAP 분석기"""
    
    def __init__(self, model=None, background_data=None):
        self.model = model
        self.background_data = background_data
        self.explainer = None
        self.feature_names = []
        self.explanations_history = []
        
        # SHAP 설명기 초기화
        if model is not None:
            self._initialize_explainer()
    
    def _initialize_explainer(self):
        """SHAP 설명기 초기화"""
        try:
            if self.background_data is None:
                # TreeSHAP (트리 기반 모델용)
                if hasattr(self.model, 'feature_importances_'):
                    self.explainer = shap.TreeExplainer(self.model)
                else:
                    # KernelSHAP (일반 모델용)
                    self.explainer = shap.KernelExplainer(self.model.predict, self.background_data)
            else:
                # 배경 데이터가 있는 경우
                if hasattr(self.model, 'feature_importances_'):
                    self.explainer = shap.TreeExplainer(self.model, self.background_data)
                else:
                    self.explainer = shap.KernelExplainer(self.model.predict, self.background_data)
            
            logger.info("SHAP 설명기 초기화 완료")
            
        except Exception as e:
            logger.error(f"SHAP 설명기 초기화 오류: {e}")
    
    def analyze_feature_importance(self, data: Union[np.ndarray, pd.DataFrame]) -> List[FeatureImportance]:
        """특성 중요도 분석"""
        try:
            if self.explainer is None:
                logger.error("SHAP 설명기가 초기화되지 않음")
                return []
            
            # SHAP 값 계산
            if isinstance(data, pd.DataFrame):
                shap_values = self.explainer.shap_values(data)
                feature_names = data.columns.tolist()
            else:
                shap_values = self.explainer.shap_values(data)
                feature_names = [f"feature_{i}" for i in range(data.shape[1])]
            
            # 평균 절댓값으로 중요도 계산
            if len(shap_values.shape) > 1:
                mean_abs_shap = np.mean(np.abs(shap_values), axis=0)
            else:
                mean_abs_shap = np.abs(shap_values)
            
            # 특성 중요도 정렬
            feature_importance_pairs = list(zip(feature_names, mean_abs_shap))
            feature_importance_pairs.sort(key=lambda x: x[1], reverse=True)
            
            # FeatureImportance 객체 생성
            feature_importances = []
            for rank, (feature_name, importance_score) in enumerate(feature_importance_pairs):
                # 기여도 타입 결정
                if len(shap_values.shape) > 1:
                    mean_shap = np.mean(shap_values[:, rank])
                else:
                    mean_shap = shap_values[rank]
                
                if mean_shap > 0:
                    contribution_type = 'positive'
                elif mean_shap < 0:
                    contribution_type = 'negative'
                else:
                    contribution_type = 'neutral'
                
                # 신뢰 구간 계산 (부트스트랩)
                confidence_interval = self._calculate_confidence_interval(shap_values, rank)
                
                feature_importance = FeatureImportance(
                    feature_name=feature_name,
                    importance_score=importance_score,
                    rank=rank + 1,
                    contribution_type=contribution_type,
                    confidence_interval=confidence_interval
                )
                
                feature_importances.append(feature_importance)
            
            return feature_importances
            
        except Exception as e:
            logger.error(f"특성 중요도 분석 오류: {e}")
            return []
    
    def explain_prediction(self, data_point: Union[np.ndarray, pd.DataFrame]) -> SHAPExplanation:
        """개별 예측 설명"""
        try:
            if self.explainer is None:
                logger.error("SHAP 설명기가 초기화되지 않음")
                return None
            
            # SHAP 값 계산
            if isinstance(data_point, pd.DataFrame):
                shap_values = self.explainer.shap_values(data_point)
                feature_names = data_point.columns.tolist()
                feature_values = data_point.iloc[0].values
            else:
                shap_values = self.explainer.shap_values(data_point)
                feature_names = [f"feature_{i}" for i in range(data_point.shape[1])]
                feature_values = data_point.flatten()
            
            # 예측값 계산
            prediction = self.model.predict(data_point)[0] if hasattr(self.model, 'predict') else 0.0
            
            # 기본값 (배경 데이터 평균)
            base_value = self.explainer.expected_value
            
            explanation = SHAPExplanation(
                explanation_id=f"shap_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                feature_names=feature_names,
                feature_values=feature_values.tolist(),
                shap_values=shap_values,
                base_value=base_value,
                prediction=prediction,
                timestamp=datetime.now(),
                model_type=type(self.model).__name__,
                explanation_type='local'
            )
            
            # 히스토리에 추가
            self.explanations_history.append(explanation)
            
            return explanation
            
        except Exception as e:
            logger.error(f"예측 설명 오류: {e}")
            return None
    
    def analyze_interaction_effects(self, data: Union[np.ndarray, pd.DataFrame]) -> Dict[str, float]:
        """상호작용 효과 분석"""
        try:
            if self.explainer is None:
                logger.error("SHAP 설명기가 초기화되지 않음")
                return {}
            
            # SHAP 상호작용 값 계산
            if isinstance(data, pd.DataFrame):
                shap_interaction_values = self.explainer.shap_interaction_values(data)
                feature_names = data.columns.tolist()
            else:
                shap_interaction_values = self.explainer.shap_interaction_values(data)
                feature_names = [f"feature_{i}" for i in range(data.shape[1])]
            
            # 상호작용 효과 계산
            interaction_effects = {}
            
            for i in range(len(feature_names)):
                for j in range(i + 1, len(feature_names)):
                    interaction_key = f"{feature_names[i]}_x_{feature_names[j]}"
                    
                    # 상호작용 강도 계산
                    interaction_strength = np.mean(np.abs(shap_interaction_values[:, i, j]))
                    interaction_effects[interaction_key] = interaction_strength
            
            # 상호작용 효과 정렬
            sorted_interactions = sorted(interaction_effects.items(), 
                                       key=lambda x: x[1], reverse=True)
            
            return dict(sorted_interactions)
            
        except Exception as e:
            logger.error(f"상호작용 효과 분석 오류: {e}")
            return {}
    
    def _calculate_confidence_interval(self, shap_values: np.ndarray, 
                                     feature_idx: int, confidence: float = 0.95) -> Tuple[float, float]:
        """신뢰 구간 계산"""
        try:
            if len(shap_values.shape) > 1:
                feature_shap_values = shap_values[:, feature_idx]
            else:
                feature_shap_values = shap_values
            
            # 부트스트랩으로 신뢰 구간 계산
            n_bootstrap = 1000
            bootstrap_means = []
            
            for _ in range(n_bootstrap):
                bootstrap_sample = np.random.choice(feature_shap_values, 
                                                   size=len(feature_shap_values), 
                                                   replace=True)
                bootstrap_means.append(np.mean(bootstrap_sample))
            
            # 신뢰 구간 계산
            alpha = 1 - confidence
            lower_percentile = (alpha / 2) * 100
            upper_percentile = (1 - alpha / 2) * 100
            
            lower_bound = np.percentile(bootstrap_means, lower_percentile)
            upper_bound = np.percentile(bootstrap_means, upper_percentile)
            
            return (lower_bound, upper_bound)
            
        except Exception as e:
            logger.error(f"신뢰 구간 계산 오류: {e}")
            return (0.0, 0.0)
    
    def generate_visualization(self, explanation: SHAPExplanation, 
                             plot_type: str = 'waterfall') -> str:
        """시각화 생성"""
        try:
            if plot_type == 'waterfall':
                return self._generate_waterfall_plot(explanation)
            elif plot_type == 'bar':
                return self._generate_bar_plot(explanation)
            elif plot_type == 'force':
                return self._generate_force_plot(explanation)
            else:
                logger.error(f"지원하지 않는 플롯 타입: {plot_type}")
                return ""
                
        except Exception as e:
            logger.error(f"시각화 생성 오류: {e}")
            return ""
    
    def _generate_waterfall_plot(self, explanation: SHAPExplanation) -> str:
        """워터폴 플롯 생성"""
        try:
            plt.figure(figsize=(10, 6))
            
            # SHAP 값과 특성명 준비
            shap_values = explanation.shap_values.flatten()
            feature_names = explanation.feature_names
            
            # 워터폴 플롯 생성
            shap.waterfall_plot(
                shap.Explanation(
                    values=shap_values,
                    base_values=explanation.base_value,
                    feature_names=feature_names
                ),
                show=False
            )
            
            plt.title(f"SHAP Waterfall Plot - Prediction: {explanation.prediction:.4f}")
            plt.tight_layout()
            
            # 파일로 저장
            file_path = f"shap_waterfall_{explanation.explanation_id}.png"
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return file_path
            
        except Exception as e:
            logger.error(f"워터폴 플롯 생성 오류: {e}")
            return ""
    
    def _generate_bar_plot(self, explanation: SHAPExplanation) -> str:
        """바 플롯 생성"""
        try:
            plt.figure(figsize=(10, 6))
            
            # 특성 중요도 계산
            feature_importances = self.analyze_feature_importance(
                np.array([explanation.feature_values])
            )
            
            # 상위 10개 특성만 선택
            top_features = feature_importances[:10]
            
            feature_names = [f.feature_name for f in top_features]
            importance_scores = [f.importance_score for f in top_features]
            colors = ['red' if f.contribution_type == 'negative' else 'blue' 
                     for f in top_features]
            
            # 바 플롯 생성
            plt.barh(range(len(feature_names)), importance_scores, color=colors)
            plt.yticks(range(len(feature_names)), feature_names)
            plt.xlabel('SHAP Importance')
            plt.title('Feature Importance (SHAP)')
            plt.gca().invert_yaxis()
            
            plt.tight_layout()
            
            # 파일로 저장
            file_path = f"shap_bar_{explanation.explanation_id}.png"
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return file_path
            
        except Exception as e:
            logger.error(f"바 플롯 생성 오류: {e}")
            return ""
    
    def _generate_force_plot(self, explanation: SHAPExplanation) -> str:
        """포스 플롯 생성"""
        try:
            plt.figure(figsize=(12, 4))
            
            # 포스 플롯 생성
            shap.force_plot(
                explanation.base_value,
                explanation.shap_values,
                explanation.feature_values,
                feature_names=explanation.feature_names,
                show=False
            )
            
            plt.title(f"SHAP Force Plot - Prediction: {explanation.prediction:.4f}")
            plt.tight_layout()
            
            # 파일로 저장
            file_path = f"shap_force_{explanation.explanation_id}.png"
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return file_path
            
        except Exception as e:
            logger.error(f"포스 플롯 생성 오류: {e}")
            return ""
```

## 🔧 **LIME 설명 시스템**

### 📦 **LIME 설명기**

```python
# explainable-ai/lime-explanation/lime_explainer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime
import logging
from lime import lime_tabular
from lime.lime_tabular import LimeTabularExplainer
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

@dataclass
class LIMEExplanation:
    """LIME 설명"""
    explanation_id: str
    feature_names: List[str]
    feature_weights: List[float]
    feature_values: List[float]
    prediction: float
    confidence: float
    timestamp: datetime
    explanation_type: str = 'local'

@dataclass
class FeatureContribution:
    """특성 기여도"""
    feature_name: str
    weight: float
    value: float
    contribution: float
    rank: int

class LIMEExplainer:
    """LIME 설명기"""
    
    def __init__(self, training_data: Union[np.ndarray, pd.DataFrame], 
                 feature_names: List[str] = None, 
                 class_names: List[str] = None):
        self.training_data = training_data
        self.feature_names = feature_names
        self.class_names = class_names
        self.explainer = None
        self.explanations_history = []
        
        # LIME 설명기 초기화
        self._initialize_explainer()
    
    def _initialize_explainer(self):
        """LIME 설명기 초기화"""
        try:
            if isinstance(self.training_data, pd.DataFrame):
                data_array = self.training_data.values
                if self.feature_names is None:
                    self.feature_names = self.training_data.columns.tolist()
            else:
                data_array = self.training_data
                if self.feature_names is None:
                    self.feature_names = [f"feature_{i}" for i in range(data_array.shape[1])]
            
            # LIME 설명기 생성
            self.explainer = LimeTabularExplainer(
                data_array,
                feature_names=self.feature_names,
                class_names=self.class_names,
                mode='regression' if len(self.class_names) == 1 else 'classification'
            )
            
            logger.info("LIME 설명기 초기화 완료")
            
        except Exception as e:
            logger.error(f"LIME 설명기 초기화 오류: {e}")
    
    def explain_prediction(self, data_point: Union[np.ndarray, pd.DataFrame], 
                         model, num_features: int = 10) -> LIMEExplanation:
        """개별 예측 설명"""
        try:
            if self.explainer is None:
                logger.error("LIME 설명기가 초기화되지 않음")
                return None
            
            # 데이터 포인트 준비
            if isinstance(data_point, pd.DataFrame):
                data_array = data_point.values
            else:
                data_array = data_point
            
            # LIME 설명 생성
            explanation = self.explainer.explain_instance(
                data_array.flatten(),
                model.predict,
                num_features=num_features
            )
            
            # 예측값 계산
            prediction = model.predict(data_point)[0] if hasattr(model, 'predict') else 0.0
            
            # 특성 가중치 추출
            feature_weights = []
            feature_values = []
            
            for feature_idx, weight in explanation.as_list():
                feature_weights.append(weight)
                feature_values.append(data_array[0, feature_idx])
            
            # 신뢰도 계산 (간단한 방법)
            confidence = self._calculate_confidence(explanation)
            
            lime_explanation = LIMEExplanation(
                explanation_id=f"lime_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                feature_names=self.feature_names[:num_features],
                feature_weights=feature_weights,
                feature_values=feature_values,
                prediction=prediction,
                confidence=confidence,
                timestamp=datetime.now(),
                explanation_type='local'
            )
            
            # 히스토리에 추가
            self.explanations_history.append(lime_explanation)
            
            return lime_explanation
            
        except Exception as e:
            logger.error(f"LIME 예측 설명 오류: {e}")
            return None
    
    def _calculate_confidence(self, explanation) -> float:
        """신뢰도 계산"""
        try:
            # 간단한 신뢰도 계산 방법
            # 실제로는 더 정교한 방법 사용 가능
            
            # 가중치의 절댓값 합
            total_weight = sum(abs(weight) for _, weight in explanation.as_list())
            
            # 정규화된 신뢰도
            confidence = min(1.0, total_weight / 10.0)
            
            return confidence
            
        except Exception as e:
            logger.error(f"신뢰도 계산 오류: {e}")
            return 0.5
    
    def get_feature_contributions(self, explanation: LIMEExplanation) -> List[FeatureContribution]:
        """특성 기여도 계산"""
        try:
            contributions = []
            
            for i, (feature_name, weight, value) in enumerate(zip(
                explanation.feature_names,
                explanation.feature_weights,
                explanation.feature_values
            )):
                # 기여도 계산 (가중치 * 값)
                contribution = weight * value
                
                feature_contribution = FeatureContribution(
                    feature_name=feature_name,
                    weight=weight,
                    value=value,
                    contribution=contribution,
                    rank=i + 1
                )
                
                contributions.append(feature_contribution)
            
            # 기여도 순으로 정렬
            contributions.sort(key=lambda x: abs(x.contribution), reverse=True)
            
            # 순위 업데이트
            for i, contribution in enumerate(contributions):
                contribution.rank = i + 1
            
            return contributions
            
        except Exception as e:
            logger.error(f"특성 기여도 계산 오류: {e}")
            return []
    
    def generate_visualization(self, explanation: LIMEExplanation) -> str:
        """LIME 시각화 생성"""
        try:
            plt.figure(figsize=(10, 6))
            
            # 특성 기여도 계산
            contributions = self.get_feature_contributions(explanation)
            
            # 상위 10개 특성만 선택
            top_contributions = contributions[:10]
            
            feature_names = [c.feature_name for c in top_contributions]
            weights = [c.weight for c in top_contributions]
            colors = ['red' if w < 0 else 'blue' for w in weights]
            
            # 바 플롯 생성
            bars = plt.barh(range(len(feature_names)), weights, color=colors)
            plt.yticks(range(len(feature_names)), feature_names)
            plt.xlabel('LIME Weight')
            plt.title(f'LIME Feature Weights - Prediction: {explanation.prediction:.4f}')
            plt.gca().invert_yaxis()
            
            # 값 표시
            for i, (bar, contribution) in enumerate(zip(bars, top_contributions)):
                plt.text(bar.get_width() + (0.01 if bar.get_width() > 0 else -0.01),
                        bar.get_y() + bar.get_height()/2,
                        f'{contribution.value:.3f}',
                        va='center', ha='left' if bar.get_width() > 0 else 'right')
            
            plt.tight_layout()
            
            # 파일로 저장
            file_path = f"lime_explanation_{explanation.explanation_id}.png"
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return file_path
            
        except Exception as e:
            logger.error(f"LIME 시각화 생성 오류: {e}")
            return ""
```

## 🔧 **거래 결정 시각화 시스템**

### 📦 **거래 결정 시각화기**

```python
# explainable-ai/decision-visualization/decision_visualizer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime
import logging
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots

logger = logging.getLogger(__name__)

@dataclass
class TradingDecision:
    """거래 결정"""
    decision_id: str
    symbol: str
    action: str  # 'BUY', 'SELL', 'HOLD'
    confidence: float
    price: float
    quantity: float
    timestamp: datetime
    reasoning: Dict[str, Any]
    risk_score: float

@dataclass
class DecisionExplanation:
    """결정 설명"""
    decision_id: str
    technical_factors: Dict[str, float]
    fundamental_factors: Dict[str, float]
    sentiment_factors: Dict[str, float]
    risk_factors: Dict[str, float]
    overall_confidence: float
    recommendation: str

class DecisionVisualizer:
    """거래 결정 시각화기"""
    
    def __init__(self):
        self.decisions_history = []
        self.explanations_history = []
    
    def add_decision(self, decision: TradingDecision, explanation: DecisionExplanation):
        """거래 결정 추가"""
        try:
            self.decisions_history.append(decision)
            self.explanations_history.append(explanation)
            
            logger.info(f"거래 결정 추가: {decision.symbol} - {decision.action}")
            
        except Exception as e:
            logger.error(f"거래 결정 추가 오류: {e}")
    
    def generate_decision_dashboard(self, symbol: str, 
                                  time_range: Tuple[datetime, datetime] = None) -> str:
        """거래 결정 대시보드 생성"""
        try:
            # 해당 심볼의 결정 필터링
            symbol_decisions = [d for d in self.decisions_history if d.symbol == symbol]
            
            if not symbol_decisions:
                logger.warning(f"심볼 {symbol}에 대한 거래 결정이 없음")
                return ""
            
            # 시간 범위 필터링
            if time_range:
                start_time, end_time = time_range
                symbol_decisions = [d for d in symbol_decisions 
                                  if start_time <= d.timestamp <= end_time]
            
            if not symbol_decisions:
                logger.warning(f"지정된 시간 범위에 거래 결정이 없음")
                return ""
            
            # 대시보드 생성
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=('Decision History', 'Confidence Distribution',
                              'Action Distribution', 'Risk Score Trend',
                              'Factor Contributions', 'Performance Metrics'),
                specs=[[{"type": "scatter"}, {"type": "histogram"}],
                       [{"type": "pie"}, {"type": "scatter"}],
                       [{"type": "bar"}, {"type": "scatter"}]]
            )
            
            # 1. 결정 히스토리
            timestamps = [d.timestamp for d in symbol_decisions]
            prices = [d.price for d in symbol_decisions]
            actions = [d.action for d in symbol_decisions]
            
            colors = {'BUY': 'green', 'SELL': 'red', 'HOLD': 'blue'}
            action_colors = [colors[action] for action in actions]
            
            fig.add_trace(
                go.Scatter(x=timestamps, y=prices, mode='markers',
                          marker=dict(color=action_colors, size=8),
                          name='Decisions'),
                row=1, col=1
            )
            
            # 2. 신뢰도 분포
            confidences = [d.confidence for d in symbol_decisions]
            fig.add_trace(
                go.Histogram(x=confidences, nbinsx=20, name='Confidence'),
                row=1, col=2
            )
            
            # 3. 액션 분포
            action_counts = pd.Series(actions).value_counts()
            fig.add_trace(
                go.Pie(labels=action_counts.index, values=action_counts.values,
                      name='Actions'),
                row=2, col=1
            )
            
            # 4. 리스크 스코어 트렌드
            risk_scores = [d.risk_score for d in symbol_decisions]
            fig.add_trace(
                go.Scatter(x=timestamps, y=risk_scores, mode='lines+markers',
                          name='Risk Score'),
                row=2, col=2
            )
            
            # 5. 팩터 기여도
            if self.explanations_history:
                latest_explanation = self.explanations_history[-1]
                
                factor_names = list(latest_explanation.technical_factors.keys())
                factor_values = list(latest_explanation.technical_factors.values())
                
                fig.add_trace(
                    go.Bar(x=factor_names, y=factor_values, name='Technical Factors'),
                    row=3, col=1
                )
            
            # 6. 성과 메트릭
            # 간단한 성과 계산
            buy_decisions = [d for d in symbol_decisions if d.action == 'BUY']
            sell_decisions = [d for d in symbol_decisions if d.action == 'SELL']
            
            if buy_decisions and sell_decisions:
                avg_buy_price = np.mean([d.price for d in buy_decisions])
                avg_sell_price = np.mean([d.price for d in sell_decisions])
                
                fig.add_trace(
                    go.Scatter(x=['Buy', 'Sell'], y=[avg_buy_price, avg_sell_price],
                              mode='markers', marker=dict(size=15),
                              name='Average Prices'),
                    row=3, col=2
                )
            
            # 레이아웃 업데이트
            fig.update_layout(
                title=f'Trading Decision Dashboard - {symbol}',
                height=1200,
                showlegend=True
            )
            
            # 파일로 저장
            file_path = f"decision_dashboard_{symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            fig.write_html(file_path)
            
            return file_path
            
        except Exception as e:
            logger.error(f"거래 결정 대시보드 생성 오류: {e}")
            return ""
    
    def generate_confidence_analysis(self, symbol: str) -> str:
        """신뢰도 분석 생성"""
        try:
            # 해당 심볼의 결정 필터링
            symbol_decisions = [d for d in self.decisions_history if d.symbol == symbol]
            
            if not symbol_decisions:
                return ""
            
            # 신뢰도 분석
            confidences = [d.confidence for d in symbol_decisions]
            actions = [d.action for d in symbol_decisions]
            
            # 액션별 신뢰도 분석
            action_confidence = {}
            for action in set(actions):
                action_confidences = [d.confidence for d in symbol_decisions if d.action == action]
                action_confidence[action] = {
                    'mean': np.mean(action_confidences),
                    'std': np.std(action_confidences),
                    'count': len(action_confidences)
                }
            
            # 시각화
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            
            # 1. 신뢰도 분포
            axes[0, 0].hist(confidences, bins=20, alpha=0.7, color='skyblue')
            axes[0, 0].set_title('Confidence Distribution')
            axes[0, 0].set_xlabel('Confidence')
            axes[0, 0].set_ylabel('Frequency')
            
            # 2. 액션별 신뢰도 박스플롯
            action_data = []
            action_labels = []
            for action in set(actions):
                action_confidences = [d.confidence for d in symbol_decisions if d.action == action]
                action_data.append(action_confidences)
                action_labels.append(action)
            
            axes[0, 1].boxplot(action_data, labels=action_labels)
            axes[0, 1].set_title('Confidence by Action')
            axes[0, 1].set_ylabel('Confidence')
            
            # 3. 시간에 따른 신뢰도 변화
            timestamps = [d.timestamp for d in symbol_decisions]
            axes[1, 0].scatter(timestamps, confidences, alpha=0.6)
            axes[1, 0].set_title('Confidence Over Time')
            axes[1, 0].set_xlabel('Time')
            axes[1, 0].set_ylabel('Confidence')
            axes[1, 0].tick_params(axis='x', rotation=45)
            
            # 4. 신뢰도 vs 리스크 스코어
            risk_scores = [d.risk_score for d in symbol_decisions]
            scatter = axes[1, 1].scatter(confidences, risk_scores, 
                                       c=[hash(a) for a in actions], alpha=0.6)
            axes[1, 1].set_title('Confidence vs Risk Score')
            axes[1, 1].set_xlabel('Confidence')
            axes[1, 1].set_ylabel('Risk Score')
            
            # 범례 추가
            legend_elements = [plt.Line2D([0], [0], marker='o', color='w', 
                                        markerfacecolor=plt.cm.Set1(i/len(set(actions))),
                                        label=action, markersize=8)
                              for i, action in enumerate(set(actions))]
            axes[1, 1].legend(handles=legend_elements)
            
            plt.tight_layout()
            
            # 파일로 저장
            file_path = f"confidence_analysis_{symbol}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.png"
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return file_path
            
        except Exception as e:
            logger.error(f"신뢰도 분석 생성 오류: {e}")
            return ""
    
    def generate_factor_importance_chart(self, explanation: DecisionExplanation) -> str:
        """팩터 중요도 차트 생성"""
        try:
            # 모든 팩터 통합
            all_factors = {}
            all_factors.update(explanation.technical_factors)
            all_factors.update(explanation.fundamental_factors)
            all_factors.update(explanation.sentiment_factors)
            all_factors.update(explanation.risk_factors)
            
            # 중요도 순으로 정렬
            sorted_factors = sorted(all_factors.items(), key=lambda x: abs(x[1]), reverse=True)
            
            # 상위 15개 팩터만 선택
            top_factors = sorted_factors[:15]
            
            factor_names = [f[0] for f in top_factors]
            factor_values = [f[1] for f in top_factors]
            
            # 색상 결정 (양수/음수)
            colors = ['red' if v < 0 else 'blue' for v in factor_values]
            
            # 시각화
            plt.figure(figsize=(12, 8))
            bars = plt.barh(range(len(factor_names)), factor_values, color=colors, alpha=0.7)
            plt.yticks(range(len(factor_names)), factor_names)
            plt.xlabel('Factor Importance')
            plt.title('Factor Importance Analysis')
            plt.gca().invert_yaxis()
            
            # 값 표시
            for i, (bar, value) in enumerate(zip(bars, factor_values)):
                plt.text(bar.get_width() + (0.01 if value > 0 else -0.01),
                        bar.get_y() + bar.get_height()/2,
                        f'{value:.3f}',
                        va='center', ha='left' if value > 0 else 'right')
            
            plt.tight_layout()
            
            # 파일로 저장
            file_path = f"factor_importance_{explanation.decision_id}.png"
            plt.savefig(file_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            return file_path
            
        except Exception as e:
            logger.error(f"팩터 중요도 차트 생성 오류: {e}")
            return ""
```

## 🔧 **고급 위험 관리 시스템**

### 📦 **VaR/CVaR 계산기**

```python
# explainable-ai/advanced-risk-management/var_cvar_calculator.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
from scipy import stats
from scipy.optimize import minimize

logger = logging.getLogger(__name__)

@dataclass
class RiskMetrics:
    """위험 메트릭"""
    var_95: float
    var_99: float
    cvar_95: float
    cvar_99: float
    portfolio_volatility: float
    sharpe_ratio: float
    max_drawdown: float
    timestamp: datetime

@dataclass
class StressTestResult:
    """스트레스 테스트 결과"""
    scenario_name: str
    portfolio_value: float
    var_impact: float
    cvar_impact: float
    volatility_impact: float
    timestamp: datetime

class VaRCVaRCalculator:
    """VaR/CVaR 계산기"""
    
    def __init__(self, confidence_levels: List[float] = None):
        self.confidence_levels = confidence_levels or [0.95, 0.99]
        self.historical_window = 252  # 1년
    
    def calculate_var_cvar(self, returns: pd.Series, 
                          confidence_levels: List[float] = None) -> Dict[str, float]:
        """VaR/CVaR 계산"""
        try:
            if confidence_levels is None:
                confidence_levels = self.confidence_levels
            
            results = {}
            
            for confidence in confidence_levels:
                # VaR 계산 (역분위수)
                var = np.percentile(returns, (1 - confidence) * 100)
                
                # CVaR 계산 (조건부 기대값)
                var_threshold = np.percentile(returns, (1 - confidence) * 100)
                cvar = returns[returns <= var_threshold].mean()
                
                results[f'var_{int(confidence*100)}'] = var
                results[f'cvar_{int(confidence*100)}'] = cvar
            
            return results
            
        except Exception as e:
            logger.error(f"VaR/CVaR 계산 오류: {e}")
            return {}
    
    def calculate_portfolio_risk(self, portfolio_returns: pd.Series, 
                               weights: List[float] = None) -> RiskMetrics:
        """포트폴리오 위험 계산"""
        try:
            if weights is None:
                weights = [1.0 / len(portfolio_returns)] * len(portfolio_returns)
            
            # 기본 통계
            mean_return = portfolio_returns.mean()
            volatility = portfolio_returns.std()
            
            # VaR/CVaR 계산
            risk_measures = self.calculate_var_cvar(portfolio_returns)
            
            # 샤프 비율 계산
            risk_free_rate = 0.02  # 2% 무위험 수익률
            sharpe_ratio = (mean_return - risk_free_rate) / volatility if volatility > 0 else 0
            
            # 최대 드로우다운 계산
            cumulative_returns = (1 + portfolio_returns).cumprod()
            running_max = cumulative_returns.expanding().max()
            drawdown = (cumulative_returns - running_max) / running_max
            max_drawdown = drawdown.min()
            
            return RiskMetrics(
                var_95=risk_measures.get('var_95', 0.0),
                var_99=risk_measures.get('var_99', 0.0),
                cvar_95=risk_measures.get('cvar_95', 0.0),
                cvar_99=risk_measures.get('cvar_99', 0.0),
                portfolio_volatility=volatility,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=max_drawdown,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"포트폴리오 위험 계산 오류: {e}")
            return RiskMetrics(
                var_95=0.0, var_99=0.0, cvar_95=0.0, cvar_99=0.0,
                portfolio_volatility=0.0, sharpe_ratio=0.0, max_drawdown=0.0,
                timestamp=datetime.now()
            )
    
    def stress_test(self, portfolio_returns: pd.Series, 
                   scenarios: Dict[str, Dict[str, float]]) -> List[StressTestResult]:
        """스트레스 테스트"""
        try:
            results = []
            base_risk = self.calculate_portfolio_risk(portfolio_returns)
            
            for scenario_name, scenario_params in scenarios.items():
                # 시나리오 적용
                stressed_returns = self._apply_stress_scenario(portfolio_returns, scenario_params)
                
                # 스트레스된 위험 계산
                stressed_risk = self.calculate_portfolio_risk(stressed_returns)
                
                # 영향도 계산
                var_impact = stressed_risk.var_95 - base_risk.var_95
                cvar_impact = stressed_risk.cvar_95 - base_risk.cvar_95
                volatility_impact = stressed_risk.portfolio_volatility - base_risk.portfolio_volatility
                
                results.append(StressTestResult(
                    scenario_name=scenario_name,
                    portfolio_value=stressed_returns.mean(),
                    var_impact=var_impact,
                    cvar_impact=cvar_impact,
                    volatility_impact=volatility_impact,
                    timestamp=datetime.now()
                ))
            
            return results
            
        except Exception as e:
            logger.error(f"스트레스 테스트 오류: {e}")
            return []
    
    def _apply_stress_scenario(self, returns: pd.Series, 
                             scenario_params: Dict[str, float]) -> pd.Series:
        """스트레스 시나리오 적용"""
        try:
            stressed_returns = returns.copy()
            
            # 변동성 증가
            if 'volatility_multiplier' in scenario_params:
                multiplier = scenario_params['volatility_multiplier']
                stressed_returns = stressed_returns * multiplier
            
            # 수익률 감소
            if 'return_shock' in scenario_params:
                shock = scenario_params['return_shock']
                stressed_returns = stressed_returns + shock
            
            # 상관관계 변화
            if 'correlation_shock' in scenario_params:
                # 상관관계 변화는 더 복잡한 구현 필요
                pass
            
            return stressed_returns
            
        except Exception as e:
            logger.error(f"스트레스 시나리오 적용 오류: {e}")
            return returns
```

### 📦 **정교한 백테스팅 엔진**

```python
# explainable-ai/sophisticated-backtesting/backtest_engine.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
from enum import Enum
import multiprocessing as mp
from concurrent.futures import ProcessPoolExecutor

logger = logging.getLogger(__name__)

class BacktestType(Enum):
    """백테스트 타입"""
    SIMPLE = "simple"
    WALK_FORWARD = "walk_forward"
    MONTE_CARLO = "monte_carlo"
    STRESS_TEST = "stress_test"

@dataclass
class Trade:
    """거래"""
    symbol: str
    entry_time: datetime
    exit_time: Optional[datetime]
    entry_price: float
    exit_price: Optional[float]
    quantity: float
    side: str  # 'BUY', 'SELL'
    pnl: Optional[float] = None
    commission: float = 0.0

@dataclass
class BacktestResult:
    """백테스트 결과"""
    strategy_name: str
    total_return: float
    sharpe_ratio: float
    max_drawdown: float
    win_rate: float
    profit_factor: float
    total_trades: int
    avg_trade_duration: timedelta
    trades: List[Trade]
    equity_curve: pd.Series
    timestamp: datetime

class SophisticatedBacktestEngine:
    """정교한 백테스트 엔진"""
    
    def __init__(self, initial_capital: float = 100000, 
                 commission_rate: float = 0.001):
        self.initial_capital = initial_capital
        self.commission_rate = commission_rate
        self.results_cache = {}
    
    def run_backtest(self, strategy_func: Callable, 
                    data: pd.DataFrame,
                    backtest_type: BacktestType = BacktestType.SIMPLE,
                    **kwargs) -> BacktestResult:
        """백테스트 실행"""
        try:
            if backtest_type == BacktestType.SIMPLE:
                return self._run_simple_backtest(strategy_func, data, **kwargs)
            elif backtest_type == BacktestType.WALK_FORWARD:
                return self._run_walk_forward_backtest(strategy_func, data, **kwargs)
            elif backtest_type == BacktestType.MONTE_CARLO:
                return self._run_monte_carlo_backtest(strategy_func, data, **kwargs)
            else:
                raise ValueError(f"지원하지 않는 백테스트 타입: {backtest_type}")
                
        except Exception as e:
            logger.error(f"백테스트 실행 오류: {e}")
            return None
    
    def _run_simple_backtest(self, strategy_func: Callable, 
                           data: pd.DataFrame, **kwargs) -> BacktestResult:
        """단순 백테스트"""
        try:
            # 초기 설정
            capital = self.initial_capital
            position = 0
            trades = []
            equity_curve = []
            
            # 전략 실행
            for i, (timestamp, row) in enumerate(data.iterrows()):
                # 전략 신호 생성
                signal = strategy_func(row, i, data, **kwargs)
                
                # 거래 실행
                if signal == 'BUY' and position <= 0:
                    # 매수
                    quantity = capital / row['close']
                    trade = Trade(
                        symbol=row.get('symbol', 'UNKNOWN'),
                        entry_time=timestamp,
                        entry_price=row['close'],
                        quantity=quantity,
                        side='BUY'
                    )
                    trades.append(trade)
                    position = quantity
                    capital = 0
                    
                elif signal == 'SELL' and position > 0:
                    # 매도
                    trade = trades[-1]  # 마지막 매수 거래
                    trade.exit_time = timestamp
                    trade.exit_price = row['close']
                    trade.pnl = (trade.exit_price - trade.entry_price) * trade.quantity
                    trade.commission = (trade.entry_price + trade.exit_price) * trade.quantity * self.commission_rate
                    trade.pnl -= trade.commission
                    
                    capital = trade.exit_price * trade.quantity - trade.commission
                    position = 0
                
                # 자본 곡선 업데이트
                current_value = capital + (position * row['close'] if position > 0 else 0)
                equity_curve.append(current_value)
            
            # 결과 계산
            return self._calculate_backtest_results(trades, equity_curve, data.index)
            
        except Exception as e:
            logger.error(f"단순 백테스트 오류: {e}")
            return None
    
    def _run_walk_forward_backtest(self, strategy_func: Callable, 
                                 data: pd.DataFrame, 
                                 window_size: int = 252,
                                 step_size: int = 63) -> BacktestResult:
        """워크포워드 백테스트"""
        try:
            all_trades = []
            all_equity_curves = []
            
            for start_idx in range(0, len(data) - window_size, step_size):
                end_idx = start_idx + window_size
                window_data = data.iloc[start_idx:end_idx]
                
                # 윈도우별 백테스트 실행
                window_result = self._run_simple_backtest(strategy_func, window_data)
                
                if window_result:
                    all_trades.extend(window_result.trades)
                    all_equity_curves.extend(window_result.equity_curve.tolist())
            
            # 전체 결과 계산
            return self._calculate_backtest_results(all_trades, all_equity_curves, data.index)
            
        except Exception as e:
            logger.error(f"워크포워드 백테스트 오류: {e}")
            return None
    
    def _run_monte_carlo_backtest(self, strategy_func: Callable, 
                                data: pd.DataFrame, 
                                n_simulations: int = 1000) -> BacktestResult:
        """몬테카를로 백테스트"""
        try:
            # 병렬 처리를 위한 함수
            def run_single_simulation(sim_id):
                # 데이터 순서를 랜덤하게 섞기
                shuffled_data = data.sample(frac=1.0, random_state=sim_id).reset_index()
                return self._run_simple_backtest(strategy_func, shuffled_data)
            
            # 병렬 실행
            with ProcessPoolExecutor(max_workers=mp.cpu_count()) as executor:
                futures = [executor.submit(run_single_simulation, i) 
                          for i in range(n_simulations)]
                results = [future.result() for future in futures if future.result()]
            
            # 결과 집계
            if results:
                # 평균 결과 계산
                avg_return = np.mean([r.total_return for r in results])
                avg_sharpe = np.mean([r.sharpe_ratio for r in results])
                avg_drawdown = np.mean([r.max_drawdown for r in results])
                
                # 모든 거래 통합
                all_trades = []
                for result in results:
                    all_trades.extend(result.trades)
                
                return BacktestResult(
                    strategy_name=f"Monte_Carlo_{n_simulations}",
                    total_return=avg_return,
                    sharpe_ratio=avg_sharpe,
                    max_drawdown=avg_drawdown,
                    win_rate=np.mean([r.win_rate for r in results]),
                    profit_factor=np.mean([r.profit_factor for r in results]),
                    total_trades=len(all_trades),
                    avg_trade_duration=timedelta(days=1),  # 평균값 계산 필요
                    trades=all_trades,
                    equity_curve=pd.Series([avg_return]),
                    timestamp=datetime.now()
                )
            
            return None
            
        except Exception as e:
            logger.error(f"몬테카를로 백테스트 오류: {e}")
            return None
    
    def _calculate_backtest_results(self, trades: List[Trade], 
                                  equity_curve: List[float], 
                                  timestamps: pd.DatetimeIndex) -> BacktestResult:
        """백테스트 결과 계산"""
        try:
            if not trades:
                return BacktestResult(
                    strategy_name="Empty_Strategy",
                    total_return=0.0,
                    sharpe_ratio=0.0,
                    max_drawdown=0.0,
                    win_rate=0.0,
                    profit_factor=0.0,
                    total_trades=0,
                    avg_trade_duration=timedelta(0),
                    trades=[],
                    equity_curve=pd.Series(),
                    timestamp=datetime.now()
                )
            
            # 기본 통계
            total_trades = len([t for t in trades if t.pnl is not None])
            winning_trades = [t for t in trades if t.pnl and t.pnl > 0]
            losing_trades = [t for t in trades if t.pnl and t.pnl < 0]
            
            # 수익률 계산
            total_pnl = sum(t.pnl for t in trades if t.pnl)
            total_return = total_pnl / self.initial_capital
            
            # 승률
            win_rate = len(winning_trades) / total_trades if total_trades > 0 else 0
            
            # 수익 팩터
            gross_profit = sum(t.pnl for t in winning_trades)
            gross_loss = abs(sum(t.pnl for t in losing_trades))
            profit_factor = gross_profit / gross_loss if gross_loss > 0 else float('inf')
            
            # 샤프 비율
            returns = pd.Series(equity_curve).pct_change().dropna()
            sharpe_ratio = returns.mean() / returns.std() * np.sqrt(252) if returns.std() > 0 else 0
            
            # 최대 드로우다운
            equity_series = pd.Series(equity_curve, index=timestamps[:len(equity_curve)])
            cumulative_returns = (1 + equity_series.pct_change()).cumprod()
            running_max = cumulative_returns.expanding().max()
            drawdown = (cumulative_returns - running_max) / running_max
            max_drawdown = drawdown.min()
            
            # 평균 거래 기간
            durations = [t.exit_time - t.entry_time for t in trades if t.exit_time]
            avg_duration = np.mean(durations) if durations else timedelta(0)
            
            return BacktestResult(
                strategy_name="Backtest_Strategy",
                total_return=total_return,
                sharpe_ratio=sharpe_ratio,
                max_drawdown=max_drawdown,
                win_rate=win_rate,
                profit_factor=profit_factor,
                total_trades=total_trades,
                avg_trade_duration=avg_duration,
                trades=trades,
                equity_curve=equity_series,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"백테스트 결과 계산 오류: {e}")
            return None
```

## 📊 **성과 지표**

### **목표 성과**
- **SHAP 분석 정확도**: > 90%
- **LIME 설명 정확도**: > 85%
- **시각화 생성 속도**: < 2초
- **실시간 설명**: < 100ms
- **위험 계산 정확도**: > 95%
- **백테스팅 정확도**: > 90%
- **사용자 이해도**: > 80%

### **성능 지표**
- **SHAP 분석 시간**: < 10초
- **LIME 설명 생성**: < 1초
- **시각화 생성**: < 2초
- **위험 계산**: < 1초 VaR/CVaR 계산
- **백테스팅**: < 5분 전체 백테스트 완료
- **페이지 로딩**: < 2초 대시보드 로딩
- **메모리 사용량**: < 1GB
- **시스템 가동률**: > 99.5%

## 🔗 **관련 문서**

- [Phase 3.5.1: 기술적 지표 분석](3.5.1_TECHNICAL_ANALYSIS.md)
- [Phase 3.5.2: 거래 전략 라이브러리](3.5.2_TRADING_STRATEGIES.md)
- [Phase 3.5.3: 뉴스 이벤트 분석](3.5.3_NEWS_EVENT_ANALYSIS.md)
- [Phase 3.5.4: 온라인 학습](3.5.4_ONLINE_LEARNING.md)

---

**마지막 업데이트**: 2025-01-26  
**프로젝트 상태**: 설계 완료, 개발 준비  
**다음 단계**: 전체 Phase 3.5 시스템 통합 및 최적화 