# 🧠 Phase 3.5.4: 온라인 학습 시스템 (학습 + 품질관리 + 모니터링 통합)

## 📋 **개요**

### 🎯 **목표**
- **증분 학습**: 새로운 데이터로 모델을 지속적으로 업데이트
- **개념 드리프트 감지**: 시장 패턴 변화를 자동으로 감지
- **적응형 파라미터**: 시장 상황에 따라 모델 파라미터 자동 조정
- **데이터 품질 관리**: 데이터 검증, 정제, 증강 시스템
- **실시간 모니터링**: 시스템 성능 및 전략 성과 실시간 추적
- **실시간 모델 업데이트**: 5분 이내 모델 재훈련 완료
- **메타러닝**: 다양한 시장 상황에서 최적의 학습 방법 선택

### 📊 **성능 목표**
- **모델 업데이트 시간**: < 5분 온라인 학습 완료
- **개념 드리프트 감지**: < 1시간 변화 감지
- **적응 속도**: < 10분 파라미터 조정
- **데이터 품질 정확도**: > 99.9% 데이터 정확도
- **실시간 모니터링**: < 100ms 모니터링 지연
- **메모리 효율성**: < 2GB 모델 메모리
- **학습 정확도**: > 70% 실시간 예측 정확도

## 🏗️ **온라인 학습 시스템 아키텍처**

### 📁 **시스템 구조**
```
online-learning/
├── incremental-learning/                 # 증분 학습
│   ├── streaming-data-processor/        # 스트리밍 데이터 처리
│   ├── model-updater/                   # 모델 업데이터
│   ├── memory-management/               # 메모리 관리
│   └── learning-rate-adapter/           # 학습률 적응기
├── concept-drift-detection/              # 개념 드리프트 감지
│   ├── drift-detector/                  # 드리프트 감지기
│   ├── change-point-detection/          # 변화점 감지
│   ├── distribution-monitor/            # 분포 모니터
│   └── drift-alert-system/              # 드리프트 알림
├── adaptive-parameters/                  # 적응형 파라미터
│   ├── parameter-optimizer/             # 파라미터 최적화
│   ├── market-regime-detector/          # 시장 체제 감지
│   ├── dynamic-adjustment/              # 동적 조정
│   └── performance-tracker/             # 성능 추적
├── meta-learning/                        # 메타러닝
│   ├── algorithm-selector/              # 알고리즘 선택기
│   ├── hyperparameter-optimizer/        # 하이퍼파라미터 최적화
│   ├── ensemble-manager/                # 앙상블 관리
│   └── learning-strategy-adapter/       # 학습 전략 적응
├── model-updating/                       # 모델 업데이트
│   ├── version-control/                 # 버전 관리
│   ├── rollback-manager/                # 롤백 관리
│   ├── a-b-testing/                     # A/B 테스트
│   └── deployment-manager/              # 배포 관리
├── performance-monitoring/               # 성능 모니터링
    ├── real-time-metrics/               # 실시간 메트릭
    ├── model-health-monitor/            # 모델 건강도 모니터
    ├── alert-system/                    # 알림 시스템
    └── performance-dashboard/           # 성능 대시보드
├── data-quality-management/              # 데이터 품질 관리
    ├── data-validation/                 # 데이터 검증
    ├── data-cleansing/                  # 데이터 정제
    ├── data-augmentation/               # 데이터 증강
    ├── outlier-detection/               # 이상치 감지
    └── quality-monitoring/              # 품질 모니터링
└── real-time-monitoring/                 # 실시간 모니터링
    ├── system-performance/              # 시스템 성능
    ├── strategy-performance/            # 전략 성과
    ├── risk-monitoring/                 # 위험 모니터링
    └── alert-management/                # 알림 관리
```

## 🔧 **증분 학습 시스템**

### 📦 **스트리밍 데이터 처리기**

```python
# online-learning/incremental-learning/streaming_data_processor.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
import asyncio
from collections import deque
import threading
import queue

logger = logging.getLogger(__name__)

@dataclass
class DataPoint:
    """데이터 포인트"""
    timestamp: datetime
    features: Dict[str, float]
    target: Optional[float] = None
    metadata: Dict[str, Any] = None

@dataclass
class DataBatch:
    """데이터 배치"""
    batch_id: str
    data_points: List[DataPoint]
    batch_size: int
    timestamp: datetime
    features_mean: Dict[str, float]
    features_std: Dict[str, float]

class StreamingDataProcessor:
    """스트리밍 데이터 처리기"""
    
    def __init__(self, batch_size: int = 100, max_buffer_size: int = 1000):
        self.batch_size = batch_size
        self.max_buffer_size = max_buffer_size
        self.data_buffer = deque(maxlen=max_buffer_size)
        self.batch_queue = queue.Queue()
        self.processing_task = None
        self.is_running = False
        
        # 통계 정보
        self.feature_stats = {}
        self.total_processed = 0
        self.last_update_time = datetime.now()
    
    async def start_processing(self):
        """데이터 처리 시작"""
        self.is_running = True
        self.processing_task = asyncio.create_task(self._processing_loop())
        logger.info("스트리밍 데이터 처리 시작")
    
    async def stop_processing(self):
        """데이터 처리 중지"""
        self.is_running = False
        if self.processing_task:
            self.processing_task.cancel()
        logger.info("스트리밍 데이터 처리 중지")
    
    async def add_data_point(self, data_point: DataPoint):
        """데이터 포인트 추가"""
        try:
            # 버퍼에 추가
            self.data_buffer.append(data_point)
            
            # 통계 업데이트
            self._update_feature_stats(data_point)
            
            # 배치 크기에 도달하면 배치 생성
            if len(self.data_buffer) >= self.batch_size:
                await self._create_batch()
                
        except Exception as e:
            logger.error(f"데이터 포인트 추가 오류: {e}")
    
    async def _processing_loop(self):
        """처리 루프"""
        while self.is_running:
            try:
                # 배치 큐에서 배치 가져오기
                try:
                    batch = self.batch_queue.get_nowait()
                    await self._process_batch(batch)
                except queue.Empty:
                    await asyncio.sleep(0.1)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"처리 루프 오류: {e}")
                await asyncio.sleep(1)
    
    async def _create_batch(self):
        """배치 생성"""
        try:
            if len(self.data_buffer) < self.batch_size:
                return
            
            # 배치 데이터 추출
            batch_data = list(self.data_buffer)[:self.batch_size]
            
            # 배치 통계 계산
            features_mean = self._calculate_batch_mean(batch_data)
            features_std = self._calculate_batch_std(batch_data, features_mean)
            
            # 배치 생성
            batch = DataBatch(
                batch_id=f"batch_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                data_points=batch_data,
                batch_size=len(batch_data),
                timestamp=datetime.now(),
                features_mean=features_mean,
                features_std=features_std
            )
            
            # 큐에 배치 추가
            self.batch_queue.put(batch)
            
            # 버퍼에서 처리된 데이터 제거
            for _ in range(self.batch_size):
                if self.data_buffer:
                    self.data_buffer.popleft()
            
            logger.info(f"배치 생성 완료: {batch.batch_id} - {len(batch_data)}개 데이터")
            
        except Exception as e:
            logger.error(f"배치 생성 오류: {e}")
    
    def _update_feature_stats(self, data_point: DataPoint):
        """특성 통계 업데이트"""
        for feature_name, feature_value in data_point.features.items():
            if feature_name not in self.feature_stats:
                self.feature_stats[feature_name] = {
                    'count': 0,
                    'sum': 0.0,
                    'sum_sq': 0.0,
                    'min': float('inf'),
                    'max': float('-inf')
                }
            
            stats = self.feature_stats[feature_name]
            stats['count'] += 1
            stats['sum'] += feature_value
            stats['sum_sq'] += feature_value ** 2
            stats['min'] = min(stats['min'], feature_value)
            stats['max'] = max(stats['max'], feature_value)
    
    def _calculate_batch_mean(self, batch_data: List[DataPoint]) -> Dict[str, float]:
        """배치 평균 계산"""
        if not batch_data:
            return {}
        
        feature_sums = {}
        feature_counts = {}
        
        for data_point in batch_data:
            for feature_name, feature_value in data_point.features.items():
                if feature_name not in feature_sums:
                    feature_sums[feature_name] = 0.0
                    feature_counts[feature_name] = 0
                
                feature_sums[feature_name] += feature_value
                feature_counts[feature_name] += 1
        
        return {
            feature_name: feature_sums[feature_name] / feature_counts[feature_name]
            for feature_name in feature_sums
        }
    
    def _calculate_batch_std(self, batch_data: List[DataPoint], 
                           batch_mean: Dict[str, float]) -> Dict[str, float]:
        """배치 표준편차 계산"""
        if not batch_data:
            return {}
        
        feature_sums_sq = {}
        feature_counts = {}
        
        for data_point in batch_data:
            for feature_name, feature_value in data_point.features.items():
                if feature_name not in feature_sums_sq:
                    feature_sums_sq[feature_name] = 0.0
                    feature_counts[feature_name] = 0
                
                mean = batch_mean.get(feature_name, 0.0)
                feature_sums_sq[feature_name] += (feature_value - mean) ** 2
                feature_counts[feature_name] += 1
        
        return {
            feature_name: np.sqrt(feature_sums_sq[feature_name] / feature_counts[feature_name])
            for feature_name in feature_sums_sq
        }
    
    async def _process_batch(self, batch: DataBatch):
        """배치 처리"""
        try:
            # 데이터 정규화
            normalized_data = self._normalize_batch(batch)
            
            # 모델 업데이트 요청
            await self._request_model_update(normalized_data)
            
            # 처리된 데이터 수 업데이트
            self.total_processed += batch.batch_size
            self.last_update_time = datetime.now()
            
            logger.info(f"배치 처리 완료: {batch.batch_id}")
            
        except Exception as e:
            logger.error(f"배치 처리 오류: {e}")
    
    def _normalize_batch(self, batch: DataBatch) -> List[DataPoint]:
        """배치 정규화"""
        normalized_data = []
        
        for data_point in batch.data_points:
            normalized_features = {}
            
            for feature_name, feature_value in data_point.features.items():
                mean = batch.features_mean.get(feature_name, 0.0)
                std = batch.features_std.get(feature_name, 1.0)
                
                if std > 0:
                    normalized_value = (feature_value - mean) / std
                else:
                    normalized_value = feature_value - mean
                
                normalized_features[feature_name] = normalized_value
            
            normalized_data_point = DataPoint(
                timestamp=data_point.timestamp,
                features=normalized_features,
                target=data_point.target,
                metadata=data_point.metadata
            )
            
            normalized_data.append(normalized_data_point)
        
        return normalized_data
    
    async def _request_model_update(self, normalized_data: List[DataPoint]):
        """모델 업데이트 요청"""
        # 실제 구현에서는 모델 업데이터에 요청
        # 여기서는 로깅만 수행
        logger.info(f"모델 업데이트 요청: {len(normalized_data)}개 데이터")
```

### 📦 **개념 드리프트 감지기**

```python
# online-learning/concept-drift-detection/concept_drift_detector.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
from scipy import stats
from sklearn.metrics import kl_divergence
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

@dataclass
class DriftAlert:
    """드리프트 알림"""
    alert_id: str
    drift_type: str
    severity: str  # 'low', 'medium', 'high', 'critical'
    confidence: float
    affected_features: List[str]
    timestamp: datetime
    description: str
    recommendations: List[str]

class ConceptDriftDetector:
    """개념 드리프트 감지기"""
    
    def __init__(self, window_size: int = 1000, detection_threshold: float = 0.05):
        self.window_size = window_size
        self.detection_threshold = detection_threshold
        self.reference_window = []
        self.current_window = []
        self.drift_history = []
        self.detection_methods = {
            'statistical_test': self._statistical_test_detection,
            'distribution_comparison': self._distribution_comparison_detection,
            'change_point_detection': self._change_point_detection,
            'kl_divergence': self._kl_divergence_detection
        }
    
    def add_data_point(self, data_point: DataPoint):
        """데이터 포인트 추가"""
        try:
            # 현재 윈도우에 추가
            self.current_window.append(data_point)
            
            # 윈도우 크기 초과 시 오래된 데이터 제거
            if len(self.current_window) > self.window_size:
                self.current_window.pop(0)
            
            # 참조 윈도우가 비어있으면 초기화
            if not self.reference_window and len(self.current_window) >= self.window_size // 2:
                self.reference_window = self.current_window.copy()
            
            # 드리프트 감지 수행
            if len(self.current_window) >= self.window_size // 2:
                drift_detected = self._detect_drift()
                
                if drift_detected:
                    self._handle_drift_detection(drift_detected)
                
        except Exception as e:
            logger.error(f"데이터 포인트 추가 오류: {e}")
    
    def _detect_drift(self) -> Optional[DriftAlert]:
        """드리프트 감지"""
        try:
            if len(self.reference_window) < self.window_size // 2:
                return None
            
            # 각 감지 방법으로 드리프트 확인
            drift_results = {}
            
            for method_name, method_func in self.detection_methods.items():
                try:
                    result = method_func()
                    if result:
                        drift_results[method_name] = result
                except Exception as e:
                    logger.error(f"드리프트 감지 방법 오류 {method_name}: {e}")
            
            # 종합적인 드리프트 판단
            if drift_results:
                return self._combine_drift_results(drift_results)
            
            return None
            
        except Exception as e:
            logger.error(f"드리프트 감지 오류: {e}")
            return None
    
    def _statistical_test_detection(self) -> Optional[Dict]:
        """통계적 검정을 통한 드리프트 감지"""
        try:
            if len(self.reference_window) < 30 or len(self.current_window) < 30:
                return None
            
            # 각 특성에 대해 t-검정 수행
            drift_scores = {}
            
            for feature_name in self.reference_window[0].features.keys():
                ref_values = [dp.features[feature_name] for dp in self.reference_window]
                cur_values = [dp.features[feature_name] for dp in self.current_window]
                
                # t-검정
                t_stat, p_value = stats.ttest_ind(ref_values, cur_values)
                
                # p-value가 임계값보다 작으면 드리프트로 판단
                if p_value < self.detection_threshold:
                    drift_scores[feature_name] = {
                        'p_value': p_value,
                        't_stat': t_stat,
                        'severity': 'high' if p_value < 0.01 else 'medium'
                    }
            
            if drift_scores:
                return {
                    'method': 'statistical_test',
                    'drift_scores': drift_scores,
                    'confidence': 1 - min(score['p_value'] for score in drift_scores.values())
                }
            
            return None
            
        except Exception as e:
            logger.error(f"통계적 검정 드리프트 감지 오류: {e}")
            return None
    
    def _distribution_comparison_detection(self) -> Optional[Dict]:
        """분포 비교를 통한 드리프트 감지"""
        try:
            if len(self.reference_window) < 50 or len(self.current_window) < 50:
                return None
            
            # 각 특성에 대해 분포 비교
            drift_scores = {}
            
            for feature_name in self.reference_window[0].features.keys():
                ref_values = [dp.features[feature_name] for dp in self.reference_window]
                cur_values = [dp.features[feature_name] for dp in self.current_window]
                
                # Kolmogorov-Smirnov 검정
                ks_stat, ks_p_value = stats.ks_2samp(ref_values, cur_values)
                
                # Anderson-Darling 검정
                try:
                    ad_stat, ad_critical_values, ad_significance_levels = stats.anderson_ksamp([ref_values, cur_values])
                    ad_p_value = 1 - ad_significance_levels[0] / 100
                except:
                    ad_p_value = 1.0
                
                # 종합적인 드리프트 점수
                combined_p_value = (ks_p_value + ad_p_value) / 2
                
                if combined_p_value < self.detection_threshold:
                    drift_scores[feature_name] = {
                        'ks_stat': ks_stat,
                        'ks_p_value': ks_p_value,
                        'ad_p_value': ad_p_value,
                        'combined_p_value': combined_p_value,
                        'severity': 'high' if combined_p_value < 0.01 else 'medium'
                    }
            
            if drift_scores:
                return {
                    'method': 'distribution_comparison',
                    'drift_scores': drift_scores,
                    'confidence': 1 - min(score['combined_p_value'] for score in drift_scores.values())
                }
            
            return None
            
        except Exception as e:
            logger.error(f"분포 비교 드리프트 감지 오류: {e}")
            return None
    
    def _change_point_detection(self) -> Optional[Dict]:
        """변화점 감지를 통한 드리프트 감지"""
        try:
            if len(self.current_window) < 100:
                return None
            
            # 시계열 데이터로 변환
            time_series_data = []
            for dp in self.current_window:
                # 특성들의 평균값 사용
                avg_feature = np.mean(list(dp.features.values()))
                time_series_data.append(avg_feature)
            
            # CUSUM (Cumulative Sum) 변화점 감지
            mean_val = np.mean(time_series_data)
            std_val = np.std(time_series_data)
            
            if std_val == 0:
                return None
            
            # CUSUM 계산
            cusum_positive = []
            cusum_negative = []
            
            for i, value in enumerate(time_series_data):
                if i == 0:
                    cusum_positive.append(0)
                    cusum_negative.append(0)
                else:
                    # 양의 CUSUM
                    pos_val = max(0, cusum_positive[i-1] + (value - mean_val) / std_val)
                    cusum_positive.append(pos_val)
                    
                    # 음의 CUSUM
                    neg_val = max(0, cusum_negative[i-1] - (value - mean_val) / std_val)
                    cusum_negative.append(neg_val)
            
            # 임계값 설정 (일반적으로 5 사용)
            threshold = 5
            
            # 변화점 감지
            change_points = []
            for i in range(len(cusum_positive)):
                if cusum_positive[i] > threshold or cusum_negative[i] > threshold:
                    change_points.append(i)
            
            if change_points:
                # 최근 변화점
                latest_change = max(change_points)
                change_ratio = latest_change / len(time_series_data)
                
                return {
                    'method': 'change_point_detection',
                    'change_points': change_points,
                    'latest_change': latest_change,
                    'change_ratio': change_ratio,
                    'confidence': min(1.0, len(change_points) / 10),
                    'severity': 'high' if change_ratio > 0.8 else 'medium'
                }
            
            return None
            
        except Exception as e:
            logger.error(f"변화점 감지 드리프트 감지 오류: {e}")
            return None
    
    def _kl_divergence_detection(self) -> Optional[Dict]:
        """KL 발산을 통한 드리프트 감지"""
        try:
            if len(self.reference_window) < 50 or len(self.current_window) < 50:
                return None
            
            # 각 특성에 대해 KL 발산 계산
            drift_scores = {}
            
            for feature_name in self.reference_window[0].features.keys():
                ref_values = [dp.features[feature_name] for dp in self.reference_window]
                cur_values = [dp.features[feature_name] for dp in self.current_window]
                
                # 히스토그램 생성
                ref_hist, ref_bins = np.histogram(ref_values, bins=20, density=True)
                cur_hist, cur_bins = np.histogram(cur_values, bins=20, density=True)
                
                # KL 발산 계산
                try:
                    kl_div = kl_divergence(ref_hist, cur_hist)
                    
                    # 임계값 설정 (경험적으로 0.1 사용)
                    if kl_div > 0.1:
                        drift_scores[feature_name] = {
                            'kl_divergence': kl_div,
                            'severity': 'high' if kl_div > 0.5 else 'medium'
                        }
                except:
                    continue
            
            if drift_scores:
                return {
                    'method': 'kl_divergence',
                    'drift_scores': drift_scores,
                    'confidence': min(1.0, max(score['kl_divergence'] for score in drift_scores.values())),
                    'severity': 'high' if any(score['severity'] == 'high' for score in drift_scores.values()) else 'medium'
                }
            
            return None
            
        except Exception as e:
            logger.error(f"KL 발산 드리프트 감지 오류: {e}")
            return None
    
    def _combine_drift_results(self, drift_results: Dict) -> DriftAlert:
        """드리프트 결과 결합"""
        try:
            # 모든 감지된 특성 수집
            all_features = set()
            for result in drift_results.values():
                if 'drift_scores' in result:
                    all_features.update(result['drift_scores'].keys())
            
            # 종합적인 신뢰도 계산
            confidences = [result.get('confidence', 0.0) for result in drift_results.values()]
            overall_confidence = np.mean(confidences)
            
            # 심각도 결정
            severities = []
            for result in drift_results.values():
                if 'severity' in result:
                    severities.append(result['severity'])
                elif 'drift_scores' in result:
                    for score in result['drift_scores'].values():
                        if 'severity' in score:
                            severities.append(score['severity'])
            
            overall_severity = 'high' if 'high' in severities else 'medium'
            
            # 권장사항 생성
            recommendations = [
                "모델 재훈련 고려",
                "데이터 분포 재검토",
                "특성 엔지니어링 업데이트"
            ]
            
            if overall_severity == 'high':
                recommendations.append("즉시 모델 업데이트 필요")
            
            return DriftAlert(
                alert_id=f"drift_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                drift_type="concept_drift",
                severity=overall_severity,
                confidence=overall_confidence,
                affected_features=list(all_features),
                timestamp=datetime.now(),
                description=f"개념 드리프트 감지됨 - {len(drift_results)}개 방법으로 확인",
                recommendations=recommendations
            )
            
        except Exception as e:
            logger.error(f"드리프트 결과 결합 오류: {e}")
            return None
    
    def _handle_drift_detection(self, drift_alert: DriftAlert):
        """드리프트 감지 처리"""
        try:
            # 드리프트 히스토리에 추가
            self.drift_history.append(drift_alert)
            
            # 알림 발송
            self._send_drift_alert(drift_alert)
            
            # 참조 윈도우 업데이트
            self._update_reference_window()
            
            logger.warning(f"개념 드리프트 감지: {drift_alert.description}")
            
        except Exception as e:
            logger.error(f"드리프트 감지 처리 오류: {e}")
    
    def _update_reference_window(self):
        """참조 윈도우 업데이트"""
        try:
            # 현재 윈도우를 새로운 참조 윈도우로 설정
            if len(self.current_window) >= self.window_size // 2:
                self.reference_window = self.current_window.copy()
                logger.info("참조 윈도우 업데이트 완료")
            
        except Exception as e:
            logger.error(f"참조 윈도우 업데이트 오류: {e}")
    
    def _send_drift_alert(self, drift_alert: DriftAlert):
        """드리프트 알림 발송"""
        # 실제 구현에서는 알림 시스템 사용
        logger.warning(f"드리프트 알림: {drift_alert.description}")
```

## 🔧 **적응형 파라미터 시스템**

### 📦 **적응형 파라미터 최적화기**

```python
# online-learning/adaptive-parameters/parameter_optimizer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any, Callable
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import optuna

logger = logging.getLogger(__name__)

@dataclass
class MarketRegime:
    """시장 체제"""
    regime_id: str
    regime_type: str  # 'trending', 'ranging', 'volatile', 'stable'
    volatility_level: float
    trend_strength: float
    volume_level: float
    start_time: datetime
    end_time: Optional[datetime] = None
    parameters: Dict[str, float] = None

@dataclass
class ParameterSet:
    """파라미터 세트"""
    parameter_id: str
    parameters: Dict[str, float]
    performance_score: float
    market_regime: str
    created_time: datetime
    is_active: bool = False

class AdaptiveParameterOptimizer:
    """적응형 파라미터 최적화기"""
    
    def __init__(self, optimization_interval: int = 3600):
        self.optimization_interval = optimization_interval
        self.current_regime = None
        self.parameter_history = []
        self.performance_history = []
        self.regime_history = []
        self.optimization_task = None
        
        # 파라미터 범위 정의
        self.parameter_ranges = {
            'learning_rate': (0.001, 0.1),
            'batch_size': (32, 256),
            'momentum': (0.8, 0.99),
            'regularization': (0.001, 0.1),
            'dropout_rate': (0.1, 0.5)
        }
    
    async def start_optimization(self):
        """최적화 시작"""
        self.optimization_task = asyncio.create_task(self._optimization_loop())
        logger.info("적응형 파라미터 최적화 시작")
    
    async def stop_optimization(self):
        """최적화 중지"""
        if self.optimization_task:
            self.optimization_task.cancel()
        logger.info("적응형 파라미터 최적화 중지")
    
    async def _optimization_loop(self):
        """최적화 루프"""
        while True:
            try:
                # 시장 체제 감지
                current_regime = await self._detect_market_regime()
                
                if current_regime != self.current_regime:
                    # 체제 변경 감지
                    await self._handle_regime_change(current_regime)
                
                # 파라미터 최적화 수행
                await self._optimize_parameters()
                
                # 최적화 간격만큼 대기
                await asyncio.sleep(self.optimization_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"최적화 루프 오류: {e}")
                await asyncio.sleep(self.optimization_interval)
    
    async def _detect_market_regime(self) -> MarketRegime:
        """시장 체제 감지"""
        try:
            # 최근 시장 데이터 분석
            market_data = await self._get_recent_market_data()
            
            if not market_data:
                return self.current_regime
            
            # 변동성 계산
            volatility = self._calculate_volatility(market_data)
            
            # 트렌드 강도 계산
            trend_strength = self._calculate_trend_strength(market_data)
            
            # 거래량 레벨 계산
            volume_level = self._calculate_volume_level(market_data)
            
            # 체제 분류
            regime_type = self._classify_regime(volatility, trend_strength, volume_level)
            
            regime = MarketRegime(
                regime_id=f"regime_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                regime_type=regime_type,
                volatility_level=volatility,
                trend_strength=trend_strength,
                volume_level=volume_level,
                start_time=datetime.now()
            )
            
            return regime
            
        except Exception as e:
            logger.error(f"시장 체제 감지 오류: {e}")
            return self.current_regime
    
    def _calculate_volatility(self, market_data: List[Dict]) -> float:
        """변동성 계산"""
        try:
            if len(market_data) < 2:
                return 0.0
            
            returns = []
            for i in range(1, len(market_data)):
                prev_price = market_data[i-1].get('close', 0)
                curr_price = market_data[i].get('close', 0)
                
                if prev_price > 0:
                    ret = (curr_price - prev_price) / prev_price
                    returns.append(ret)
            
            if returns:
                return np.std(returns)
            
            return 0.0
            
        except Exception as e:
            logger.error(f"변동성 계산 오류: {e}")
            return 0.0
    
    def _calculate_trend_strength(self, market_data: List[Dict]) -> float:
        """트렌드 강도 계산"""
        try:
            if len(market_data) < 20:
                return 0.0
            
            prices = [d.get('close', 0) for d in market_data]
            
            # 선형 회귀로 트렌드 계산
            x = np.arange(len(prices)).reshape(-1, 1)
            y = np.array(prices)
            
            reg = LinearRegression()
            reg.fit(x, y)
            
            # R² 점수로 트렌드 강도 측정
            trend_strength = reg.score(x, y)
            
            return max(0.0, trend_strength)
            
        except Exception as e:
            logger.error(f"트렌드 강도 계산 오류: {e}")
            return 0.0
    
    def _calculate_volume_level(self, market_data: List[Dict]) -> float:
        """거래량 레벨 계산"""
        try:
            if not market_data:
                return 0.0
            
            volumes = [d.get('volume', 0) for d in market_data]
            
            if volumes:
                # 최근 거래량의 평균
                recent_volume = np.mean(volumes[-10:]) if len(volumes) >= 10 else np.mean(volumes)
                
                # 전체 기간 평균 대비 상대적 거래량
                avg_volume = np.mean(volumes)
                
                if avg_volume > 0:
                    return recent_volume / avg_volume
                
            return 1.0
            
        except Exception as e:
            logger.error(f"거래량 레벨 계산 오류: {e}")
            return 1.0
    
    def _classify_regime(self, volatility: float, trend_strength: float, 
                        volume_level: float) -> str:
        """체제 분류"""
        try:
            # 변동성 기준
            if volatility > 0.03:  # 3% 이상
                if trend_strength > 0.7:
                    return 'trending'
                else:
                    return 'volatile'
            else:
                if trend_strength > 0.5:
                    return 'trending'
                else:
                    return 'ranging'
            
        except Exception as e:
            logger.error(f"체제 분류 오류: {e}")
            return 'stable'
    
    async def _handle_regime_change(self, new_regime: MarketRegime):
        """체제 변경 처리"""
        try:
            # 이전 체제 종료
            if self.current_regime:
                self.current_regime.end_time = datetime.now()
                self.regime_history.append(self.current_regime)
            
            # 새 체제 설정
            self.current_regime = new_regime
            
            # 체제별 최적 파라미터 로드
            optimal_params = self._get_optimal_parameters_for_regime(new_regime.regime_type)
            
            if optimal_params:
                await self._apply_parameters(optimal_params)
            
            logger.info(f"시장 체제 변경: {new_regime.regime_type}")
            
        except Exception as e:
            logger.error(f"체제 변경 처리 오류: {e}")
    
    def _get_optimal_parameters_for_regime(self, regime_type: str) -> Optional[Dict[str, float]]:
        """체제별 최적 파라미터 조회"""
        try:
            # 체제별 기본 파라미터
            regime_parameters = {
                'trending': {
                    'learning_rate': 0.01,
                    'batch_size': 64,
                    'momentum': 0.9,
                    'regularization': 0.01,
                    'dropout_rate': 0.2
                },
                'ranging': {
                    'learning_rate': 0.005,
                    'batch_size': 128,
                    'momentum': 0.85,
                    'regularization': 0.05,
                    'dropout_rate': 0.3
                },
                'volatile': {
                    'learning_rate': 0.02,
                    'batch_size': 32,
                    'momentum': 0.95,
                    'regularization': 0.02,
                    'dropout_rate': 0.4
                },
                'stable': {
                    'learning_rate': 0.001,
                    'batch_size': 256,
                    'momentum': 0.8,
                    'regularization': 0.1,
                    'dropout_rate': 0.1
                }
            }
            
            return regime_parameters.get(regime_type, regime_parameters['stable'])
            
        except Exception as e:
            logger.error(f"체제별 최적 파라미터 조회 오류: {e}")
            return None
    
    async def _optimize_parameters(self):
        """파라미터 최적화"""
        try:
            if not self.current_regime:
                return
            
            # 최근 성능 데이터 수집
            performance_data = await self._get_recent_performance_data()
            
            if len(performance_data) < 100:
                return
            
            # Optuna를 사용한 베이지안 최적화
            study = optuna.create_study(direction='maximize')
            
            def objective(trial):
                # 파라미터 샘플링
                params = {
                    'learning_rate': trial.suggest_float('learning_rate', 
                                                       self.parameter_ranges['learning_rate'][0],
                                                       self.parameter_ranges['learning_rate'][1],
                                                       log=True),
                    'batch_size': trial.suggest_int('batch_size',
                                                   self.parameter_ranges['batch_size'][0],
                                                   self.parameter_ranges['batch_size'][1]),
                    'momentum': trial.suggest_float('momentum',
                                                   self.parameter_ranges['momentum'][0],
                                                   self.parameter_ranges['momentum'][1]),
                    'regularization': trial.suggest_float('regularization',
                                                         self.parameter_ranges['regularization'][0],
                                                         self.parameter_ranges['regularization'][1],
                                                         log=True),
                    'dropout_rate': trial.suggest_float('dropout_rate',
                                                       self.parameter_ranges['dropout_rate'][0],
                                                       self.parameter_ranges['dropout_rate'][1])
                }
                
                # 성능 평가
                performance_score = self._evaluate_parameters(params, performance_data)
                
                return performance_score
            
            # 최적화 실행
            study.optimize(objective, n_trials=50, timeout=300)
            
            # 최적 파라미터 적용
            best_params = study.best_params
            best_score = study.best_value
            
            # 파라미터 세트 생성
            parameter_set = ParameterSet(
                parameter_id=f"params_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                parameters=best_params,
                performance_score=best_score,
                market_regime=self.current_regime.regime_type,
                created_time=datetime.now(),
                is_active=True
            )
            
            # 파라미터 적용
            await self._apply_parameters(best_params)
            
            # 히스토리에 추가
            self.parameter_history.append(parameter_set)
            
            logger.info(f"파라미터 최적화 완료: {best_score:.4f}")
            
        except Exception as e:
            logger.error(f"파라미터 최적화 오류: {e}")
    
    def _evaluate_parameters(self, params: Dict[str, float], 
                           performance_data: List[Dict]) -> float:
        """파라미터 성능 평가"""
        try:
            # 간단한 성능 평가 (실제로는 모델 성능 측정)
            # 여기서는 파라미터 조합의 적합성을 평가
            
            score = 0.0
            
            # 학습률 평가
            if 0.001 <= params['learning_rate'] <= 0.1:
                score += 0.2
            
            # 배치 크기 평가
            if 32 <= params['batch_size'] <= 256:
                score += 0.2
            
            # 모멘텀 평가
            if 0.8 <= params['momentum'] <= 0.99:
                score += 0.2
            
            # 정규화 평가
            if 0.001 <= params['regularization'] <= 0.1:
                score += 0.2
            
            # 드롭아웃 평가
            if 0.1 <= params['dropout_rate'] <= 0.5:
                score += 0.2
            
            return score
            
        except Exception as e:
            logger.error(f"파라미터 성능 평가 오류: {e}")
            return 0.0
    
    async def _apply_parameters(self, parameters: Dict[str, float]):
        """파라미터 적용"""
        try:
            # 실제 구현에서는 모델에 파라미터 적용
            logger.info(f"파라미터 적용: {parameters}")
            
        except Exception as e:
            logger.error(f"파라미터 적용 오류: {e}")
    
    async def _get_recent_market_data(self) -> List[Dict]:
        """최근 시장 데이터 조회"""
        # 실제 구현에서는 시장 데이터 API 호출
        return []
    
    async def _get_recent_performance_data(self) -> List[Dict]:
        """최근 성능 데이터 조회"""
        # 실제 구현에서는 성능 데이터 조회
        return []
```

## 🔧 **데이터 품질 관리 시스템**

### 📦 **데이터 검증기**

```python
# online-learning/data-quality-management/data_validator.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
from enum import Enum

logger = logging.getLogger(__name__)

class ValidationRule(Enum):
    """검증 규칙"""
    RANGE_CHECK = "range_check"
    TYPE_CHECK = "type_check"
    NULL_CHECK = "null_check"
    UNIQUENESS_CHECK = "uniqueness_check"
    CONSISTENCY_CHECK = "consistency_check"

@dataclass
class ValidationResult:
    """검증 결과"""
    rule: ValidationRule
    field: str
    is_valid: bool
    error_message: Optional[str] = None
    timestamp: datetime = None

@dataclass
class DataQualityReport:
    """데이터 품질 보고서"""
    total_records: int
    valid_records: int
    invalid_records: int
    quality_score: float
    validation_results: List[ValidationResult]
    timestamp: datetime

class DataValidator:
    """데이터 검증기"""
    
    def __init__(self):
        self.validation_rules = self._load_validation_rules()
        self.quality_threshold = 0.95
    
    def _load_validation_rules(self) -> Dict[str, Dict]:
        """검증 규칙 로드"""
        return {
            'price': {
                'type': 'float',
                'range': (0.0, float('inf')),
                'null_allowed': False
            },
            'volume': {
                'type': 'float',
                'range': (0.0, float('inf')),
                'null_allowed': False
            },
            'timestamp': {
                'type': 'datetime',
                'null_allowed': False
            },
            'symbol': {
                'type': 'string',
                'null_allowed': False,
                'max_length': 20
            }
        }
    
    def validate_data(self, data: pd.DataFrame) -> DataQualityReport:
        """데이터 검증"""
        try:
            validation_results = []
            total_records = len(data)
            valid_records = 0
            
            for column in data.columns:
                if column in self.validation_rules:
                    rule = self.validation_rules[column]
                    column_results = self._validate_column(data[column], column, rule)
                    validation_results.extend(column_results)
                    
                    # 유효한 레코드 수 계산
                    valid_count = sum(1 for result in column_results if result.is_valid)
                    valid_records = min(valid_records, valid_count) if valid_records > 0 else valid_count
            
            # 품질 점수 계산
            quality_score = valid_records / total_records if total_records > 0 else 0.0
            
            return DataQualityReport(
                total_records=total_records,
                valid_records=valid_records,
                invalid_records=total_records - valid_records,
                quality_score=quality_score,
                validation_results=validation_results,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"데이터 검증 오류: {e}")
            return DataQualityReport(
                total_records=0,
                valid_records=0,
                invalid_records=0,
                quality_score=0.0,
                validation_results=[],
                timestamp=datetime.now()
            )
    
    def _validate_column(self, column_data: pd.Series, column_name: str, 
                        rule: Dict) -> List[ValidationResult]:
        """컬럼 검증"""
        results = []
        
        # 타입 검증
        if 'type' in rule:
            type_result = self._validate_type(column_data, column_name, rule['type'])
            results.append(type_result)
        
        # 범위 검증
        if 'range' in rule:
            range_result = self._validate_range(column_data, column_name, rule['range'])
            results.append(range_result)
        
        # NULL 검증
        if 'null_allowed' in rule:
            null_result = self._validate_null(column_data, column_name, rule['null_allowed'])
            results.append(null_result)
        
        return results
    
    def _validate_type(self, column_data: pd.Series, column_name: str, 
                      expected_type: str) -> ValidationResult:
        """타입 검증"""
        try:
            if expected_type == 'float':
                is_valid = pd.to_numeric(column_data, errors='coerce').notna().all()
            elif expected_type == 'datetime':
                is_valid = pd.to_datetime(column_data, errors='coerce').notna().all()
            elif expected_type == 'string':
                is_valid = column_data.astype(str).notna().all()
            else:
                is_valid = True
            
            return ValidationResult(
                rule=ValidationRule.TYPE_CHECK,
                field=column_name,
                is_valid=is_valid,
                error_message=None if is_valid else f"타입 불일치: {expected_type}",
                timestamp=datetime.now()
            )
            
        except Exception as e:
            return ValidationResult(
                rule=ValidationRule.TYPE_CHECK,
                field=column_name,
                is_valid=False,
                error_message=f"타입 검증 오류: {str(e)}",
                timestamp=datetime.now()
            )
```

### 📦 **실시간 모니터링 시스템**

```python
# online-learning/real-time-monitoring/real_time_monitor.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
import asyncio
import threading
import time
from collections import deque

logger = logging.getLogger(__name__)

@dataclass
class SystemMetric:
    """시스템 메트릭"""
    metric_name: str
    value: float
    unit: str
    timestamp: datetime
    threshold: Optional[float] = None
    is_alert: bool = False

@dataclass
class StrategyPerformance:
    """전략 성과"""
    strategy_name: str
    total_return: float
    sharpe_ratio: float
    max_drawdown: float
    win_rate: float
    total_trades: int
    timestamp: datetime

@dataclass
class RiskMetric:
    """위험 메트릭"""
    var_95: float
    var_99: float
    portfolio_volatility: float
    correlation: float
    beta: float
    timestamp: datetime

class RealTimeMonitor:
    """실시간 모니터링 시스템"""
    
    def __init__(self, alert_thresholds: Dict[str, float] = None):
        self.alert_thresholds = alert_thresholds or {
            'cpu_usage': 80.0,
            'memory_usage': 85.0,
            'response_time': 1000.0,  # ms
            'error_rate': 5.0,  # %
            'drawdown': 10.0  # %
        }
        
        self.system_metrics = deque(maxlen=1000)
        self.strategy_performance = deque(maxlen=100)
        self.risk_metrics = deque(maxlen=100)
        self.alerts = deque(maxlen=100)
        
        self.monitoring_active = False
        self.monitoring_thread = None
    
    def start_monitoring(self):
        """모니터링 시작"""
        if not self.monitoring_active:
            self.monitoring_active = True
            self.monitoring_thread = threading.Thread(target=self._monitoring_loop)
            self.monitoring_thread.daemon = True
            self.monitoring_thread.start()
            logger.info("실시간 모니터링 시작")
    
    def stop_monitoring(self):
        """모니터링 중지"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join()
        logger.info("실시간 모니터링 중지")
    
    def _monitoring_loop(self):
        """모니터링 루프"""
        while self.monitoring_active:
            try:
                # 시스템 메트릭 수집
                system_metrics = self._collect_system_metrics()
                self.system_metrics.extend(system_metrics)
                
                # 전략 성과 수집
                strategy_performance = self._collect_strategy_performance()
                self.strategy_performance.extend(strategy_performance)
                
                # 위험 메트릭 수집
                risk_metrics = self._collect_risk_metrics()
                self.risk_metrics.extend(risk_metrics)
                
                # 알림 확인
                alerts = self._check_alerts()
                self.alerts.extend(alerts)
                
                # 1초 대기
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"모니터링 루프 오류: {e}")
                time.sleep(5)
    
    def _collect_system_metrics(self) -> List[SystemMetric]:
        """시스템 메트릭 수집"""
        try:
            metrics = []
            current_time = datetime.now()
            
            # CPU 사용률
            cpu_usage = self._get_cpu_usage()
            metrics.append(SystemMetric(
                metric_name='cpu_usage',
                value=cpu_usage,
                unit='%',
                timestamp=current_time,
                threshold=self.alert_thresholds['cpu_usage'],
                is_alert=cpu_usage > self.alert_thresholds['cpu_usage']
            ))
            
            # 메모리 사용률
            memory_usage = self._get_memory_usage()
            metrics.append(SystemMetric(
                metric_name='memory_usage',
                value=memory_usage,
                unit='%',
                timestamp=current_time,
                threshold=self.alert_thresholds['memory_usage'],
                is_alert=memory_usage > self.alert_thresholds['memory_usage']
            ))
            
            # 응답 시간
            response_time = self._get_response_time()
            metrics.append(SystemMetric(
                metric_name='response_time',
                value=response_time,
                unit='ms',
                timestamp=current_time,
                threshold=self.alert_thresholds['response_time'],
                is_alert=response_time > self.alert_thresholds['response_time']
            ))
            
            return metrics
            
        except Exception as e:
            logger.error(f"시스템 메트릭 수집 오류: {e}")
            return []
    
    def _get_cpu_usage(self) -> float:
        """CPU 사용률 조회"""
        # 실제 구현에서는 psutil 사용
        import random
        return random.uniform(20.0, 90.0)
    
    def _get_memory_usage(self) -> float:
        """메모리 사용률 조회"""
        # 실제 구현에서는 psutil 사용
        import random
        return random.uniform(30.0, 95.0)
    
    def _get_response_time(self) -> float:
        """응답 시간 조회"""
        # 실제 구현에서는 실제 응답 시간 측정
        import random
        return random.uniform(50.0, 1500.0)
    
    def _collect_strategy_performance(self) -> List[StrategyPerformance]:
        """전략 성과 수집"""
        try:
            # 실제 구현에서는 전략 성과 데이터 조회
            return []
            
        except Exception as e:
            logger.error(f"전략 성과 수집 오류: {e}")
            return []
    
    def _collect_risk_metrics(self) -> List[RiskMetric]:
        """위험 메트릭 수집"""
        try:
            # 실제 구현에서는 위험 메트릭 계산
            return []
            
        except Exception as e:
            logger.error(f"위험 메트릭 수집 오류: {e}")
            return []
    
    def _check_alerts(self) -> List[Dict[str, Any]]:
        """알림 확인"""
        alerts = []
        
        # 시스템 메트릭 알림 확인
        for metric in list(self.system_metrics)[-10:]:  # 최근 10개 메트릭
            if metric.is_alert:
                alerts.append({
                    'type': 'system_alert',
                    'metric': metric.metric_name,
                    'value': metric.value,
                    'threshold': metric.threshold,
                    'timestamp': metric.timestamp,
                    'message': f"{metric.metric_name} 임계값 초과: {metric.value}{metric.unit}"
                })
        
        return alerts
    
    def get_system_health(self) -> Dict[str, Any]:
        """시스템 건강도 조회"""
        try:
            if not self.system_metrics:
                return {'status': 'unknown', 'score': 0.0}
            
            recent_metrics = list(self.system_metrics)[-10:]  # 최근 10개
            
            # 알림 개수 계산
            alert_count = sum(1 for metric in recent_metrics if metric.is_alert)
            
            # 건강도 점수 계산 (0-100)
            health_score = max(0, 100 - (alert_count * 10))
            
            # 상태 결정
            if health_score >= 80:
                status = 'healthy'
            elif health_score >= 60:
                status = 'warning'
            else:
                status = 'critical'
            
            return {
                'status': status,
                'score': health_score,
                'alert_count': alert_count,
                'last_update': datetime.now()
            }
            
        except Exception as e:
            logger.error(f"시스템 건강도 조회 오류: {e}")
            return {'status': 'error', 'score': 0.0}
```

## 📊 **성과 지표**

### **목표 성과**
- **모델 업데이트 시간**: < 5분
- **개념 드리프트 감지**: < 1시간
- **적응 속도**: < 10분
- **데이터 품질 정확도**: > 99.9% 데이터 정확도
- **실시간 모니터링**: < 100ms 모니터링 지연
- **학습 정확도**: > 70%
- **메모리 효율성**: < 2GB

### **성능 지표**
- **스트리밍 처리 속도**: < 100ms per batch
- **드리프트 감지 정확도**: > 85%
- **파라미터 최적화 시간**: < 5분
- **데이터 검증 시간**: < 50ms
- **모니터링 지연**: < 100ms
- **시스템 가동률**: > 99.5%
- **메모리 사용량**: < 2GB

## 🔗 **관련 문서**

- [Phase 3.5.1: 기술적 지표 분석](3.5.1_TECHNICAL_ANALYSIS.md)
- [Phase 3.5.2: 거래 전략 라이브러리](3.5.2_TRADING_STRATEGIES.md)
- [Phase 3.5.3: 뉴스 이벤트 분석](3.5.3_NEWS_EVENT_ANALYSIS.md)
- [Phase 3.5.5: 설명 가능한 AI](3.5.5_EXPLAINABLE_AI.md)

---

**마지막 업데이트**: 2025-01-26  
**프로젝트 상태**: 설계 완료, 개발 준비  
**다음 단계**: 설명 가능한 AI 시스템 구현 