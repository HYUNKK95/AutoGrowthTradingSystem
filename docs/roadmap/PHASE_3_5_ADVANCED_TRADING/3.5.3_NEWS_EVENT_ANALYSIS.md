# 📰 Phase 3.5.3: 뉴스 이벤트 분석 시스템 (뉴스 + 감정 통합)

## 📋 **개요**

### 🎯 **목표**
- **이벤트 감지 시스템**: 경제지표, 기업 실적, 정부 정책 등 중요 이벤트 감지
- **경제 캘린더 연동**: 주요 경제 이벤트 스케줄링 및 알림
- **뉴스 영향도 분석**: 뉴스의 시장 영향도 평가 및 예측
- **팩트체킹 시스템**: 뉴스 사실 검증 및 신뢰도 평가
- **뉴스 신뢰도 평가**: 출처 신뢰도, 일관성, 검증 가능성 평가
- **소셜 미디어 감정 분석**: Twitter, Reddit, 뉴스 댓글 실시간 감정 분석
- **레귤레이션 뉴스 파싱**: 규제 관련 뉴스 자동 파싱 및 분석
- **뉴스 API 연동**: 다양한 뉴스 소스 API 통합
- **소셜 미디어 API 연동**: Twitter, Reddit, 기타 소셜 플랫폼 API 통합
- **키워드 기반 중요도 스코어링**: 키워드 분석을 통한 뉴스 중요도 평가
- **팩트 체크 알고리즘**: 자동화된 사실 검증 시스템
- **다국어 모델 학습·서빙**: 한국어, 영어, 중국어, 일본어 등 다국어 지원
- **뉴스 기반 자동 포지션 관리**: 뉴스 분석 결과 기반 자동 거래
- **리스크 조정 기능**: 뉴스 기반 리스크 관리 및 포지션 조정
- **감정 기반 거래 신호**: 감정 점수 기반 거래 신호 생성
- **이벤트 기반 거래 트리거**: 중요 이벤트 발생 시 자동 거래 신호 생성
- **실시간 뉴스 모니터링**: 24/7 뉴스 스트림 분석

### 📊 **성능 목표**
- **이벤트 감지 속도**: < 1초 중요 이벤트 감지
- **뉴스 분석 정확도**: > 85% 영향도 예측 정확도
- **감정 분석 정확도**: > 75% 감정 분석 정확도
- **실시간 처리**: < 500ms 뉴스 분석 완료
- **소셜 미디어 처리**: < 200ms 감정 분석 완료
- **다국어 지원**: 영어, 한국어, 중국어, 일본어
- **이벤트 예측**: > 70% 이벤트 발생 예측 정확도

## 🏗️ **뉴스 이벤트 분석 시스템 아키텍처**

### 📁 **시스템 구조**
```
news-event-analysis/
├── event-detection/                      # 이벤트 감지
│   ├── economic-indicators/             # 경제 지표 감지
│   ├── earnings-reports/                # 실적 발표 감지
│   ├── policy-changes/                  # 정책 변경 감지
│   ├── market-events/                   # 시장 이벤트 감지
│   └── breaking-news/                   # 긴급 뉴스 감지
├── fact-checking/                        # 팩트체킹 시스템
│   ├── fact-checker/                    # 팩트 체커
│   ├── source-verification/             # 출처 검증
│   ├── consistency-checker/             # 일관성 검사
│   └── credibility-scorer/              # 신뢰도 점수
├── news-reliability/                     # 뉴스 신뢰도 평가
│   ├── source-reliability/              # 출처 신뢰도
│   ├── content-consistency/             # 내용 일관성
│   ├── verification-capability/         # 검증 가능성
│   └── reliability-scorer/              # 신뢰도 스코어링
├── regulatory-news-parsing/              # 레귤레이션 뉴스 파싱
│   ├── regulatory-keywords/             # 규제 키워드
│   ├── policy-extractor/                # 정책 추출기
│   ├── impact-analyzer/                 # 영향 분석기
│   └── compliance-checker/              # 준수성 검사
├── api-integration/                      # API 연동
│   ├── news-apis/                       # 뉴스 API
│   ├── social-media-apis/               # 소셜 미디어 API
│   ├── calendar-apis/                   # 캘린더 API
│   └── regulatory-apis/                 # 규제 API
├── keyword-importance-scoring/           # 키워드 중요도 스코어링
│   ├── keyword-extractor/               # 키워드 추출기
│   ├── importance-calculator/           # 중요도 계산기
│   ├── trend-analyzer/                  # 트렌드 분석기
│   └── scoring-engine/                  # 스코어링 엔진
├── fact-check-algorithms/                # 팩트 체크 알고리즘
│   ├── claim-extractor/                 # 주장 추출기
│   ├── evidence-finder/                 # 증거 찾기
│   ├── verification-engine/             # 검증 엔진
│   └── fact-check-scorer/               # 팩트 체크 스코어
├── multi-language-models/                # 다국어 모델
│   ├── language-detector/               # 언어 감지기
│   ├── model-trainer/                   # 모델 훈련기
│   ├── model-servers/                   # 모델 서버
│   └── translation-engine/              # 번역 엔진
├── news-based-position-management/       # 뉴스 기반 포지션 관리
│   ├── position-calculator/             # 포지션 계산기
│   ├── risk-adjuster/                   # 리스크 조정기
│   ├── trade-signal-generator/          # 거래 신호 생성기
│   └── position-monitor/                # 포지션 모니터
├── economic-calendar/                    # 경제 캘린더
│   ├── calendar-api/                    # 캘린더 API 연동
│   ├── event-scheduler/                 # 이벤트 스케줄러
│   ├── reminder-system/                 # 알림 시스템
│   └── impact-prediction/               # 영향도 예측
├── news-impact-analysis/                 # 뉴스 영향 분석
│   ├── sentiment-analyzer/              # 감정 분석기
│   ├── impact-scorer/                   # 영향도 스코어링
│   ├── market-correlation/              # 시장 상관관계
│   └── volatility-prediction/           # 변동성 예측
├── event-triggers/                       # 이벤트 트리거
│   ├── trigger-engine/                  # 트리거 엔진
│   ├── signal-generator/                # 신호 생성기
│   ├── risk-adjuster/                   # 리스크 조정기
│   └── position-manager/                # 포지션 관리자
├── real-time-monitoring/                 # 실시간 모니터링
│   ├── news-streams/                    # 뉴스 스트림
│   ├── social-media/                    # 소셜미디어
│   ├── financial-news/                  # 금융 뉴스
│   └── regulatory-news/                 # 규제 뉴스
├── data-sources/                         # 데이터 소스
    ├── news-apis/                       # 뉴스 API
    ├── calendar-apis/                   # 캘린더 API
    ├── social-apis/                     # 소셜 API
    └── regulatory-apis/                 # 규제 API
├── sentiment-analysis/                   # 감정 분석
    ├── social-media-sentiment/          # 소셜 미디어 감정
    ├── news-sentiment/                  # 뉴스 감정 분석
    ├── comment-sentiment/               # 댓글 감정 분석
    ├── multi-language-sentiment/        # 다국어 감정 분석
    └── sentiment-signal-generator/      # 감정 신호 생성기
```

## 🔧 **이벤트 감지 시스템**

### 📦 **경제 지표 감지기**

```python
# news-event-analysis/event-detection/economic_indicator_detector.py
import asyncio
import aiohttp
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
import json
import re
from enum import Enum

logger = logging.getLogger(__name__)

class EventType(Enum):
    """이벤트 타입"""
    ECONOMIC_INDICATOR = "economic_indicator"
    EARNINGS_REPORT = "earnings_report"
    POLICY_CHANGE = "policy_change"
    MARKET_EVENT = "market_event"
    BREAKING_NEWS = "breaking_news"

class EventImportance(Enum):
    """이벤트 중요도"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

@dataclass
class EconomicEvent:
    """경제 이벤트"""
    event_id: str
    event_type: EventType
    title: str
    description: str
    importance: EventImportance
    scheduled_time: datetime
    actual_time: Optional[datetime] = None
    expected_value: Optional[float] = None
    actual_value: Optional[float] = None
    previous_value: Optional[float] = None
    currency: str = "USD"
    country: str = "US"
    impact_score: float = 0.0
    market_impact: Dict[str, float] = None

@dataclass
class EventAlert:
    """이벤트 알림"""
    event_id: str
    alert_type: str  # 'scheduled', 'actual', 'deviation'
    message: str
    timestamp: datetime
    importance: EventImportance
    trading_signals: List[Dict] = None

class EconomicIndicatorDetector:
    """경제 지표 감지기"""
    
    def __init__(self):
        self.economic_calendar = {}
        self.event_patterns = self._load_event_patterns()
        self.importance_weights = {
            EventImportance.LOW: 0.1,
            EventImportance.MEDIUM: 0.3,
            EventImportance.HIGH: 0.6,
            EventImportance.CRITICAL: 1.0
        }
        self.monitoring_task = None
    
    def _load_event_patterns(self) -> Dict[str, Dict]:
        """이벤트 패턴 로드"""
        return {
            'fomc': {
                'keywords': ['FOMC', 'Federal Reserve', 'interest rate', 'monetary policy'],
                'importance': EventImportance.CRITICAL,
                'impact_assets': ['USD', 'US10Y', 'SPY', 'QQQ']
            },
            'non_farm_payrolls': {
                'keywords': ['non-farm payrolls', 'NFP', 'employment', 'jobs report'],
                'importance': EventImportance.HIGH,
                'impact_assets': ['USD', 'US10Y', 'SPY', 'QQQ']
            },
            'cpi': {
                'keywords': ['CPI', 'inflation', 'consumer price index'],
                'importance': EventImportance.HIGH,
                'impact_assets': ['USD', 'US10Y', 'SPY', 'QQQ']
            },
            'gdp': {
                'keywords': ['GDP', 'gross domestic product', 'economic growth'],
                'importance': EventImportance.HIGH,
                'impact_assets': ['USD', 'US10Y', 'SPY', 'QQQ']
            },
            'earnings': {
                'keywords': ['earnings', 'quarterly report', 'Q1', 'Q2', 'Q3', 'Q4'],
                'importance': EventImportance.MEDIUM,
                'impact_assets': ['individual_stocks']
            }
        }
    
    async def start_monitoring(self):
        """이벤트 모니터링 시작"""
        self.monitoring_task = asyncio.create_task(self._monitor_events())
        logger.info("경제 이벤트 모니터링 시작")
    
    async def stop_monitoring(self):
        """이벤트 모니터링 중지"""
        if self.monitoring_task:
            self.monitoring_task.cancel()
            logger.info("경제 이벤트 모니터링 중지")
    
    async def _monitor_events(self):
        """이벤트 모니터링 루프"""
        while True:
            try:
                # 스케줄된 이벤트 확인
                await self._check_scheduled_events()
                
                # 실시간 뉴스 확인
                await self._check_breaking_news()
                
                # 1분 대기
                await asyncio.sleep(60)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"이벤트 모니터링 오류: {e}")
                await asyncio.sleep(60)
    
    async def _check_scheduled_events(self):
        """스케줄된 이벤트 확인"""
        try:
            current_time = datetime.now()
            
            for event_id, event in self.economic_calendar.items():
                # 이벤트 시간이 가까워지면 알림
                time_diff = event.scheduled_time - current_time
                
                if timedelta(minutes=30) <= time_diff <= timedelta(minutes=31):
                    await self._send_event_alert(event, 'scheduled_30min')
                
                elif timedelta(minutes=5) <= time_diff <= timedelta(minutes=6):
                    await self._send_event_alert(event, 'scheduled_5min')
                
                elif timedelta(minutes=0) <= time_diff <= timedelta(minutes=1):
                    await self._send_event_alert(event, 'scheduled_now')
                
        except Exception as e:
            logger.error(f"스케줄된 이벤트 확인 오류: {e}")
    
    async def _check_breaking_news(self):
        """긴급 뉴스 확인"""
        try:
            # 뉴스 API에서 최신 뉴스 가져오기
            breaking_news = await self._fetch_breaking_news()
            
            for news in breaking_news:
                # 이벤트 패턴 매칭
                matched_event = self._match_event_pattern(news)
                
                if matched_event:
                    await self._process_breaking_news(matched_event, news)
                
        except Exception as e:
            logger.error(f"긴급 뉴스 확인 오류: {e}")
    
    async def _fetch_breaking_news(self) -> List[Dict]:
        """긴급 뉴스 가져오기"""
        # 실제 구현에서는 뉴스 API 사용
        # 예: Alpha Vantage, NewsAPI, Reuters 등
        
        # 예시 데이터
        return [
            {
                'title': 'Federal Reserve announces interest rate decision',
                'content': 'The Federal Reserve has decided to raise interest rates by 25 basis points...',
                'timestamp': datetime.now(),
                'source': 'Reuters',
                'url': 'https://example.com/news/1'
            }
        ]
    
    def _match_event_pattern(self, news: Dict) -> Optional[Dict]:
        """뉴스와 이벤트 패턴 매칭"""
        title = news.get('title', '').lower()
        content = news.get('content', '').lower()
        text = f"{title} {content}"
        
        for pattern_name, pattern in self.event_patterns.items():
            keywords = pattern['keywords']
            
            # 키워드 매칭 확인
            matches = sum(1 for keyword in keywords if keyword.lower() in text)
            
            if matches >= len(keywords) * 0.5:  # 50% 이상 매칭
                return {
                    'pattern_name': pattern_name,
                    'pattern': pattern,
                    'news': news,
                    'match_score': matches / len(keywords)
                }
        
        return None
    
    async def _process_breaking_news(self, matched_event: Dict, news: Dict):
        """긴급 뉴스 처리"""
        try:
            pattern = matched_event['pattern']
            news_data = matched_event['news']
            
            # 이벤트 생성
            event = EconomicEvent(
                event_id=f"breaking_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                event_type=EventType.BREAKING_NEWS,
                title=news_data['title'],
                description=news_data['content'],
                importance=pattern['importance'],
                scheduled_time=datetime.now(),
                actual_time=datetime.now(),
                impact_score=self._calculate_impact_score(pattern, news_data)
            )
            
            # 알림 발송
            await self._send_event_alert(event, 'breaking_news')
            
            # 거래 신호 생성
            trading_signals = self._generate_trading_signals(event)
            if trading_signals:
                await self._send_trading_signals(trading_signals)
            
        except Exception as e:
            logger.error(f"긴급 뉴스 처리 오류: {e}")
    
    def _calculate_impact_score(self, pattern: Dict, news: Dict) -> float:
        """영향도 점수 계산"""
        base_score = self.importance_weights[pattern['importance']]
        
        # 뉴스 소스 신뢰도
        source_credibility = {
            'Reuters': 0.9,
            'Bloomberg': 0.9,
            'CNBC': 0.8,
            'MarketWatch': 0.7
        }
        
        source = news.get('source', '')
        credibility = source_credibility.get(source, 0.5)
        
        # 최종 점수 계산
        impact_score = base_score * credibility
        
        return min(1.0, impact_score)
    
    def _generate_trading_signals(self, event: EconomicEvent) -> List[Dict]:
        """거래 신호 생성"""
        signals = []
        
        # 이벤트 타입별 신호 생성
        if event.event_type == EventType.ECONOMIC_INDICATOR:
            signals.extend(self._generate_economic_signals(event))
        elif event.event_type == EventType.EARNINGS_REPORT:
            signals.extend(self._generate_earnings_signals(event))
        elif event.event_type == EventType.POLICY_CHANGE:
            signals.extend(self._generate_policy_signals(event))
        
        return signals
    
    def _generate_economic_signals(self, event: EconomicEvent) -> List[Dict]:
        """경제 지표 신호 생성"""
        signals = []
        
        # FOMC 이벤트
        if 'fomc' in event.title.lower():
            if 'raise' in event.description.lower():
                signals.append({
                    'type': 'SELL',
                    'asset': 'US10Y',
                    'reason': 'FOMC rate hike expected',
                    'confidence': 0.8
                })
            elif 'cut' in event.description.lower():
                signals.append({
                    'type': 'BUY',
                    'asset': 'US10Y',
                    'reason': 'FOMC rate cut expected',
                    'confidence': 0.8
                })
        
        # NFP 이벤트
        elif 'non-farm payrolls' in event.title.lower():
            if event.actual_value and event.expected_value:
                if event.actual_value > event.expected_value:
                    signals.append({
                        'type': 'BUY',
                        'asset': 'USD',
                        'reason': 'Strong NFP data',
                        'confidence': 0.7
                    })
                else:
                    signals.append({
                        'type': 'SELL',
                        'asset': 'USD',
                        'reason': 'Weak NFP data',
                        'confidence': 0.7
                    })
        
        return signals
    
    async def _send_event_alert(self, event: EconomicEvent, alert_type: str):
        """이벤트 알림 발송"""
        try:
            alert = EventAlert(
                event_id=event.event_id,
                alert_type=alert_type,
                message=f"{event.title} - {event.description}",
                timestamp=datetime.now(),
                importance=event.importance
            )
            
            # 알림 시스템으로 전송
            await self._send_alert(alert)
            
            logger.info(f"이벤트 알림 발송: {alert_type} - {event.title}")
            
        except Exception as e:
            logger.error(f"이벤트 알림 발송 오류: {e}")
    
    async def _send_trading_signals(self, signals: List[Dict]):
        """거래 신호 발송"""
        try:
            # 거래 시스템으로 신호 전송
            for signal in signals:
                await self._send_signal(signal)
            
            logger.info(f"거래 신호 발송: {len(signals)}개 신호")
            
        except Exception as e:
            logger.error(f"거래 신호 발송 오류: {e}")
    
    async def _send_alert(self, alert: EventAlert):
        """알림 전송 (실제 구현에서는 알림 시스템 사용)"""
        # 실제 구현에서는 이메일, SMS, 웹훅 등 사용
        pass
    
    async def _send_signal(self, signal: Dict):
        """신호 전송 (실제 구현에서는 거래 시스템 사용)"""
        # 실제 구현에서는 거래 시스템 API 호출
        pass
```

## 🔧 **경제 캘린더 시스템**

### 📦 **경제 캘린더 관리자**

```python
# news-event-analysis/economic-calendar/calendar_manager.py
import asyncio
import aiohttp
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
import json
import icalendar
from enum import Enum

logger = logging.getLogger(__name__)

class CalendarSource(Enum):
    """캘린더 소스"""
    INVESTING_COM = "investing.com"
    FOREX_FACTORY = "forexfactory.com"
    FX_STREET = "fxstreet.com"
    CUSTOM = "custom"

@dataclass
class CalendarEvent:
    """캘린더 이벤트"""
    event_id: str
    title: str
    description: str
    scheduled_time: datetime
    currency: str
    country: str
    importance: str
    expected_value: Optional[str] = None
    previous_value: Optional[str] = None
    source: str = ""
    url: str = ""

class EconomicCalendarManager:
    """경제 캘린더 관리자"""
    
    def __init__(self):
        self.calendar_events = {}
        self.calendar_sources = {
            CalendarSource.INVESTING_COM: "https://www.investing.com/economic-calendar/",
            CalendarSource.FOREX_FACTORY: "https://www.forexfactory.com/calendar",
            CalendarSource.FX_STREET: "https://www.fxstreet.com/economic-calendar"
        }
        self.update_interval = 3600  # 1시간마다 업데이트
        self.update_task = None
    
    async def start_calendar_updates(self):
        """캘린더 업데이트 시작"""
        self.update_task = asyncio.create_task(self._calendar_update_loop())
        logger.info("경제 캘린더 업데이트 시작")
    
    async def stop_calendar_updates(self):
        """캘린더 업데이트 중지"""
        if self.update_task:
            self.update_task.cancel()
            logger.info("경제 캘린더 업데이트 중지")
    
    async def _calendar_update_loop(self):
        """캘린더 업데이트 루프"""
        while True:
            try:
                # 모든 소스에서 캘린더 데이터 가져오기
                await self._update_calendar_data()
                
                # 스케줄된 시간만큼 대기
                await asyncio.sleep(self.update_interval)
                
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"캘린더 업데이트 오류: {e}")
                await asyncio.sleep(self.update_interval)
    
    async def _update_calendar_data(self):
        """캘린더 데이터 업데이트"""
        try:
            for source, url in self.calendar_sources.items():
                events = await self._fetch_calendar_events(source, url)
                
                if events:
                    self.calendar_events[source] = events
                    logger.info(f"캘린더 데이터 업데이트 완료: {source.value} - {len(events)}개 이벤트")
                
        except Exception as e:
            logger.error(f"캘린더 데이터 업데이트 오류: {e}")
    
    async def _fetch_calendar_events(self, source: CalendarSource, url: str) -> List[CalendarEvent]:
        """캘린더 이벤트 가져오기"""
        try:
            # 실제 구현에서는 각 사이트의 API 또는 웹 스크래핑 사용
            # 여기서는 예시 데이터 반환
            
            if source == CalendarSource.INVESTING_COM:
                return await self._fetch_investing_calendar()
            elif source == CalendarSource.FOREX_FACTORY:
                return await self._fetch_forex_factory_calendar()
            elif source == CalendarSource.FX_STREET:
                return await self._fetch_fxstreet_calendar()
            
            return []
            
        except Exception as e:
            logger.error(f"캘린더 이벤트 가져오기 오류 {source.value}: {e}")
            return []
    
    async def _fetch_investing_calendar(self) -> List[CalendarEvent]:
        """Investing.com 캘린더 가져오기"""
        # 실제 구현에서는 Investing.com API 또는 웹 스크래핑
        events = []
        
        # 예시 데이터
        events.append(CalendarEvent(
            event_id="investing_001",
            title="Non-Farm Payrolls",
            description="Employment change in the non-farm sector",
            scheduled_time=datetime.now() + timedelta(days=1, hours=8),
            currency="USD",
            country="US",
            importance="High",
            expected_value="180K",
            previous_value="175K",
            source="investing.com"
        ))
        
        return events
    
    async def _fetch_forex_factory_calendar(self) -> List[CalendarEvent]:
        """Forex Factory 캘린더 가져오기"""
        # 실제 구현에서는 Forex Factory 웹 스크래핑
        events = []
        
        # 예시 데이터
        events.append(CalendarEvent(
            event_id="forex_001",
            title="FOMC Interest Rate Decision",
            description="Federal Reserve interest rate decision",
            scheduled_time=datetime.now() + timedelta(days=2, hours=14),
            currency="USD",
            country="US",
            importance="High",
            expected_value="5.50%",
            previous_value="5.25%",
            source="forexfactory.com"
        ))
        
        return events
    
    async def _fetch_fxstreet_calendar(self) -> List[CalendarEvent]:
        """FX Street 캘린더 가져오기"""
        # 실제 구현에서는 FX Street API 또는 웹 스크래핑
        events = []
        
        # 예시 데이터
        events.append(CalendarEvent(
            event_id="fxstreet_001",
            title="CPI (YoY)",
            description="Consumer Price Index year-over-year change",
            scheduled_time=datetime.now() + timedelta(days=3, hours=8),
            currency="USD",
            country="US",
            importance="High",
            expected_value="3.1%",
            previous_value="3.2%",
            source="fxstreet.com"
        ))
        
        return events
    
    def get_upcoming_events(self, hours: int = 24) -> List[CalendarEvent]:
        """다가오는 이벤트 조회"""
        upcoming_events = []
        current_time = datetime.now()
        end_time = current_time + timedelta(hours=hours)
        
        for source_events in self.calendar_events.values():
            for event in source_events:
                if current_time <= event.scheduled_time <= end_time:
                    upcoming_events.append(event)
        
        # 시간순 정렬
        upcoming_events.sort(key=lambda x: x.scheduled_time)
        
        return upcoming_events
    
    def get_events_by_importance(self, importance: str) -> List[CalendarEvent]:
        """중요도별 이벤트 조회"""
        filtered_events = []
        
        for source_events in self.calendar_events.values():
            for event in source_events:
                if event.importance.lower() == importance.lower():
                    filtered_events.append(event)
        
        return filtered_events
    
    def get_events_by_currency(self, currency: str) -> List[CalendarEvent]:
        """통화별 이벤트 조회"""
        filtered_events = []
        
        for source_events in self.calendar_events.values():
            for event in source_events:
                if event.currency.upper() == currency.upper():
                    filtered_events.append(event)
        
        return filtered_events
    
    def add_custom_event(self, event: CalendarEvent):
        """커스텀 이벤트 추가"""
        if CalendarSource.CUSTOM not in self.calendar_events:
            self.calendar_events[CalendarSource.CUSTOM] = []
        
        self.calendar_events[CalendarSource.CUSTOM].append(event)
        logger.info(f"커스텀 이벤트 추가: {event.title}")
    
    def export_calendar_ics(self, file_path: str):
        """캘린더를 iCal 형식으로 내보내기"""
        try:
            cal = icalendar.Calendar()
            cal.add('prodid', '-//Economic Calendar//AutoGrowthTradingSystem//')
            cal.add('version', '2.0')
            
            for source_events in self.calendar_events.values():
                for event in source_events:
                    ical_event = icalendar.Event()
                    ical_event.add('summary', event.title)
                    ical_event.add('description', event.description)
                    ical_event.add('dtstart', event.scheduled_time)
                    ical_event.add('dtend', event.scheduled_time + timedelta(hours=1))
                    ical_event.add('location', f"{event.country} - {event.currency}")
                    
                    cal.add_component(ical_event)
            
            with open(file_path, 'wb') as f:
                f.write(cal.to_ical())
            
            logger.info(f"캘린더 내보내기 완료: {file_path}")
            
        except Exception as e:
            logger.error(f"캘린더 내보내기 오류: {e}")
```

## 🔧 **감정 분석 시스템**

### 📦 **소셜 미디어 감정 분석기**

```python
# news-event-analysis/sentiment-analysis/social_media_sentiment_analyzer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
from textblob import TextBlob
import tweepy
import praw
import requests
from transformers import pipeline

logger = logging.getLogger(__name__)

@dataclass
class SentimentData:
    """감정 데이터"""
    source: str  # 'twitter', 'reddit', 'news_comments'
    text: str
    sentiment_score: float  # -1.0 ~ 1.0
    confidence: float
    language: str
    timestamp: datetime
    user_id: Optional[str] = None
    engagement: int = 0  # 좋아요, 리트윗, 댓글 수

@dataclass
class SentimentSignal:
    """감정 신호"""
    symbol: str
    sentiment_score: float
    confidence: float
    volume: int
    source_breakdown: Dict[str, float]
    timestamp: datetime
    trading_signal: str  # 'BUY', 'SELL', 'HOLD'

class SocialMediaSentimentAnalyzer:
    """소셜 미디어 감정 분석기"""
    
    def __init__(self, twitter_api_key: str = None, reddit_api_key: str = None):
        self.twitter_api_key = twitter_api_key
        self.reddit_api_key = reddit_api_key
        self.sentiment_pipeline = pipeline("sentiment-analysis", model="cardiffnlp/twitter-roberta-base-sentiment")
        self.sentiment_history = []
        self.sentiment_threshold = 0.3
    
    def analyze_twitter_sentiment(self, symbol: str, keywords: List[str], 
                                count: int = 100) -> List[SentimentData]:
        """Twitter 감정 분석"""
        try:
            sentiment_data = []
            
            # Twitter API 호출 (실제 구현에서는 tweepy 사용)
            # tweets = self.twitter_api.search_tweets(q=f"${symbol} {' '.join(keywords)}", count=count)
            
            # 예시 데이터
            tweets = [
                {"text": f"${symbol} is going to the moon! 🚀", "created_at": datetime.now(), "user_id": "user1", "favorite_count": 10, "retweet_count": 5},
                {"text": f"${symbol} earnings look terrible", "created_at": datetime.now(), "user_id": "user2", "favorite_count": 2, "retweet_count": 1},
                {"text": f"${symbol} new product announcement", "created_at": datetime.now(), "user_id": "user3", "favorite_count": 15, "retweet_count": 8}
            ]
            
            for tweet in tweets:
                # 감정 분석
                sentiment_result = self.sentiment_pipeline(tweet['text'])[0]
                
                # 감정 점수 변환 (-1.0 ~ 1.0)
                if sentiment_result['label'] == 'POSITIVE':
                    sentiment_score = sentiment_result['score']
                elif sentiment_result['label'] == 'NEGATIVE':
                    sentiment_score = -sentiment_result['score']
                else:
                    sentiment_score = 0.0
                
                # 참여도 계산
                engagement = tweet.get('favorite_count', 0) + tweet.get('retweet_count', 0) * 2
                
                sentiment_data.append(SentimentData(
                    source='twitter',
                    text=tweet['text'],
                    sentiment_score=sentiment_score,
                    confidence=sentiment_result['score'],
                    language='en',
                    timestamp=tweet['created_at'],
                    user_id=tweet['user_id'],
                    engagement=engagement
                ))
            
            return sentiment_data
            
        except Exception as e:
            logger.error(f"Twitter 감정 분석 오류: {e}")
            return []
    
    def analyze_reddit_sentiment(self, symbol: str, subreddits: List[str], 
                               limit: int = 100) -> List[SentimentData]:
        """Reddit 감정 분석"""
        try:
            sentiment_data = []
            
            # Reddit API 호출 (실제 구현에서는 praw 사용)
            # for subreddit_name in subreddits:
            #     subreddit = self.reddit.subreddit(subreddit_name)
            #     posts = subreddit.search(f"{symbol}", limit=limit//len(subreddits))
            
            # 예시 데이터
            posts = [
                {"title": f"{symbol} DD - Bullish case", "selftext": "Great fundamentals", "score": 100, "created_utc": datetime.now().timestamp()},
                {"title": f"{symbol} is overvalued", "selftext": "Bubble will pop", "score": 50, "created_utc": datetime.now().timestamp()}
            ]
            
            for post in posts:
                # 제목과 본문 결합
                full_text = f"{post['title']} {post['selftext']}"
                
                # 감정 분석
                sentiment_result = self.sentiment_pipeline(full_text)[0]
                
                # 감정 점수 변환
                if sentiment_result['label'] == 'POSITIVE':
                    sentiment_score = sentiment_result['score']
                elif sentiment_result['label'] == 'NEGATIVE':
                    sentiment_score = -sentiment_result['score']
                else:
                    sentiment_score = 0.0
                
                sentiment_data.append(SentimentData(
                    source='reddit',
                    text=full_text,
                    sentiment_score=sentiment_score,
                    confidence=sentiment_result['score'],
                    language='en',
                    timestamp=datetime.fromtimestamp(post['created_utc']),
                    engagement=post['score']
                ))
            
            return sentiment_data
            
        except Exception as e:
            logger.error(f"Reddit 감정 분석 오류: {e}")
            return []
    
    def generate_sentiment_signal(self, sentiment_data: List[SentimentData], 
                                symbol: str) -> SentimentSignal:
        """감정 기반 거래 신호 생성"""
        try:
            if not sentiment_data:
                return SentimentSignal(
                    symbol=symbol,
                    sentiment_score=0.0,
                    confidence=0.0,
                    volume=0,
                    source_breakdown={},
                    timestamp=datetime.now(),
                    trading_signal='HOLD'
                )
            
            # 소스별 감정 점수 계산
            source_sentiments = {}
            total_weighted_sentiment = 0.0
            total_weight = 0.0
            
            for data in sentiment_data:
                # 가중치 계산 (참여도 기반)
                weight = data.engagement + 1
                
                if data.source not in source_sentiments:
                    source_sentiments[data.source] = {
                        'total_sentiment': 0.0,
                        'total_weight': 0.0,
                        'count': 0
                    }
                
                source_sentiments[data.source]['total_sentiment'] += data.sentiment_score * weight
                source_sentiments[data.source]['total_weight'] += weight
                source_sentiments[data.source]['count'] += 1
                
                total_weighted_sentiment += data.sentiment_score * weight
                total_weight += weight
            
            # 전체 평균 감정 점수
            if total_weight > 0:
                overall_sentiment = total_weighted_sentiment / total_weight
            else:
                overall_sentiment = 0.0
            
            # 소스별 평균 계산
            source_breakdown = {}
            for source, data in source_sentiments.items():
                if data['total_weight'] > 0:
                    source_breakdown[source] = data['total_sentiment'] / data['total_weight']
                else:
                    source_breakdown[source] = 0.0
            
            # 거래 신호 결정
            if overall_sentiment > self.sentiment_threshold:
                trading_signal = 'BUY'
            elif overall_sentiment < -self.sentiment_threshold:
                trading_signal = 'SELL'
            else:
                trading_signal = 'HOLD'
            
            # 신뢰도 계산
            confidence = min(1.0, len(sentiment_data) / 100.0)  # 데이터 양 기반
            
            return SentimentSignal(
                symbol=symbol,
                sentiment_score=overall_sentiment,
                confidence=confidence,
                volume=len(sentiment_data),
                source_breakdown=source_breakdown,
                timestamp=datetime.now(),
                trading_signal=trading_signal
            )
            
        except Exception as e:
            logger.error(f"감정 신호 생성 오류: {e}")
            return SentimentSignal(
                symbol=symbol,
                sentiment_score=0.0,
                confidence=0.0,
                volume=0,
                source_breakdown={},
                timestamp=datetime.now(),
                trading_signal='HOLD'
            )
```

### 📦 **다국어 감정 분석기**

```python
# news-event-analysis/sentiment-analysis/multi_language_sentiment_analyzer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime
import logging
from transformers import pipeline
import langdetect

logger = logging.getLogger(__name__)

@dataclass
class MultiLanguageSentiment:
    """다국어 감정 분석 결과"""
    text: str
    detected_language: str
    sentiment_score: float
    confidence: float
    translated_text: Optional[str] = None

class MultiLanguageSentimentAnalyzer:
    """다국어 감정 분석기"""
    
    def __init__(self):
        # 언어별 감정 분석 모델
        self.sentiment_models = {
            'en': pipeline("sentiment-analysis", model="cardiffnlp/twitter-roberta-base-sentiment"),
            'ko': pipeline("sentiment-analysis", model="klue/roberta-base"),
            'zh': pipeline("sentiment-analysis", model="uer/roberta-base-finetuned-jd-binary-chinese"),
            'ja': pipeline("sentiment-analysis", model="cl-tohoku/bert-base-japanese-v3")
        }
        
        self.language_mapping = {
            'en': 'english',
            'ko': 'korean', 
            'zh': 'chinese',
            'ja': 'japanese'
        }
    
    def detect_language(self, text: str) -> str:
        """언어 감지"""
        try:
            detected = langdetect.detect(text)
            return detected
        except:
            return 'en'  # 기본값
    
    def analyze_sentiment(self, text: str, target_language: str = None) -> MultiLanguageSentiment:
        """다국어 감정 분석"""
        try:
            # 언어 감지
            detected_lang = self.detect_language(text)
            
            # 분석할 언어 결정
            if target_language and target_language in self.sentiment_models:
                analysis_lang = target_language
            elif detected_lang in self.sentiment_models:
                analysis_lang = detected_lang
            else:
                analysis_lang = 'en'  # 기본값
            
            # 감정 분석 수행
            model = self.sentiment_models[analysis_lang]
            result = model(text)[0]
            
            # 감정 점수 변환
            if result['label'] in ['POSITIVE', 'positive', '긍정']:
                sentiment_score = result['score']
            elif result['label'] in ['NEGATIVE', 'negative', '부정']:
                sentiment_score = -result['score']
            else:
                sentiment_score = 0.0
            
            return MultiLanguageSentiment(
                text=text,
                detected_language=detected_lang,
                sentiment_score=sentiment_score,
                confidence=result['score']
            )
            
        except Exception as e:
            logger.error(f"다국어 감정 분석 오류: {e}")
            return MultiLanguageSentiment(
                text=text,
                detected_language='en',
                sentiment_score=0.0,
                confidence=0.0
            )
    
    def analyze_batch(self, texts: List[str]) -> List[MultiLanguageSentiment]:
        """배치 감정 분석"""
        results = []
        
        for text in texts:
            result = self.analyze_sentiment(text)
            results.append(result)
        
        return results
```

## 📊 **성과 지표**

### **목표 성과**
- **이벤트 감지 정확도**: 90% 이상
- **뉴스 분석 정확도**: 85% 이상
- **감정 분석 정확도**: 75% 이상
- **이벤트 예측 정확도**: 70% 이상
- **실시간 처리**: < 1초
- **다국어 지원**: 4개 언어

### **성능 지표**
- **이벤트 감지 속도**: < 1초
- **뉴스 분석 시간**: < 500ms
- **감정 분석 시간**: < 200ms
- **캘린더 업데이트**: < 1시간
- **알림 발송 시간**: < 100ms
- **시스템 가동률**: > 99.5%

## 🔗 **관련 문서**

- [Phase 3.5.1: 기술적 지표 분석](3.5.1_TECHNICAL_ANALYSIS.md)
- [Phase 3.5.2: 거래 전략 라이브러리](3.5.2_TRADING_STRATEGIES.md)
- [Phase 3.5.4: 온라인 학습](3.5.4_ONLINE_LEARNING.md)
- [Phase 3.5.5: 설명 가능한 AI](3.5.5_EXPLAINABLE_AI.md)

## 🔧 **새로운 모듈 구현 코드**

### 🔍 **팩트체킹 시스템**

```python
# news-event-analysis/fact-checking/fact_checker.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import logging
import re
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)

@dataclass
class FactCheckResult:
    """팩트체크 결과"""
    claim: str
    verification_score: float
    evidence_sources: List[str]
    consistency_score: float
    credibility_score: float
    final_verdict: str

class FactChecker:
    """팩트체커"""
    
    def __init__(self):
        self.trusted_sources = [
            'reuters.com', 'bloomberg.com', 'wsj.com', 
            'ft.com', 'cnbc.com', 'marketwatch.com'
        ]
        self.verification_threshold = 0.7
        
    def extract_claims(self, text: str) -> List[str]:
        """텍스트에서 주장 추출"""
        try:
            claims = []
            
            # 주장 패턴 매칭
            claim_patterns = [
                r'([A-Z][^.]*(?:증가|감소|상승|하락|변화)[^.]*\.)',
                r'([A-Z][^.]*(?:발표|공개|발표했다|공개했다)[^.]*\.)',
                r'([A-Z][^.]*(?:예상|전망|예측)[^.]*\.)',
                r'([A-Z][^.]*(?:확인|검증|입증)[^.]*\.)'
            ]
            
            for pattern in claim_patterns:
                matches = re.findall(pattern, text)
                claims.extend(matches)
            
            return list(set(claims))  # 중복 제거
            
        except Exception as e:
            logger.error(f"주장 추출 오류: {e}")
            return []
    
    def find_evidence(self, claim: str, news_sources: List[Dict]) -> List[Dict]:
        """증거 찾기"""
        try:
            evidence = []
            
            # 키워드 추출
            keywords = self._extract_keywords(claim)
            
            for source in news_sources:
                relevance_score = self._calculate_relevance(claim, source['content'], keywords)
                
                if relevance_score > 0.3:  # 임계값
                    evidence.append({
                        'source': source['source'],
                        'content': source['content'],
                        'relevance_score': relevance_score,
                        'timestamp': source['timestamp']
                    })
            
            # 관련성 점수별 정렬
            evidence.sort(key=lambda x: x['relevance_score'], reverse=True)
            
            return evidence[:5]  # 상위 5개만 반환
            
        except Exception as e:
            logger.error(f"증거 찾기 오류: {e}")
            return []
    
    def verify_claim(self, claim: str, evidence: List[Dict]) -> FactCheckResult:
        """주장 검증"""
        try:
            if not evidence:
                return FactCheckResult(
                    claim=claim,
                    verification_score=0.0,
                    evidence_sources=[],
                    consistency_score=0.0,
                    credibility_score=0.0,
                    final_verdict='insufficient_evidence'
                )
            
            # 검증 점수 계산
            verification_score = self._calculate_verification_score(claim, evidence)
            
            # 일관성 점수 계산
            consistency_score = self._calculate_consistency_score(evidence)
            
            # 신뢰도 점수 계산
            credibility_score = self._calculate_credibility_score(evidence)
            
            # 최종 판정
            final_verdict = self._determine_verdict(verification_score, consistency_score, credibility_score)
            
            return FactCheckResult(
                claim=claim,
                verification_score=verification_score,
                evidence_sources=[e['source'] for e in evidence],
                consistency_score=consistency_score,
                credibility_score=credibility_score,
                final_verdict=final_verdict
            )
            
        except Exception as e:
            logger.error(f"주장 검증 오류: {e}")
            return FactCheckResult(
                claim=claim,
                verification_score=0.0,
                evidence_sources=[],
                consistency_score=0.0,
                credibility_score=0.0,
                final_verdict='error'
            )
    
    def _extract_keywords(self, text: str) -> List[str]:
        """키워드 추출"""
        # 간단한 키워드 추출 (실제로는 NLP 라이브러리 사용)
        words = text.split()
        keywords = [word for word in words if len(word) > 2]
        return keywords[:10]  # 상위 10개
    
    def _calculate_relevance(self, claim: str, content: str, keywords: List[str]) -> float:
        """관련성 점수 계산"""
        try:
            # 텍스트 유사도
            similarity = SequenceMatcher(None, claim, content).ratio()
            
            # 키워드 매칭
            keyword_matches = sum(1 for keyword in keywords if keyword.lower() in content.lower())
            keyword_score = keyword_matches / len(keywords) if keywords else 0
            
            # 종합 점수
            relevance_score = 0.6 * similarity + 0.4 * keyword_score
            
            return min(1.0, relevance_score)
            
        except Exception as e:
            logger.error(f"관련성 점수 계산 오류: {e}")
            return 0.0
    
    def _calculate_verification_score(self, claim: str, evidence: List[Dict]) -> float:
        """검증 점수 계산"""
        try:
            if not evidence:
                return 0.0
            
            # 증거의 평균 관련성 점수
            avg_relevance = np.mean([e['relevance_score'] for e in evidence])
            
            # 신뢰할 수 있는 소스의 비율
            trusted_count = sum(1 for e in evidence if any(source in e['source'] for source in self.trusted_sources))
            trusted_ratio = trusted_count / len(evidence)
            
            # 검증 점수
            verification_score = 0.7 * avg_relevance + 0.3 * trusted_ratio
            
            return min(1.0, verification_score)
            
        except Exception as e:
            logger.error(f"검증 점수 계산 오류: {e}")
            return 0.0
    
    def _calculate_consistency_score(self, evidence: List[Dict]) -> float:
        """일관성 점수 계산"""
        try:
            if len(evidence) < 2:
                return 1.0
            
            # 증거 간 유사성 계산
            similarities = []
            for i in range(len(evidence)):
                for j in range(i + 1, len(evidence)):
                    similarity = SequenceMatcher(None, evidence[i]['content'], evidence[j]['content']).ratio()
                    similarities.append(similarity)
            
            if similarities:
                consistency_score = np.mean(similarities)
            else:
                consistency_score = 1.0
            
            return consistency_score
            
        except Exception as e:
            logger.error(f"일관성 점수 계산 오류: {e}")
            return 0.0
    
    def _calculate_credibility_score(self, evidence: List[Dict]) -> float:
        """신뢰도 점수 계산"""
        try:
            if not evidence:
                return 0.0
            
            credibility_scores = []
            
            for e in evidence:
                # 출처 신뢰도
                source_credibility = 1.0 if any(source in e['source'] for source in self.trusted_sources) else 0.5
                
                # 관련성 점수
                relevance_score = e['relevance_score']
                
                # 종합 신뢰도
                credibility = 0.6 * source_credibility + 0.4 * relevance_score
                credibility_scores.append(credibility)
            
            return np.mean(credibility_scores)
            
        except Exception as e:
            logger.error(f"신뢰도 점수 계산 오류: {e}")
            return 0.0
    
    def _determine_verdict(self, verification_score: float, consistency_score: float, credibility_score: float) -> str:
        """최종 판정"""
        try:
            # 종합 점수
            overall_score = (verification_score + consistency_score + credibility_score) / 3
            
            if overall_score >= self.verification_threshold:
                return 'verified'
            elif overall_score >= 0.5:
                return 'partially_verified'
            elif overall_score >= 0.3:
                return 'unverified'
            else:
                return 'false'
                
        except Exception as e:
            logger.error(f"최종 판정 오류: {e}")
            return 'error'
```

### 📰 **뉴스 신뢰도 평가 시스템**

```python
# news-event-analysis/news-reliability/news_reliability_scorer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import logging
import re

logger = logging.getLogger(__name__)

@dataclass
class ReliabilityScore:
    """신뢰도 점수"""
    source_reliability: float
    content_consistency: float
    verification_capability: float
    overall_reliability: float
    confidence_level: str

class NewsReliabilityScorer:
    """뉴스 신뢰도 평가기"""
    
    def __init__(self):
        self.trusted_sources = {
            'reuters.com': 0.95,
            'bloomberg.com': 0.93,
            'wsj.com': 0.92,
            'ft.com': 0.91,
            'cnbc.com': 0.88,
            'marketwatch.com': 0.87
        }
        self.medium_sources = {
            'yahoo.com': 0.75,
            'cnn.com': 0.72,
            'bbc.com': 0.78
        }
        
    def evaluate_source_reliability(self, source_url: str, source_history: Dict) -> float:
        """출처 신뢰도 평가"""
        try:
            # 기본 신뢰도 점수
            if source_url in self.trusted_sources:
                base_score = self.trusted_sources[source_url]
            elif source_url in self.medium_sources:
                base_score = self.medium_sources[source_url]
            else:
                base_score = 0.5  # 기본값
            
            # 히스토리 기반 조정
            if source_history:
                accuracy_rate = source_history.get('accuracy_rate', 0.5)
                consistency_rate = source_history.get('consistency_rate', 0.5)
                
                # 조정된 점수
                adjusted_score = base_score * 0.6 + accuracy_rate * 0.25 + consistency_rate * 0.15
            else:
                adjusted_score = base_score
            
            return min(1.0, adjusted_score)
            
        except Exception as e:
            logger.error(f"출처 신뢰도 평가 오류: {e}")
            return 0.5
    
    def evaluate_content_consistency(self, content: str, similar_articles: List[Dict]) -> float:
        """내용 일관성 평가"""
        try:
            if not similar_articles:
                return 0.5  # 비교 대상이 없으면 중간값
            
            consistency_scores = []
            
            for article in similar_articles:
                # 키워드 일치도
                content_keywords = self._extract_keywords(content)
                article_keywords = self._extract_keywords(article['content'])
                
                keyword_overlap = len(set(content_keywords) & set(article_keywords))
                keyword_consistency = keyword_overlap / max(len(content_keywords), len(article_keywords)) if content_keywords and article_keywords else 0
                
                # 감정 일관성
                sentiment_consistency = 1.0 - abs(content.get('sentiment', 0) - article.get('sentiment', 0))
                
                # 종합 일관성
                consistency = (keyword_consistency + sentiment_consistency) / 2
                consistency_scores.append(consistency)
            
            return np.mean(consistency_scores)
            
        except Exception as e:
            logger.error(f"내용 일관성 평가 오류: {e}")
            return 0.5
    
    def evaluate_verification_capability(self, content: str, metadata: Dict) -> float:
        """검증 가능성 평가"""
        try:
            verification_score = 0.5  # 기본값
            
            # 인용 및 출처
            if metadata.get('citations'):
                verification_score += 0.2
            
            # 링크 및 참조
            if metadata.get('references'):
                verification_score += 0.15
            
            # 작성자 정보
            if metadata.get('author') and metadata.get('author_credentials'):
                verification_score += 0.1
            
            # 날짜 및 시간
            if metadata.get('timestamp'):
                verification_score += 0.05
            
            # 수치 및 데이터
            if self._has_numerical_data(content):
                verification_score += 0.1
            
            return min(1.0, verification_score)
            
        except Exception as e:
            logger.error(f"검증 가능성 평가 오류: {e}")
            return 0.5
    
    def calculate_overall_reliability(self, source_reliability: float, 
                                    content_consistency: float, 
                                    verification_capability: float) -> ReliabilityScore:
        """전체 신뢰도 계산"""
        try:
            # 가중 평균
            overall_reliability = (
                source_reliability * 0.4 +
                content_consistency * 0.35 +
                verification_capability * 0.25
            )
            
            # 신뢰도 레벨 결정
            if overall_reliability >= 0.8:
                confidence_level = 'high'
            elif overall_reliability >= 0.6:
                confidence_level = 'medium'
            elif overall_reliability >= 0.4:
                confidence_level = 'low'
            else:
                confidence_level = 'very_low'
            
            return ReliabilityScore(
                source_reliability=source_reliability,
                content_consistency=content_consistency,
                verification_capability=verification_capability,
                overall_reliability=overall_reliability,
                confidence_level=confidence_level
            )
            
        except Exception as e:
            logger.error(f"전체 신뢰도 계산 오류: {e}")
            return ReliabilityScore(0.5, 0.5, 0.5, 0.5, 'low')
    
    def _extract_keywords(self, text: str) -> List[str]:
        """키워드 추출"""
        # 간단한 키워드 추출
        words = re.findall(r'\b\w+\b', text.lower())
        # 불용어 제거
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}
        keywords = [word for word in words if word not in stop_words and len(word) > 3]
        return keywords[:20]  # 상위 20개
    
    def _has_numerical_data(self, content: str) -> bool:
        """수치 데이터 포함 여부"""
        # 숫자 패턴 찾기
        number_patterns = [
            r'\d+\.\d+%',  # 퍼센트
            r'\$\d+',      # 달러
            r'\d+\.\d+',   # 소수점
            r'\d+',        # 정수
        ]
        
        for pattern in number_patterns:
            if re.search(pattern, content):
                return True
        
        return False
```

### 📋 **레귤레이션 뉴스 파싱 시스템**

```python
# news-event-analysis/regulatory-news-parsing/regulatory_news_parser.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from datetime import datetime
import logging
import re

logger = logging.getLogger(__name__)

@dataclass
class RegulatoryEvent:
    """규제 이벤트"""
    event_type: str
    affected_assets: List[str]
    impact_level: str
    effective_date: datetime
    description: str
    compliance_requirements: List[str]

class RegulatoryNewsParser:
    """레귤레이션 뉴스 파서"""
    
    def __init__(self):
        self.regulatory_keywords = {
            'policy': ['정책', 'policy', 'regulation', '규제', '법안', 'bill'],
            'enforcement': ['집행', 'enforcement', '단속', 'crackdown', '규제강화'],
            'compliance': ['준수', 'compliance', '의무', 'obligation', '요구사항'],
            'penalty': ['벌금', 'penalty', '제재', 'sanction', '징계'],
            'approval': ['승인', 'approval', '허가', 'permit', '인가'],
            'ban': ['금지', 'ban', 'prohibition', '제한', 'restriction']
        }
        
        self.impact_levels = {
            'high': ['금지', 'ban', 'prohibition', '중단', 'suspension'],
            'medium': ['제한', 'restriction', '규제', 'regulation', '강화'],
            'low': ['가이드라인', 'guideline', '권고', 'recommendation']
        }
    
    def parse_regulatory_news(self, news_content: str, metadata: Dict) -> Optional[RegulatoryEvent]:
        """규제 뉴스 파싱"""
        try:
            # 규제 키워드 감지
            detected_keywords = self._detect_regulatory_keywords(news_content)
            
            if not detected_keywords:
                return None
            
            # 이벤트 타입 결정
            event_type = self._determine_event_type(detected_keywords)
            
            # 영향받는 자산 추출
            affected_assets = self._extract_affected_assets(news_content)
            
            # 영향 수준 평가
            impact_level = self._assess_impact_level(news_content, detected_keywords)
            
            # 발효일 추출
            effective_date = self._extract_effective_date(news_content, metadata)
            
            # 설명 생성
            description = self._generate_description(news_content, detected_keywords)
            
            # 준수 요구사항 추출
            compliance_requirements = self._extract_compliance_requirements(news_content)
            
            return RegulatoryEvent(
                event_type=event_type,
                affected_assets=affected_assets,
                impact_level=impact_level,
                effective_date=effective_date,
                description=description,
                compliance_requirements=compliance_requirements
            )
            
        except Exception as e:
            logger.error(f"규제 뉴스 파싱 오류: {e}")
            return None
    
    def _detect_regulatory_keywords(self, content: str) -> Dict[str, List[str]]:
        """규제 키워드 감지"""
        detected_keywords = {}
        
        for category, keywords in self.regulatory_keywords.items():
            found_keywords = []
            for keyword in keywords:
                if keyword.lower() in content.lower():
                    found_keywords.append(keyword)
            
            if found_keywords:
                detected_keywords[category] = found_keywords
        
        return detected_keywords
    
    def _determine_event_type(self, keywords: Dict[str, List[str]]) -> str:
        """이벤트 타입 결정"""
        if 'policy' in keywords:
            return 'policy_change'
        elif 'enforcement' in keywords:
            return 'enforcement_action'
        elif 'compliance' in keywords:
            return 'compliance_requirement'
        elif 'penalty' in keywords:
            return 'penalty_announcement'
        elif 'approval' in keywords:
            return 'approval_granted'
        elif 'ban' in keywords:
            return 'ban_announcement'
        else:
            return 'regulatory_update'
    
    def _extract_affected_assets(self, content: str) -> List[str]:
        """영향받는 자산 추출"""
        # 자산 키워드 패턴
        asset_patterns = [
            r'([A-Z]{2,5})',  # 주식 심볼
            r'([가-힣]+주)',   # 한국 주식
            r'(crypto|bitcoin|ethereum)',  # 암호화폐
            r'(금융|은행|보험|증권)',  # 금융 섹터
        ]
        
        affected_assets = []
        
        for pattern in asset_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            affected_assets.extend(matches)
        
        return list(set(affected_assets))  # 중복 제거
    
    def _assess_impact_level(self, content: str, keywords: Dict[str, List[str]]) -> str:
        """영향 수준 평가"""
        impact_score = 0.0
        
        # 키워드 기반 점수
        for category, found_keywords in keywords.items():
            if category in ['ban', 'enforcement']:
                impact_score += 0.4
            elif category in ['policy', 'compliance']:
                impact_score += 0.3
            elif category in ['penalty']:
                impact_score += 0.2
            else:
                impact_score += 0.1
        
        # 영향 수준 키워드 확인
        for level, level_keywords in self.impact_levels.items():
            for keyword in level_keywords:
                if keyword.lower() in content.lower():
                    if level == 'high':
                        impact_score += 0.3
                    elif level == 'medium':
                        impact_score += 0.2
                    else:
                        impact_score += 0.1
        
        # 영향 수준 결정
        if impact_score >= 0.6:
            return 'high'
        elif impact_score >= 0.3:
            return 'medium'
        else:
            return 'low'
    
    def _extract_effective_date(self, content: str, metadata: Dict) -> datetime:
        """발효일 추출"""
        try:
            # 메타데이터에서 날짜 추출
            if metadata.get('published_date'):
                return metadata['published_date']
            
            # 텍스트에서 날짜 패턴 찾기
            date_patterns = [
                r'(\d{4}년\s*\d{1,2}월\s*\d{1,2}일)',
                r'(\d{1,2}/\d{1,2}/\d{4})',
                r'(\d{4}-\d{2}-\d{2})',
                r'(내년|내월|다음주|오늘|내일)'
            ]
            
            for pattern in date_patterns:
                match = re.search(pattern, content)
                if match:
                    # 날짜 파싱 로직 (간단한 예시)
                    return datetime.now()  # 실제로는 파싱된 날짜 반환
            
            # 기본값
            return datetime.now()
            
        except Exception as e:
            logger.error(f"발효일 추출 오류: {e}")
            return datetime.now()
    
    def _generate_description(self, content: str, keywords: Dict[str, List[str]]) -> str:
        """설명 생성"""
        try:
            # 핵심 문장 추출
            sentences = content.split('.')
            
            # 키워드가 포함된 문장 찾기
            relevant_sentences = []
            for sentence in sentences:
                for category, found_keywords in keywords.items():
                    if any(keyword.lower() in sentence.lower() for keyword in found_keywords):
                        relevant_sentences.append(sentence.strip())
                        break
            
            if relevant_sentences:
                return '. '.join(relevant_sentences[:3])  # 상위 3개 문장
            else:
                return content[:200] + '...'  # 처음 200자
                
        except Exception as e:
            logger.error(f"설명 생성 오류: {e}")
            return content[:200] + '...'
    
    def _extract_compliance_requirements(self, content: str) -> List[str]:
        """준수 요구사항 추출"""
        requirements = []
        
        # 요구사항 패턴
        requirement_patterns = [
            r'([가-힣\s]+해야\s+한다)',
            r'([가-힣\s]+필요하다)',
            r'([가-힣\s]+의무가\s+있다)',
            r'(must\s+[a-zA-Z\s]+)',
            r'(required\s+to\s+[a-zA-Z\s]+)',
            r'(obligated\s+to\s+[a-zA-Z\s]+)'
        ]
        
        for pattern in requirement_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            requirements.extend(matches)
        
        return list(set(requirements))  # 중복 제거
```

### 🔗 **API 연동 시스템**

```python
# news-event-analysis/api-integration/api_integration_manager.py
import asyncio
import aiohttp
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from datetime import datetime, timedelta
import logging
import json
import os

logger = logging.getLogger(__name__)

@dataclass
class NewsArticle:
    """뉴스 기사"""
    title: str
    content: str
    source: str
    url: str
    published_date: datetime
    sentiment_score: float
    importance_score: float

class APIIntegrationManager:
    """API 연동 관리자"""
    
    def __init__(self):
        self.api_keys = {
            'news_api': os.getenv('NEWS_API_KEY', ''),
            'twitter_api': os.getenv('TWITTER_API_KEY', ''),
            'reddit_api': os.getenv('REDDIT_API_KEY', ''),
            'alpha_vantage': os.getenv('ALPHA_VANTAGE_KEY', '')
        }
        
        self.rate_limits = {
            'news_api': {'requests_per_minute': 100, 'last_request': datetime.now()},
            'twitter_api': {'requests_per_minute': 300, 'last_request': datetime.now()},
            'reddit_api': {'requests_per_minute': 60, 'last_request': datetime.now()}
        }
    
    async def fetch_news_articles(self, keywords: List[str], 
                                sources: List[str] = None,
                                max_articles: int = 50) -> List[NewsArticle]:
        """뉴스 기사 가져오기"""
        try:
            articles = []
            
            # News API 사용
            if self.api_keys['news_api']:
                news_articles = await self._fetch_from_news_api(keywords, sources, max_articles)
                articles.extend(news_articles)
            
            # 다른 뉴스 소스들
            other_articles = await self._fetch_from_other_sources(keywords, max_articles)
            articles.extend(other_articles)
            
            return articles[:max_articles]
            
        except Exception as e:
            logger.error(f"뉴스 기사 가져오기 오류: {e}")
            return []
    
    async def fetch_social_media_posts(self, keywords: List[str], 
                                     platforms: List[str] = None,
                                     max_posts: int = 100) -> List[Dict]:
        """소셜 미디어 포스트 가져오기"""
        try:
            posts = []
            
            if not platforms:
                platforms = ['twitter', 'reddit']
            
            for platform in platforms:
                if platform == 'twitter' and self.api_keys['twitter_api']:
                    twitter_posts = await self._fetch_from_twitter(keywords, max_posts // len(platforms))
                    posts.extend(twitter_posts)
                
                elif platform == 'reddit' and self.api_keys['reddit_api']:
                    reddit_posts = await self._fetch_from_reddit(keywords, max_posts // len(platforms))
                    posts.extend(reddit_posts)
            
            return posts
            
        except Exception as e:
            logger.error(f"소셜 미디어 포스트 가져오기 오류: {e}")
            return []
    
    async def fetch_economic_calendar(self, start_date: datetime, 
                                    end_date: datetime) -> List[Dict]:
        """경제 캘린더 가져오기"""
        try:
            calendar_events = []
            
            # Alpha Vantage API 사용
            if self.api_keys['alpha_vantage']:
                events = await self._fetch_from_alpha_vantage(start_date, end_date)
                calendar_events.extend(events)
            
            # 다른 캘린더 API들
            other_events = await self._fetch_from_other_calendars(start_date, end_date)
            calendar_events.extend(other_events)
            
            return calendar_events
            
        except Exception as e:
            logger.error(f"경제 캘린더 가져오기 오류: {e}")
            return []
    
    async def _fetch_from_news_api(self, keywords: List[str], 
                                  sources: List[str], 
                                  max_articles: int) -> List[NewsArticle]:
        """News API에서 기사 가져오기"""
        try:
            # Rate limiting 체크
            if not self._check_rate_limit('news_api'):
                return []
            
            url = "https://newsapi.org/v2/everything"
            params = {
                'q': ' OR '.join(keywords),
                'language': 'en',
                'sortBy': 'publishedAt',
                'pageSize': min(max_articles, 100),
                'apiKey': self.api_keys['news_api']
            }
            
            if sources:
                params['domains'] = ','.join(sources)
            
            async with aiohttp.ClientSession() as session:
                async with session.get(url, params=params) as response:
                    if response.status == 200:
                        data = await response.json()
                        
                        articles = []
                        for article in data.get('articles', []):
                            news_article = NewsArticle(
                                title=article.get('title', ''),
                                content=article.get('description', ''),
                                source=article.get('source', {}).get('name', ''),
                                url=article.get('url', ''),
                                published_date=datetime.fromisoformat(article.get('publishedAt', '').replace('Z', '+00:00')),
                                sentiment_score=0.0,  # 나중에 계산
                                importance_score=0.0   # 나중에 계산
                            )
                            articles.append(news_article)
                        
                        return articles
                    else:
                        logger.error(f"News API 오류: {response.status}")
                        return []
            
        except Exception as e:
            logger.error(f"News API 가져오기 오류: {e}")
            return []
    
    async def _fetch_from_twitter(self, keywords: List[str], max_posts: int) -> List[Dict]:
        """Twitter에서 포스트 가져오기"""
        try:
            # Rate limiting 체크
            if not self._check_rate_limit('twitter_api'):
                return []
            
            # Twitter API v2 사용 (실제 구현에서는 적절한 라이브러리 사용)
            posts = []
            
            # 간단한 시뮬레이션
            for keyword in keywords:
                # 실제로는 Twitter API 호출
                posts.append({
                    'platform': 'twitter',
                    'content': f'Simulated tweet about {keyword}',
                    'author': 'user123',
                    'timestamp': datetime.now(),
                    'sentiment_score': 0.0
                })
            
            return posts[:max_posts]
            
        except Exception as e:
            logger.error(f"Twitter 가져오기 오류: {e}")
            return []
    
    async def _fetch_from_reddit(self, keywords: List[str], max_posts: int) -> List[Dict]:
        """Reddit에서 포스트 가져오기"""
        try:
            # Rate limiting 체크
            if not self._check_rate_limit('reddit_api'):
                return []
            
            posts = []
            
            # 간단한 시뮬레이션
            for keyword in keywords:
                # 실제로는 Reddit API 호출
                posts.append({
                    'platform': 'reddit',
                    'content': f'Simulated Reddit post about {keyword}',
                    'author': 'redditor123',
                    'timestamp': datetime.now(),
                    'sentiment_score': 0.0
                })
            
            return posts[:max_posts]
            
        except Exception as e:
            logger.error(f"Reddit 가져오기 오류: {e}")
            return []
    
    def _check_rate_limit(self, api_name: str) -> bool:
        """Rate limiting 체크"""
        try:
            rate_limit = self.rate_limits[api_name]
            time_since_last = datetime.now() - rate_limit['last_request']
            
            if time_since_last.total_seconds() < 60 / rate_limit['requests_per_minute']:
                return False
            
            rate_limit['last_request'] = datetime.now()
            return True
            
        except Exception as e:
            logger.error(f"Rate limiting 체크 오류: {e}")
            return True
    
    async def _fetch_from_other_sources(self, keywords: List[str], max_articles: int) -> List[NewsArticle]:
        """다른 뉴스 소스에서 가져오기"""
        # 실제 구현에서는 다양한 뉴스 소스 API 연동
        return []
    
    async def _fetch_from_alpha_vantage(self, start_date: datetime, end_date: datetime) -> List[Dict]:
        """Alpha Vantage에서 경제 이벤트 가져오기"""
        # 실제 구현에서는 Alpha Vantage API 사용
        return []
    
    async def _fetch_from_other_calendars(self, start_date: datetime, end_date: datetime) -> List[Dict]:
        """다른 캘린더 API에서 가져오기"""
        # 실제 구현에서는 다양한 캘린더 API 연동
        return []
```

---

**마지막 업데이트**: 2025-01-26  
**프로젝트 상태**: 설계 완료, 개발 준비  
**다음 단계**: 온라인 학습 시스템 구현 