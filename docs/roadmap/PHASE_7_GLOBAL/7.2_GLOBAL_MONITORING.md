# 🌍 Phase 7.2: 글로벌 모니터링 시스템

## 📋 **개요**

### 🎯 **목표**
- **분산 모니터링**: 다중 리전 실시간 모니터링 및 알림
- **성능 분석**: 글로벌 성능 지표 수집 및 분석
- **장애 감지**: 실시간 장애 감지 및 자동 복구
- **용량 계획**: 리소스 사용량 예측 및 계획
- **보안 모니터링**: 글로벌 보안 이벤트 모니터링

### 📊 **성능 목표**
- **모니터링 지연**: < 5초 글로벌 이벤트 감지
- **알림 전송**: < 10초 중요 알림 전송
- **데이터 수집**: < 1초 메트릭 수집
- **대시보드 업데이트**: < 30초 실시간 업데이트
- **장애 복구**: < 5분 자동 복구

## 🏗️ **글로벌 모니터링 시스템 아키텍처**

### 📁 **글로벌 모니터링 시스템 구조**
```
global-monitoring/
├── distributed-monitoring/           # 분산 모니터링
│   ├── regional-agents/              # 지역별 에이전트
│   ├── central-collector/            # 중앙 수집기
│   ├── data-aggregation/             # 데이터 집계
│   └── cross-region-sync/            # 리전 간 동기화
├── performance-analysis/             # 성능 분석
│   ├── metrics-collection/           # 메트릭 수집
│   ├── performance-dashboard/        # 성능 대시보드
│   ├── trend-analysis/               # 트렌드 분석
│   └── capacity-planning/            # 용량 계획
├── incident-management/              # 장애 관리
│   ├── incident-detection/           # 장애 감지
│   ├── alert-management/             # 알림 관리
│   ├── auto-recovery/                # 자동 복구
│   └── escalation-procedures/        # 에스컬레이션 절차
└── security-monitoring/              # 보안 모니터링
    ├── threat-detection/             # 위협 감지
    ├── security-events/              # 보안 이벤트
    ├── compliance-monitoring/        # 규정 준수 모니터링
    └── audit-trails/                 # 감사 추적
```

## 🔧 **분산 모니터링 시스템**

### 📦 **지역별 에이전트 및 중앙 수집기**

```python
# global-monitoring/distributed-monitoring/global_monitoring_manager.py
import asyncio
import time
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import threading
from collections import defaultdict, deque
import hashlib
import aiohttp
import websockets
import prometheus_client
from prometheus_client import Counter, Gauge, Histogram, Summary

logger = logging.getLogger(__name__)

@dataclass
class MonitoringRegion:
    """모니터링 리전"""
    region_id: str
    name: str
    status: str  # 'active', 'maintenance', 'failed'
    agent_count: int
    service_count: int
    last_heartbeat: datetime
    performance_score: float
    created_at: datetime

@dataclass
class MonitoringAgent:
    """모니터링 에이전트"""
    agent_id: str
    region_id: str
    hostname: str
    ip_address: str
    agent_type: str  # 'system', 'application', 'database', 'network'
    status: str  # 'online', 'offline', 'error'
    last_heartbeat: datetime
    metrics_count: int
    alerts_count: int

@dataclass
class MonitoringMetric:
    """모니터링 메트릭"""
    metric_id: str
    agent_id: str
    region_id: str
    metric_name: str
    metric_value: float
    metric_unit: str
    metric_type: str  # 'counter', 'gauge', 'histogram', 'summary'
    timestamp: datetime
    labels: Dict[str, str]

@dataclass
class MonitoringAlert:
    """모니터링 알림"""
    alert_id: str
    region_id: str
    agent_id: str
    alert_type: str  # 'critical', 'warning', 'info'
    alert_message: str
    metric_name: str
    metric_value: float
    threshold: float
    status: str  # 'active', 'acknowledged', 'resolved'
    created_at: datetime
    resolved_at: Optional[datetime]

class GlobalMonitoringManager:
    """글로벌 모니터링 관리자"""
    
    def __init__(self):
        self.monitoring_regions = self._initialize_monitoring_regions()
        self.monitoring_agents = {}
        self.monitoring_metrics = {}
        self.monitoring_alerts = {}
        self.performance_metrics = MonitoringMetrics()
        
        # 스레드 안전
        self.lock = threading.Lock()
        
        # 모니터링 스레드
        self.monitoring_thread = None
        self.monitoring_active = False
        
        # Prometheus 메트릭
        self.prometheus_metrics = self._initialize_prometheus_metrics()
        
        logger.info("Global monitoring manager initialized")
    
    def _initialize_monitoring_regions(self) -> Dict[str, MonitoringRegion]:
        """모니터링 리전 초기화"""
        regions = {
            'us-east-1': MonitoringRegion(
                region_id='us-east-1',
                name='US East Monitoring Region',
                status='active',
                agent_count=0,
                service_count=0,
                last_heartbeat=datetime.now(),
                performance_score=1.0,
                created_at=datetime.now()
            ),
            'us-west-2': MonitoringRegion(
                region_id='us-west-2',
                name='US West Monitoring Region',
                status='active',
                agent_count=0,
                service_count=0,
                last_heartbeat=datetime.now(),
                performance_score=1.0,
                created_at=datetime.now()
            ),
            'eu-west-1': MonitoringRegion(
                region_id='eu-west-1',
                name='Europe Monitoring Region',
                status='active',
                agent_count=0,
                service_count=0,
                last_heartbeat=datetime.now(),
                performance_score=1.0,
                created_at=datetime.now()
            ),
            'ap-northeast-1': MonitoringRegion(
                region_id='ap-northeast-1',
                name='Asia Pacific Monitoring Region',
                status='active',
                agent_count=0,
                service_count=0,
                last_heartbeat=datetime.now(),
                performance_score=1.0,
                created_at=datetime.now()
            )
        }
        
        return regions
    
    def _initialize_prometheus_metrics(self) -> Dict[str, Any]:
        """Prometheus 메트릭 초기화"""
        metrics = {
            'total_agents': Gauge('total_agents', 'Total number of monitoring agents'),
            'active_alerts': Gauge('active_alerts', 'Number of active alerts'),
            'metrics_collected': Counter('metrics_collected', 'Total metrics collected'),
            'alert_response_time': Histogram('alert_response_time', 'Alert response time in seconds'),
            'region_health_score': Gauge('region_health_score', 'Region health score', ['region_id']),
            'agent_uptime': Gauge('agent_uptime', 'Agent uptime percentage', ['agent_id', 'region_id'])
        }
        
        return metrics
    
    async def start_monitoring_manager(self):
        """모니터링 관리자 시작"""
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop)
        self.monitoring_thread.start()
        logger.info("Global monitoring manager started")
    
    async def stop_monitoring_manager(self):
        """모니터링 관리자 중지"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join()
        logger.info("Global monitoring manager stopped")
    
    def _monitoring_loop(self):
        """모니터링 루프"""
        while self.monitoring_active:
            try:
                # 에이전트 상태 확인
                self._check_agent_health()
                
                # 리전 상태 확인
                self._check_region_health()
                
                # 알림 처리
                self._process_alerts()
                
                # 성능 측정
                self.performance_metrics.record_monitoring_cycle()
                
                time.sleep(5)  # 5초마다 실행
                
            except Exception as e:
                logger.error(f"Error in monitoring loop: {e}")
                time.sleep(10)
    
    def _check_agent_health(self):
        """에이전트 상태 확인"""
        current_time = datetime.now()
        
        for agent_id, agent in self.monitoring_agents.items():
            # 하트비트 확인
            if (current_time - agent.last_heartbeat).total_seconds() > 60:
                agent.status = 'offline'
                self._create_alert(
                    agent.region_id, agent_id, 'warning',
                    f"Agent {agent_id} is offline",
                    'agent_uptime', 0.0, 0.5
                )
            else:
                agent.status = 'online'
                
                # Prometheus 메트릭 업데이트
                self.prometheus_metrics['agent_uptime'].labels(
                    agent_id=agent_id, region_id=agent.region_id
                ).set(1.0)
    
    def _check_region_health(self):
        """리전 상태 확인"""
        for region_id, region in self.monitoring_regions.items():
            # 리전 내 에이전트 수 계산
            region_agents = [
                agent for agent in self.monitoring_agents.values()
                if agent.region_id == region_id
            ]
            
            region.agent_count = len(region_agents)
            region.service_count = len(set(agent.agent_type for agent in region_agents))
            
            # 성능 점수 계산
            online_agents = [agent for agent in region_agents if agent.status == 'online']
            if region_agents:
                region.performance_score = len(online_agents) / len(region_agents)
            else:
                region.performance_score = 0.0
            
            # Prometheus 메트릭 업데이트
            self.prometheus_metrics['region_health_score'].labels(
                region_id=region_id
            ).set(region.performance_score)
            
            # 리전 상태 업데이트
            if region.performance_score < 0.5:
                region.status = 'failed'
            elif region.performance_score < 0.8:
                region.status = 'maintenance'
            else:
                region.status = 'active'
    
    def _process_alerts(self):
        """알림 처리"""
        active_alerts = [
            alert for alert in self.monitoring_alerts.values()
            if alert.status == 'active'
        ]
        
        # Prometheus 메트릭 업데이트
        self.prometheus_metrics['active_alerts'].set(len(active_alerts))
        
        for alert in active_alerts:
            # 알림 에스컬레이션 확인
            if (datetime.now() - alert.created_at).total_seconds() > 300:  # 5분
                self._escalate_alert(alert)
    
    def _escalate_alert(self, alert: MonitoringAlert):
        """알림 에스컬레이션"""
        logger.warning(f"Alert escalated: {alert.alert_id} - {alert.alert_message}")
        # 실제 구현에서는 관리자에게 알림 발송
    
    async def register_agent(self, region_id: str, hostname: str, 
                           ip_address: str, agent_type: str) -> str:
        """에이전트 등록"""
        agent_id = f"agent_{region_id}_{hostname}_{int(time.time())}"
        
        agent = MonitoringAgent(
            agent_id=agent_id,
            region_id=region_id,
            hostname=hostname,
            ip_address=ip_address,
            agent_type=agent_type,
            status='online',
            last_heartbeat=datetime.now(),
            metrics_count=0,
            alerts_count=0
        )
        
        with self.lock:
            self.monitoring_agents[agent_id] = agent
        
        # Prometheus 메트릭 업데이트
        self.prometheus_metrics['total_agents'].inc()
        
        logger.info(f"Agent registered: {agent_id}")
        return agent_id
    
    async def unregister_agent(self, agent_id: str):
        """에이전트 등록 해제"""
        with self.lock:
            if agent_id in self.monitoring_agents:
                del self.monitoring_agents[agent_id]
        
        # Prometheus 메트릭 업데이트
        self.prometheus_metrics['total_agents'].dec()
        
        logger.info(f"Agent unregistered: {agent_id}")
    
    async def send_heartbeat(self, agent_id: str):
        """하트비트 전송"""
        with self.lock:
            if agent_id in self.monitoring_agents:
                agent = self.monitoring_agents[agent_id]
                agent.last_heartbeat = datetime.now()
                agent.status = 'online'
    
    async def collect_metric(self, agent_id: str, metric_name: str, 
                           metric_value: float, metric_unit: str = '', 
                           metric_type: str = 'gauge', labels: Dict[str, str] = None) -> str:
        """메트릭 수집"""
        metric_id = f"metric_{agent_id}_{metric_name}_{int(time.time() * 1000)}"
        
        agent = self.monitoring_agents.get(agent_id)
        if not agent:
            raise Exception(f"Agent not found: {agent_id}")
        
        metric = MonitoringMetric(
            metric_id=metric_id,
            agent_id=agent_id,
            region_id=agent.region_id,
            metric_name=metric_name,
            metric_value=metric_value,
            metric_unit=metric_unit,
            metric_type=metric_type,
            timestamp=datetime.now(),
            labels=labels or {}
        )
        
        with self.lock:
            self.monitoring_metrics[metric_id] = metric
            agent.metrics_count += 1
        
        # Prometheus 메트릭 업데이트
        self.prometheus_metrics['metrics_collected'].inc()
        
        # 임계값 확인 및 알림 생성
        await self._check_thresholds(metric)
        
        logger.debug(f"Metric collected: {metric_id} = {metric_value}")
        return metric_id
    
    async def _check_thresholds(self, metric: MonitoringMetric):
        """임계값 확인"""
        # 임계값 정의 (실제 구현에서는 설정에서 로드)
        thresholds = {
            'cpu_usage': 80.0,
            'memory_usage': 85.0,
            'disk_usage': 90.0,
            'response_time': 1000.0,  # ms
            'error_rate': 5.0  # %
        }
        
        threshold = thresholds.get(metric.metric_name)
        if threshold and metric.metric_value > threshold:
            await self._create_alert(
                metric.region_id, metric.agent_id, 'warning',
                f"{metric.metric_name} exceeded threshold: {metric.metric_value} > {threshold}",
                metric.metric_name, metric.metric_value, threshold
            )
    
    async def _create_alert(self, region_id: str, agent_id: str, alert_type: str,
                          alert_message: str, metric_name: str, metric_value: float, 
                          threshold: float) -> str:
        """알림 생성"""
        alert_id = f"alert_{region_id}_{agent_id}_{int(time.time() * 1000)}"
        
        alert = MonitoringAlert(
            alert_id=alert_id,
            region_id=region_id,
            agent_id=agent_id,
            alert_type=alert_type,
            alert_message=alert_message,
            metric_name=metric_name,
            metric_value=metric_value,
            threshold=threshold,
            status='active',
            created_at=datetime.now(),
            resolved_at=None
        )
        
        with self.lock:
            self.monitoring_alerts[alert_id] = alert
        
        # 에이전트 알림 수 증가
        if agent_id in self.monitoring_agents:
            self.monitoring_agents[agent_id].alerts_count += 1
        
        logger.warning(f"Alert created: {alert_id} - {alert_message}")
        return alert_id
    
    async def resolve_alert(self, alert_id: str):
        """알림 해결"""
        with self.lock:
            if alert_id in self.monitoring_alerts:
                alert = self.monitoring_alerts[alert_id]
                alert.status = 'resolved'
                alert.resolved_at = datetime.now()
                
                logger.info(f"Alert resolved: {alert_id}")
    
    def get_monitoring_region(self, region_id: str) -> Optional[MonitoringRegion]:
        """모니터링 리전 조회"""
        return self.monitoring_regions.get(region_id)
    
    def get_all_monitoring_regions(self) -> List[MonitoringRegion]:
        """모든 모니터링 리전 조회"""
        return list(self.monitoring_regions.values())
    
    def get_monitoring_agent(self, agent_id: str) -> Optional[MonitoringAgent]:
        """모니터링 에이전트 조회"""
        return self.monitoring_agents.get(agent_id)
    
    def get_agents_by_region(self, region_id: str) -> List[MonitoringAgent]:
        """리전별 에이전트 조회"""
        return [
            agent for agent in self.monitoring_agents.values()
            if agent.region_id == region_id
        ]
    
    def get_monitoring_metric(self, metric_id: str) -> Optional[MonitoringMetric]:
        """모니터링 메트릭 조회"""
        return self.monitoring_metrics.get(metric_id)
    
    def get_metrics_by_agent(self, agent_id: str, 
                           time_range: Optional[Tuple[datetime, datetime]] = None) -> List[MonitoringMetric]:
        """에이전트별 메트릭 조회"""
        metrics = [
            metric for metric in self.monitoring_metrics.values()
            if metric.agent_id == agent_id
        ]
        
        if time_range:
            start_time, end_time = time_range
            metrics = [
                metric for metric in metrics
                if start_time <= metric.timestamp <= end_time
            ]
        
        return sorted(metrics, key=lambda x: x.timestamp)
    
    def get_monitoring_alert(self, alert_id: str) -> Optional[MonitoringAlert]:
        """모니터링 알림 조회"""
        return self.monitoring_alerts.get(alert_id)
    
    def get_active_alerts(self) -> List[MonitoringAlert]:
        """활성 알림 조회"""
        return [
            alert for alert in self.monitoring_alerts.values()
            if alert.status == 'active'
        ]
    
    def get_alerts_by_region(self, region_id: str) -> List[MonitoringAlert]:
        """리전별 알림 조회"""
        return [
            alert for alert in self.monitoring_alerts.values()
            if alert.region_id == region_id
        ]

class MonitoringMetrics:
    """모니터링 메트릭"""
    
    def __init__(self):
        self.monitoring_cycles = 0
        self.metrics_processed = 0
        self.alerts_processed = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def record_monitoring_cycle(self):
        """모니터링 사이클 기록"""
        with self.lock:
            self.monitoring_cycles += 1
    
    def record_metrics_processed(self, count: int = 1):
        """처리된 메트릭 기록"""
        with self.lock:
            self.metrics_processed += count
    
    def record_alerts_processed(self, count: int = 1):
        """처리된 알림 기록"""
        with self.lock:
            self.alerts_processed += count
    
    def get_metrics(self) -> Dict[str, Any]:
        """메트릭 조회"""
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                'monitoring_cycles': self.monitoring_cycles,
                'metrics_processed': self.metrics_processed,
                'alerts_processed': self.alerts_processed,
                'cycles_per_second': self.monitoring_cycles / uptime if uptime > 0 else 0,
                'metrics_per_second': self.metrics_processed / uptime if uptime > 0 else 0,
                'uptime_seconds': uptime
            }
```

## 🔧 **성능 분석 시스템**

### 📦 **메트릭 수집 및 성능 대시보드**

```python
# global-monitoring/performance-analysis/performance_analyzer.py
import asyncio
import time
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import threading
from collections import defaultdict, deque
import numpy as np
import pandas as pd
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns

logger = logging.getLogger(__name__)

@dataclass
class PerformanceMetric:
    """성능 메트릭"""
    metric_id: str
    region_id: str
    service_name: str
    metric_type: str  # 'response_time', 'throughput', 'error_rate', 'availability'
    value: float
    unit: str
    timestamp: datetime
    percentile_95: Optional[float] = None
    percentile_99: Optional[float] = None

@dataclass
class PerformanceTrend:
    """성능 트렌드"""
    trend_id: str
    region_id: str
    service_name: str
    metric_type: str
    trend_direction: str  # 'improving', 'stable', 'degrading'
    trend_value: float
    confidence: float
    start_time: datetime
    end_time: datetime

@dataclass
class CapacityForecast:
    """용량 예측"""
    forecast_id: str
    region_id: str
    resource_type: str  # 'cpu', 'memory', 'storage', 'network'
    current_usage: float
    predicted_usage: float
    prediction_date: datetime
    confidence_interval: Tuple[float, float]

class PerformanceAnalyzer:
    """성능 분석기"""
    
    def __init__(self):
        self.performance_metrics = {}
        self.performance_trends = {}
        self.capacity_forecasts = {}
        self.analysis_metrics = AnalysisMetrics()
        
        # 스레드 안전
        self.lock = threading.Lock()
        
        # 분석 스레드
        self.analysis_thread = None
        self.analysis_active = False
        
        logger.info("Performance analyzer initialized")
    
    async def start_performance_analyzer(self):
        """성능 분석기 시작"""
        self.analysis_active = True
        self.analysis_thread = threading.Thread(target=self._analysis_loop)
        self.analysis_thread.start()
        logger.info("Performance analyzer started")
    
    async def stop_performance_analyzer(self):
        """성능 분석기 중지"""
        self.analysis_active = False
        if self.analysis_thread:
            self.analysis_thread.join()
        logger.info("Performance analyzer stopped")
    
    def _analysis_loop(self):
        """분석 루프"""
        while self.analysis_active:
            try:
                # 성능 트렌드 분석
                self._analyze_performance_trends()
                
                # 용량 예측
                self._generate_capacity_forecasts()
                
                # 성능 측정
                self.analysis_metrics.record_analysis_cycle()
                
                time.sleep(60)  # 1분마다 실행
                
            except Exception as e:
                logger.error(f"Error in analysis loop: {e}")
                time.sleep(300)  # 5분 대기
    
    async def add_performance_metric(self, region_id: str, service_name: str,
                                   metric_type: str, value: float, unit: str) -> str:
        """성능 메트릭 추가"""
        metric_id = f"perf_{region_id}_{service_name}_{metric_type}_{int(time.time() * 1000)}"
        
        metric = PerformanceMetric(
            metric_id=metric_id,
            region_id=region_id,
            service_name=service_name,
            metric_type=metric_type,
            value=value,
            unit=unit,
            timestamp=datetime.now()
        )
        
        with self.lock:
            self.performance_metrics[metric_id] = metric
        
        logger.debug(f"Performance metric added: {metric_id}")
        return metric_id
    
    def _analyze_performance_trends(self):
        """성능 트렌드 분석"""
        # 최근 24시간 데이터 분석
        end_time = datetime.now()
        start_time = end_time - timedelta(hours=24)
        
        # 리전별, 서비스별, 메트릭 타입별로 그룹화
        grouped_metrics = self._group_metrics_by_dimensions(start_time, end_time)
        
        for (region_id, service_name, metric_type), metrics in grouped_metrics.items():
            if len(metrics) < 10:  # 최소 10개 데이터 포인트 필요
                continue
            
            trend = self._calculate_trend(metrics)
            if trend:
                trend_id = f"trend_{region_id}_{service_name}_{metric_type}_{int(time.time())}"
                
                performance_trend = PerformanceTrend(
                    trend_id=trend_id,
                    region_id=region_id,
                    service_name=service_name,
                    metric_type=metric_type,
                    trend_direction=trend['direction'],
                    trend_value=trend['value'],
                    confidence=trend['confidence'],
                    start_time=start_time,
                    end_time=end_time
                )
                
                with self.lock:
                    self.performance_trends[trend_id] = performance_trend
                
                logger.info(f"Performance trend calculated: {trend_id} - {trend['direction']}")
    
    def _group_metrics_by_dimensions(self, start_time: datetime, 
                                   end_time: datetime) -> Dict[Tuple[str, str, str], List[PerformanceMetric]]:
        """메트릭을 차원별로 그룹화"""
        grouped = defaultdict(list)
        
        for metric in self.performance_metrics.values():
            if start_time <= metric.timestamp <= end_time:
                key = (metric.region_id, metric.service_name, metric.metric_type)
                grouped[key].append(metric)
        
        return dict(grouped)
    
    def _calculate_trend(self, metrics: List[PerformanceMetric]) -> Optional[Dict[str, Any]]:
        """트렌드 계산"""
        if len(metrics) < 2:
            return None
        
        # 시간순 정렬
        sorted_metrics = sorted(metrics, key=lambda x: x.timestamp)
        
        # 값 추출
        values = [metric.value for metric in sorted_metrics]
        timestamps = [metric.timestamp.timestamp() for metric in sorted_metrics]
        
        # 선형 회귀
        slope, intercept, r_value, p_value, std_err = stats.linregress(timestamps, values)
        
        # 트렌드 방향 결정
        if slope > 0.01:  # 임계값
            direction = 'degrading' if self._is_negative_metric(sorted_metrics[0].metric_type) else 'improving'
        elif slope < -0.01:
            direction = 'improving' if self._is_negative_metric(sorted_metrics[0].metric_type) else 'degrading'
        else:
            direction = 'stable'
        
        return {
            'direction': direction,
            'value': slope,
            'confidence': abs(r_value)
        }
    
    def _is_negative_metric(self, metric_type: str) -> bool:
        """음수 메트릭 여부 (낮을수록 좋은 메트릭)"""
        negative_metrics = ['response_time', 'error_rate', 'latency']
        return metric_type in negative_metrics
    
    def _generate_capacity_forecasts(self):
        """용량 예측 생성"""
        # 리전별, 리소스 타입별로 그룹화
        resource_types = ['cpu', 'memory', 'storage', 'network']
        
        for region_id in ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-northeast-1']:
            for resource_type in resource_types:
                forecast = self._forecast_resource_usage(region_id, resource_type)
                if forecast:
                    forecast_id = f"forecast_{region_id}_{resource_type}_{int(time.time())}"
                    
                    with self.lock:
                        self.capacity_forecasts[forecast_id] = forecast
                    
                    logger.info(f"Capacity forecast generated: {forecast_id}")
    
    def _forecast_resource_usage(self, region_id: str, resource_type: str) -> Optional[CapacityForecast]:
        """리소스 사용량 예측"""
        # 최근 7일 데이터 수집
        end_time = datetime.now()
        start_time = end_time - timedelta(days=7)
        
        metrics = [
            metric for metric in self.performance_metrics.values()
            if (metric.region_id == region_id and 
                metric.service_name == 'system' and 
                metric.metric_type == f"{resource_type}_usage" and
                start_time <= metric.timestamp <= end_time)
        ]
        
        if len(metrics) < 24:  # 최소 24개 데이터 포인트 필요
            return None
        
        # 현재 사용량
        current_usage = metrics[-1].value if metrics else 0.0
        
        # 예측 (간단한 선형 예측)
        values = [metric.value for metric in metrics]
        timestamps = [metric.timestamp.timestamp() for metric in metrics]
        
        slope, intercept, r_value, p_value, std_err = stats.linregress(timestamps, values)
        
        # 7일 후 예측
        future_timestamp = end_time.timestamp() + (7 * 24 * 3600)  # 7일 후
        predicted_usage = slope * future_timestamp + intercept
        
        # 신뢰 구간 계산
        confidence_interval = (
            max(0, predicted_usage - 2 * std_err),
            min(100, predicted_usage + 2 * std_err)
        )
        
        return CapacityForecast(
            forecast_id=f"forecast_{region_id}_{resource_type}_{int(time.time())}",
            region_id=region_id,
            resource_type=resource_type,
            current_usage=current_usage,
            predicted_usage=predicted_usage,
            prediction_date=end_time + timedelta(days=7),
            confidence_interval=confidence_interval
        )
    
    def get_performance_metric(self, metric_id: str) -> Optional[PerformanceMetric]:
        """성능 메트릭 조회"""
        return self.performance_metrics.get(metric_id)
    
    def get_metrics_by_region(self, region_id: str, 
                            time_range: Optional[Tuple[datetime, datetime]] = None) -> List[PerformanceMetric]:
        """리전별 메트릭 조회"""
        metrics = [
            metric for metric in self.performance_metrics.values()
            if metric.region_id == region_id
        ]
        
        if time_range:
            start_time, end_time = time_range
            metrics = [
                metric for metric in metrics
                if start_time <= metric.timestamp <= end_time
            ]
        
        return sorted(metrics, key=lambda x: x.timestamp)
    
    def get_performance_trend(self, trend_id: str) -> Optional[PerformanceTrend]:
        """성능 트렌드 조회"""
        return self.performance_trends.get(trend_id)
    
    def get_trends_by_region(self, region_id: str) -> List[PerformanceTrend]:
        """리전별 트렌드 조회"""
        return [
            trend for trend in self.performance_trends.values()
            if trend.region_id == region_id
        ]
    
    def get_capacity_forecast(self, forecast_id: str) -> Optional[CapacityForecast]:
        """용량 예측 조회"""
        return self.capacity_forecasts.get(forecast_id)
    
    def get_forecasts_by_region(self, region_id: str) -> List[CapacityForecast]:
        """리전별 예측 조회"""
        return [
            forecast for forecast in self.capacity_forecasts.values()
            if forecast.region_id == region_id
        ]

class AnalysisMetrics:
    """분석 메트릭"""
    
    def __init__(self):
        self.analysis_cycles = 0
        self.trends_calculated = 0
        self.forecasts_generated = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def record_analysis_cycle(self):
        """분석 사이클 기록"""
        with self.lock:
            self.analysis_cycles += 1
    
    def record_trends_calculated(self, count: int = 1):
        """계산된 트렌드 기록"""
        with self.lock:
            self.trends_calculated += count
    
    def record_forecasts_generated(self, count: int = 1):
        """생성된 예측 기록"""
        with self.lock:
            self.forecasts_generated += count
    
    def get_metrics(self) -> Dict[str, Any]:
        """메트릭 조회"""
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                'analysis_cycles': self.analysis_cycles,
                'trends_calculated': self.trends_calculated,
                'forecasts_generated': self.forecasts_generated,
                'cycles_per_minute': self.analysis_cycles / (uptime / 60) if uptime > 0 else 0,
                'uptime_seconds': uptime
            }
```

## 🎯 **다음 단계**

### 📋 **완료된 작업**
- ✅ 실시간 위험 평가 시스템 설계 (포트폴리오 위험, 시장 위험)
- ✅ 스트레스 테스트 시스템 설계 (시나리오 기반, 병렬 실행)
- ✅ 위험 한도 관리 시스템 설계
- ✅ 대칭키 암호화 시스템 설계 (AES-256-GCM)
- ✅ 데이터 익명화 시스템 설계 (마스킹, 해싱, 일반화)
- ✅ 실시간 로그 수집 시스템 설계 (구조화된 로깅, 실시간 처리)
- ✅ 규정 준수 모니터링 시스템 설계 (GDPR, SOX, PCI-DSS)
- ✅ 다중 리전 배포 시스템 설계 (리전 관리, 배포 자동화)
- ✅ 글로벌 로드 밸런싱 시스템 설계 (지리적 라우팅, 트래픽 관리)
- ✅ 지역별 저장소 시스템 설계 (주 저장소, 복제 저장소, 캐시 저장소)
- ✅ 데이터 동기화 시스템 설계 (실시간 동기화, 충돌 해결)
- ✅ 분산 모니터링 시스템 설계 (지역별 에이전트, 중앙 수집기)
- ✅ 성능 분석 시스템 설계 (메트릭 수집, 트렌드 분석, 용량 예측)

### 🔄 **진행 중인 작업**
- 🔄 장애 관리 시스템 (장애 감지, 알림 관리, 자동 복구)
- 🔄 보안 모니터링 시스템 (위협 감지, 보안 이벤트, 규정 준수)

### ⏳ **다음 단계**
1. **장애 관리 시스템** 문서 생성
2. **보안 모니터링 시스템** 문서 생성
3. **Phase 7.3 재해 복구** 문서 생성

---

**마지막 업데이트**: 2024-01-31
**다음 업데이트**: 2024-02-01 (장애 관리 시스템)
**글로벌 모니터링 목표**: < 5초 이벤트 감지, < 10초 알림 전송, < 1초 메트릭 수집
**글로벌 모니터링 성과**: 분산 모니터링, 성능 분석, 장애 관리 