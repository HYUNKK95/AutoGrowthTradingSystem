# 🌍 Phase 7.3: 재해 복구 시스템

## 📋 **개요**

### 🎯 **목표**
- **백업 전략**: 다중 리전 백업 및 복구 전략
- **장애 복구**: 자동 장애 감지 및 복구 시스템
- **데이터 보호**: 데이터 무결성 및 가용성 보장
- **비즈니스 연속성**: 24/7 서비스 중단 없는 운영
- **복구 테스트**: 정기적인 복구 테스트 및 검증

### 📊 **성능 목표**
- **RTO (Recovery Time Objective)**: < 15분
- **RPO (Recovery Point Objective)**: < 1분
- **백업 복구**: < 5분 데이터 복구
- **서비스 복구**: < 10분 서비스 복구
- **데이터 손실**: 0% 데이터 손실

## 🏗️ **재해 복구 시스템 아키텍처**

### 📁 **재해 복구 시스템 구조**
```
disaster-recovery/
├── backup-strategy/                   # 백업 전략
│   ├── multi-region-backup/          # 다중 리전 백업
│   ├── incremental-backup/           # 증분 백업
│   ├── snapshot-management/          # 스냅샷 관리
│   └── backup-verification/          # 백업 검증
├── disaster-detection/               # 재해 감지
│   ├── real-time-monitoring/         # 실시간 모니터링
│   ├── failure-detection/            # 장애 감지
│   ├── impact-assessment/            # 영향도 평가
│   └── alert-escalation/             # 알림 에스컬레이션
├── recovery-automation/              # 복구 자동화
│   ├── automated-recovery/           # 자동 복구
│   ├── failover-management/          # 장애 조치 관리
│   ├── service-restoration/          # 서비스 복원
│   └── data-synchronization/         # 데이터 동기화
└── business-continuity/              # 비즈니스 연속성
    ├── continuity-planning/          # 연속성 계획
    ├── disaster-testing/             # 재해 테스트
    ├── recovery-validation/          # 복구 검증
    └── documentation-management/     # 문서 관리
```

## 🔧 **백업 전략 시스템**

### 📦 **다중 리전 백업 및 복구 관리**

```python
# disaster-recovery/backup-strategy/backup_manager.py
import asyncio
import time
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import threading
from collections import defaultdict, deque
import hashlib
import boto3
import pymongo
import redis

logger = logging.getLogger(__name__)

@dataclass
class BackupConfig:
    """백업 설정"""
    config_id: str
    region_id: str
    backup_type: str  # 'full', 'incremental', 'differential'
    schedule: str  # cron expression
    retention_days: int
    compression: bool
    encryption: bool
    is_active: bool

@dataclass
class BackupJob:
    """백업 작업"""
    job_id: str
    config_id: str
    region_id: str
    backup_type: str
    status: str  # 'pending', 'running', 'completed', 'failed'
    start_time: datetime
    end_time: Optional[datetime]
    size_bytes: int
    checksum: str
    backup_location: str
    error_message: Optional[str]

@dataclass
class RecoveryPoint:
    """복구 지점"""
    point_id: str
    region_id: str
    backup_job_id: str
    timestamp: datetime
    data_consistency: bool
    recovery_time_estimate: int  # seconds
    size_bytes: int
    status: str  # 'available', 'corrupted', 'expired'

class BackupManager:
    """백업 관리자"""
    
    def __init__(self):
        self.backup_configs = self._initialize_backup_configs()
        self.backup_jobs = {}
        self.recovery_points = {}
        self.performance_metrics = BackupMetrics()
        
        # 스레드 안전
        self.lock = threading.Lock()
        
        # 백업 스레드
        self.backup_thread = None
        self.backup_active = False
        
        # 클라우드 클라이언트
        self.s3_clients = {}
        self.mongo_clients = {}
        self.redis_clients = {}
        
        logger.info("Backup manager initialized")
    
    def _initialize_backup_configs(self) -> Dict[str, BackupConfig]:
        """백업 설정 초기화"""
        configs = {}
        
        regions = ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-northeast-1']
        
        for region_id in regions:
            # 전체 백업 설정
            configs[f"{region_id}_full"] = BackupConfig(
                config_id=f"{region_id}_full",
                region_id=region_id,
                backup_type='full',
                schedule='0 2 * * 0',  # 매주 일요일 02:00
                retention_days=30,
                compression=True,
                encryption=True,
                is_active=True
            )
            
            # 증분 백업 설정
            configs[f"{region_id}_incremental"] = BackupConfig(
                config_id=f"{region_id}_incremental",
                region_id=region_id,
                backup_type='incremental',
                schedule='0 */6 * * *',  # 6시간마다
                retention_days=7,
                compression=True,
                encryption=True,
                is_active=True
            )
        
        return configs
    
    async def start_backup_manager(self):
        """백업 관리자 시작"""
        self.backup_active = True
        self.backup_thread = threading.Thread(target=self._backup_loop)
        self.backup_thread.start()
        logger.info("Backup manager started")
    
    async def stop_backup_manager(self):
        """백업 관리자 중지"""
        self.backup_active = False
        if self.backup_thread:
            self.backup_thread.join()
        logger.info("Backup manager stopped")
    
    def _backup_loop(self):
        """백업 루프"""
        while self.backup_active:
            try:
                # 스케줄된 백업 확인
                self._check_scheduled_backups()
                
                # 백업 작업 처리
                self._process_backup_jobs()
                
                # 만료된 백업 정리
                self._cleanup_expired_backups()
                
                # 성능 측정
                self.performance_metrics.record_backup_cycle()
                
                time.sleep(60)  # 1분마다 실행
                
            except Exception as e:
                logger.error(f"Error in backup loop: {e}")
                time.sleep(300)  # 5분 대기
    
    def _check_scheduled_backups(self):
        """스케줄된 백업 확인"""
        current_time = datetime.now()
        
        for config_id, config in self.backup_configs.items():
            if not config.is_active:
                continue
            
            # 스케줄 확인 (간단한 구현)
            if self._should_run_backup(config, current_time):
                self._create_backup_job(config)
    
    def _should_run_backup(self, config: BackupConfig, current_time: datetime) -> bool:
        """백업 실행 여부 확인"""
        # 실제 구현에서는 cron 파싱 사용
        if config.backup_type == 'full':
            # 매주 일요일 02:00
            return (current_time.weekday() == 6 and 
                   current_time.hour == 2 and 
                   current_time.minute == 0)
        elif config.backup_type == 'incremental':
            # 6시간마다
            return current_time.hour % 6 == 0 and current_time.minute == 0
        
        return False
    
    def _create_backup_job(self, config: BackupConfig):
        """백업 작업 생성"""
        job_id = f"backup_{config.region_id}_{config.backup_type}_{int(time.time())}"
        
        job = BackupJob(
            job_id=job_id,
            config_id=config.config_id,
            region_id=config.region_id,
            backup_type=config.backup_type,
            status='pending',
            start_time=datetime.now(),
            end_time=None,
            size_bytes=0,
            checksum='',
            backup_location='',
            error_message=None
        )
        
        with self.lock:
            self.backup_jobs[job_id] = job
        
        logger.info(f"Backup job created: {job_id}")
    
    def _process_backup_jobs(self):
        """백업 작업 처리"""
        pending_jobs = [
            job for job in self.backup_jobs.values()
            if job.status == 'pending'
        ]
        
        for job in pending_jobs[:5]:  # 최대 5개씩 처리
            self._execute_backup_job(job)
    
    def _execute_backup_job(self, job: BackupJob):
        """백업 작업 실행"""
        try:
            job.status = 'running'
            
            # 백업 실행
            backup_result = self._perform_backup(job)
            
            if backup_result['success']:
                job.status = 'completed'
                job.end_time = datetime.now()
                job.size_bytes = backup_result['size_bytes']
                job.checksum = backup_result['checksum']
                job.backup_location = backup_result['location']
                
                # 복구 지점 생성
                self._create_recovery_point(job)
                
                logger.info(f"Backup job completed: {job.job_id}")
            else:
                job.status = 'failed'
                job.end_time = datetime.now()
                job.error_message = backup_result['error']
                
                logger.error(f"Backup job failed: {job.job_id} - {backup_result['error']}")
            
        except Exception as e:
            job.status = 'failed'
            job.end_time = datetime.now()
            job.error_message = str(e)
            
            logger.error(f"Backup job failed: {job.job_id} - {e}")
    
    def _perform_backup(self, job: BackupJob) -> Dict[str, Any]:
        """백업 수행"""
        try:
            # 실제 구현에서는 실제 백업 로직
            # MongoDB 백업
            # mongo_client = self.mongo_clients.get(job.region_id)
            # if mongo_client:
            #     # MongoDB 백업 로직
            
            # Redis 백업
            # redis_client = self.redis_clients.get(job.region_id)
            # if redis_client:
            #     # Redis 백업 로직
            
            # S3 백업
            # s3_client = self.s3_clients.get(job.region_id)
            # if s3_client:
            #     # S3 백업 로직
            
            # 시뮬레이션
            time.sleep(10)  # 백업 시간 시뮬레이션
            
            return {
                'success': True,
                'size_bytes': 1024 * 1024 * 100,  # 100MB
                'checksum': hashlib.md5(f"backup_{job.job_id}".encode()).hexdigest(),
                'location': f"s3://backup-bucket/{job.region_id}/{job.job_id}.tar.gz"
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def _create_recovery_point(self, job: BackupJob):
        """복구 지점 생성"""
        point_id = f"rp_{job.region_id}_{job.backup_type}_{int(time.time())}"
        
        recovery_point = RecoveryPoint(
            point_id=point_id,
            region_id=job.region_id,
            backup_job_id=job.job_id,
            timestamp=job.end_time or datetime.now(),
            data_consistency=True,
            recovery_time_estimate=300,  # 5분
            size_bytes=job.size_bytes,
            status='available'
        )
        
        with self.lock:
            self.recovery_points[point_id] = recovery_point
        
        logger.info(f"Recovery point created: {point_id}")
    
    def _cleanup_expired_backups(self):
        """만료된 백업 정리"""
        current_time = datetime.now()
        
        for config_id, config in self.backup_configs.items():
            expired_jobs = [
                job for job in self.backup_jobs.values()
                if (job.config_id == config_id and 
                    job.end_time and 
                    (current_time - job.end_time).days > config.retention_days)
            ]
            
            for job in expired_jobs:
                self._delete_backup_job(job)
    
    def _delete_backup_job(self, job: BackupJob):
        """백업 작업 삭제"""
        # 실제 구현에서는 백업 파일 삭제
        # s3_client = self.s3_clients.get(job.region_id)
        # if s3_client:
        #     s3_client.delete_object(Bucket='backup-bucket', Key=job.backup_location)
        
        with self.lock:
            if job.job_id in self.backup_jobs:
                del self.backup_jobs[job.job_id]
        
        logger.info(f"Backup job deleted: {job.job_id}")
    
    async def create_manual_backup(self, region_id: str, backup_type: str = 'full') -> str:
        """수동 백업 생성"""
        config_id = f"{region_id}_{backup_type}"
        config = self.backup_configs.get(config_id)
        
        if not config:
            raise Exception(f"Backup config not found: {config_id}")
        
        self._create_backup_job(config)
        
        logger.info(f"Manual backup created for region: {region_id}")
        return config_id
    
    async def restore_from_backup(self, recovery_point_id: str, target_region: str) -> bool:
        """백업에서 복구"""
        recovery_point = self.recovery_points.get(recovery_point_id)
        if not recovery_point:
            raise Exception(f"Recovery point not found: {recovery_point_id}")
        
        try:
            # 복구 실행
            restore_result = self._perform_restore(recovery_point, target_region)
            
            if restore_result['success']:
                logger.info(f"Restore completed: {recovery_point_id} to {target_region}")
                return True
            else:
                logger.error(f"Restore failed: {recovery_point_id} - {restore_result['error']}")
                return False
                
        except Exception as e:
            logger.error(f"Restore failed: {recovery_point_id} - {e}")
            return False
    
    def _perform_restore(self, recovery_point: RecoveryPoint, target_region: str) -> Dict[str, Any]:
        """복구 수행"""
        try:
            # 실제 구현에서는 실제 복구 로직
            # MongoDB 복구
            # mongo_client = self.mongo_clients.get(target_region)
            # if mongo_client:
            #     # MongoDB 복구 로직
            
            # Redis 복구
            # redis_client = self.redis_clients.get(target_region)
            # if redis_client:
            #     # Redis 복구 로직
            
            # 시뮬레이션
            time.sleep(recovery_point.recovery_time_estimate)
            
            return {
                'success': True,
                'restore_time': recovery_point.recovery_time_estimate
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }
    
    def get_backup_config(self, config_id: str) -> Optional[BackupConfig]:
        """백업 설정 조회"""
        return self.backup_configs.get(config_id)
    
    def get_backup_job(self, job_id: str) -> Optional[BackupJob]:
        """백업 작업 조회"""
        return self.backup_jobs.get(job_id)
    
    def get_recovery_point(self, point_id: str) -> Optional[RecoveryPoint]:
        """복구 지점 조회"""
        return self.recovery_points.get(point_id)
    
    def get_recovery_points_by_region(self, region_id: str) -> List[RecoveryPoint]:
        """리전별 복구 지점 조회"""
        return [
            point for point in self.recovery_points.values()
            if point.region_id == region_id and point.status == 'available'
        ]

class BackupMetrics:
    """백업 메트릭"""
    
    def __init__(self):
        self.backup_cycles = 0
        self.backup_jobs = 0
        self.restore_operations = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def record_backup_cycle(self):
        """백업 사이클 기록"""
        with self.lock:
            self.backup_cycles += 1
    
    def record_backup_job(self):
        """백업 작업 기록"""
        with self.lock:
            self.backup_jobs += 1
    
    def record_restore_operation(self):
        """복구 작업 기록"""
        with self.lock:
            self.restore_operations += 1
    
    def get_metrics(self) -> Dict[str, Any]:
        """메트릭 조회"""
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                'backup_cycles': self.backup_cycles,
                'backup_jobs': self.backup_jobs,
                'restore_operations': self.restore_operations,
                'cycles_per_minute': self.backup_cycles / (uptime / 60) if uptime > 0 else 0,
                'uptime_seconds': uptime
            }
```

## 🔧 **재해 감지 시스템**

### 📦 **실시간 모니터링 및 장애 감지**

```python
# disaster-recovery/disaster-detection/disaster_detector.py
import asyncio
import time
import logging
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass
from datetime import datetime, timedelta
import json
import threading
from collections import defaultdict, deque
import hashlib

logger = logging.getLogger(__name__)

@dataclass
class DisasterEvent:
    """재해 이벤트"""
    event_id: str
    event_type: str  # 'system_failure', 'network_outage', 'data_corruption', 'security_breach'
    severity: str  # 'critical', 'high', 'medium', 'low'
    region_id: str
    affected_services: List[str]
    description: str
    detected_at: datetime
    resolved_at: Optional[datetime]
    impact_score: float
    status: str  # 'detected', 'investigating', 'mitigating', 'resolved'

@dataclass
class FailurePattern:
    """장애 패턴"""
    pattern_id: str
    pattern_name: str
    pattern_type: str  # 'threshold', 'trend', 'anomaly'
    conditions: Dict[str, Any]
    severity: str
    is_active: bool

@dataclass
class ImpactAssessment:
    """영향도 평가"""
    assessment_id: str
    event_id: str
    affected_users: int
    affected_transactions: int
    estimated_loss: float
    recovery_priority: str  # 'immediate', 'high', 'medium', 'low'
    assessment_time: datetime

class DisasterDetector:
    """재해 감지기"""
    
    def __init__(self):
        self.disaster_events = {}
        self.failure_patterns = self._initialize_failure_patterns()
        self.impact_assessments = {}
        self.performance_metrics = DetectionMetrics()
        
        # 스레드 안전
        self.lock = threading.Lock()
        
        # 감지 스레드
        self.detection_thread = None
        self.detection_active = False
        
        logger.info("Disaster detector initialized")
    
    def _initialize_failure_patterns(self) -> Dict[str, FailurePattern]:
        """장애 패턴 초기화"""
        patterns = {
            'high_cpu_usage': FailurePattern(
                pattern_id='high_cpu_usage',
                pattern_name='High CPU Usage',
                pattern_type='threshold',
                conditions={'metric': 'cpu_usage', 'threshold': 90, 'duration': 300},
                severity='high',
                is_active=True
            ),
            'memory_exhaustion': FailurePattern(
                pattern_id='memory_exhaustion',
                pattern_name='Memory Exhaustion',
                pattern_type='threshold',
                conditions={'metric': 'memory_usage', 'threshold': 95, 'duration': 60},
                severity='critical',
                is_active=True
            ),
            'disk_full': FailurePattern(
                pattern_id='disk_full',
                pattern_name='Disk Full',
                pattern_type='threshold',
                conditions={'metric': 'disk_usage', 'threshold': 98, 'duration': 30},
                severity='critical',
                is_active=True
            ),
            'network_latency': FailurePattern(
                pattern_id='network_latency',
                pattern_name='High Network Latency',
                pattern_type='threshold',
                conditions={'metric': 'network_latency', 'threshold': 1000, 'duration': 120},
                severity='medium',
                is_active=True
            ),
            'error_rate_spike': FailurePattern(
                pattern_id='error_rate_spike',
                pattern_name='Error Rate Spike',
                pattern_type='trend',
                conditions={'metric': 'error_rate', 'increase': 50, 'duration': 300},
                severity='high',
                is_active=True
            )
        }
        
        return patterns
    
    async def start_disaster_detector(self):
        """재해 감지기 시작"""
        self.detection_active = True
        self.detection_thread = threading.Thread(target=self._detection_loop)
        self.detection_thread.start()
        logger.info("Disaster detector started")
    
    async def stop_disaster_detector(self):
        """재해 감지기 중지"""
        self.detection_active = False
        if self.detection_thread:
            self.detection_thread.join()
        logger.info("Disaster detector stopped")
    
    def _detection_loop(self):
        """감지 루프"""
        while self.detection_active:
            try:
                # 시스템 상태 확인
                self._check_system_health()
                
                # 장애 패턴 감지
                self._detect_failure_patterns()
                
                # 영향도 평가
                self._assess_impact()
                
                # 성능 측정
                self.performance_metrics.record_detection_cycle()
                
                time.sleep(10)  # 10초마다 실행
                
            except Exception as e:
                logger.error(f"Error in detection loop: {e}")
                time.sleep(60)
    
    def _check_system_health(self):
        """시스템 상태 확인"""
        # 실제 구현에서는 시스템 메트릭 수집
        # CPU, 메모리, 디스크, 네트워크 상태 확인
        
        regions = ['us-east-1', 'us-west-2', 'eu-west-1', 'ap-northeast-1']
        
        for region_id in regions:
            # 시뮬레이션된 시스템 상태
            system_health = self._get_system_health(region_id)
            
            if not system_health['healthy']:
                self._create_disaster_event(
                    'system_failure', 'high', region_id,
                    system_health['affected_services'],
                    f"System health check failed in {region_id}: {system_health['issues']}"
                )
    
    def _get_system_health(self, region_id: str) -> Dict[str, Any]:
        """시스템 상태 조회"""
        # 실제 구현에서는 실제 시스템 상태 확인
        # 시뮬레이션
        import random
        
        if random.random() < 0.01:  # 1% 확률로 장애 발생
            return {
                'healthy': False,
                'affected_services': ['api-gateway', 'database', 'cache'],
                'issues': ['High CPU usage', 'Memory pressure']
            }
        else:
            return {
                'healthy': True,
                'affected_services': [],
                'issues': []
            }
    
    def _detect_failure_patterns(self):
        """장애 패턴 감지"""
        for pattern_id, pattern in self.failure_patterns.items():
            if not pattern.is_active:
                continue
            
            if self._matches_pattern(pattern):
                self._create_disaster_event(
                    'system_failure', pattern.severity, 'all',
                    ['system'],
                    f"Failure pattern detected: {pattern.pattern_name}"
                )
    
    def _matches_pattern(self, pattern: FailurePattern) -> bool:
        """패턴 매칭"""
        # 실제 구현에서는 실제 메트릭 데이터와 비교
        # 시뮬레이션
        import random
        
        if pattern.pattern_id == 'high_cpu_usage':
            return random.random() < 0.005  # 0.5% 확률
        elif pattern.pattern_id == 'memory_exhaustion':
            return random.random() < 0.001  # 0.1% 확률
        elif pattern.pattern_id == 'disk_full':
            return random.random() < 0.002  # 0.2% 확률
        
        return False
    
    def _create_disaster_event(self, event_type: str, severity: str, region_id: str,
                             affected_services: List[str], description: str) -> str:
        """재해 이벤트 생성"""
        event_id = f"disaster_{event_type}_{region_id}_{int(time.time())}"
        
        event = DisasterEvent(
            event_id=event_id,
            event_type=event_type,
            severity=severity,
            region_id=region_id,
            affected_services=affected_services,
            description=description,
            detected_at=datetime.now(),
            resolved_at=None,
            impact_score=self._calculate_impact_score(severity, affected_services),
            status='detected'
        )
        
        with self.lock:
            self.disaster_events[event_id] = event
        
        logger.warning(f"Disaster event detected: {event_id} - {description}")
        return event_id
    
    def _calculate_impact_score(self, severity: str, affected_services: List[str]) -> float:
        """영향도 점수 계산"""
        severity_scores = {
            'critical': 1.0,
            'high': 0.8,
            'medium': 0.5,
            'low': 0.2
        }
        
        base_score = severity_scores.get(severity, 0.5)
        service_multiplier = 1.0 + (len(affected_services) * 0.1)
        
        return min(base_score * service_multiplier, 1.0)
    
    def _assess_impact(self):
        """영향도 평가"""
        active_events = [
            event for event in self.disaster_events.values()
            if event.status in ['detected', 'investigating', 'mitigating']
        ]
        
        for event in active_events:
            if not self._has_impact_assessment(event.event_id):
                self._create_impact_assessment(event)
    
    def _has_impact_assessment(self, event_id: str) -> bool:
        """영향도 평가 존재 여부"""
        return any(
            assessment.event_id == event_id
            for assessment in self.impact_assessments.values()
        )
    
    def _create_impact_assessment(self, event: DisasterEvent):
        """영향도 평가 생성"""
        assessment_id = f"impact_{event.event_id}"
        
        # 실제 구현에서는 실제 영향도 계산
        affected_users = self._estimate_affected_users(event)
        affected_transactions = self._estimate_affected_transactions(event)
        estimated_loss = self._estimate_loss(event)
        recovery_priority = self._determine_recovery_priority(event)
        
        assessment = ImpactAssessment(
            assessment_id=assessment_id,
            event_id=event.event_id,
            affected_users=affected_users,
            affected_transactions=affected_transactions,
            estimated_loss=estimated_loss,
            recovery_priority=recovery_priority,
            assessment_time=datetime.now()
        )
        
        with self.lock:
            self.impact_assessments[assessment_id] = assessment
        
        logger.info(f"Impact assessment created: {assessment_id}")
    
    def _estimate_affected_users(self, event: DisasterEvent) -> int:
        """영향받는 사용자 수 추정"""
        # 실제 구현에서는 실제 사용자 수 계산
        base_users = 10000
        severity_multiplier = {
            'critical': 1.0,
            'high': 0.7,
            'medium': 0.4,
            'low': 0.1
        }
        
        return int(base_users * severity_multiplier.get(event.severity, 0.5))
    
    def _estimate_affected_transactions(self, event: DisasterEvent) -> int:
        """영향받는 거래 수 추정"""
        # 실제 구현에서는 실제 거래 수 계산
        base_transactions = 1000
        severity_multiplier = {
            'critical': 1.0,
            'high': 0.8,
            'medium': 0.5,
            'low': 0.2
        }
        
        return int(base_transactions * severity_multiplier.get(event.severity, 0.5))
    
    def _estimate_loss(self, event: DisasterEvent) -> float:
        """손실 추정"""
        # 실제 구현에서는 실제 손실 계산
        base_loss = 10000  # USD
        severity_multiplier = {
            'critical': 1.0,
            'high': 0.6,
            'medium': 0.3,
            'low': 0.1
        }
        
        return base_loss * severity_multiplier.get(event.severity, 0.5)
    
    def _determine_recovery_priority(self, event: DisasterEvent) -> str:
        """복구 우선순위 결정"""
        if event.severity == 'critical':
            return 'immediate'
        elif event.severity == 'high':
            return 'high'
        elif event.severity == 'medium':
            return 'medium'
        else:
            return 'low'
    
    def get_disaster_event(self, event_id: str) -> Optional[DisasterEvent]:
        """재해 이벤트 조회"""
        return self.disaster_events.get(event_id)
    
    def get_active_disaster_events(self) -> List[DisasterEvent]:
        """활성 재해 이벤트 조회"""
        return [
            event for event in self.disaster_events.values()
            if event.status in ['detected', 'investigating', 'mitigating']
        ]
    
    def get_impact_assessment(self, assessment_id: str) -> Optional[ImpactAssessment]:
        """영향도 평가 조회"""
        return self.impact_assessments.get(assessment_id)
    
    def resolve_disaster_event(self, event_id: str):
        """재해 이벤트 해결"""
        with self.lock:
            if event_id in self.disaster_events:
                event = self.disaster_events[event_id]
                event.status = 'resolved'
                event.resolved_at = datetime.now()
                
                logger.info(f"Disaster event resolved: {event_id}")

class DetectionMetrics:
    """감지 메트릭"""
    
    def __init__(self):
        self.detection_cycles = 0
        self.events_detected = 0
        self.assessments_created = 0
        self.start_time = time.time()
        self.lock = threading.Lock()
    
    def record_detection_cycle(self):
        """감지 사이클 기록"""
        with self.lock:
            self.detection_cycles += 1
    
    def record_event_detected(self):
        """감지된 이벤트 기록"""
        with self.lock:
            self.events_detected += 1
    
    def record_assessment_created(self):
        """생성된 평가 기록"""
        with self.lock:
            self.assessments_created += 1
    
    def get_metrics(self) -> Dict[str, Any]:
        """메트릭 조회"""
        with self.lock:
            uptime = time.time() - self.start_time
            return {
                'detection_cycles': self.detection_cycles,
                'events_detected': self.events_detected,
                'assessments_created': self.assessments_created,
                'cycles_per_minute': self.detection_cycles / (uptime / 60) if uptime > 0 else 0,
                'uptime_seconds': uptime
            }
```

## 🎯 **다음 단계**

### 📋 **완료된 작업**
- ✅ 실시간 위험 평가 시스템 설계 (포트폴리오 위험, 시장 위험)
- ✅ 스트레스 테스트 시스템 설계 (시나리오 기반, 병렬 실행)
- ✅ 위험 한도 관리 시스템 설계
- ✅ 대칭키 암호화 시스템 설계 (AES-256-GCM)
- ✅ 데이터 익명화 시스템 설계 (마스킹, 해싱, 일반화)
- ✅ 실시간 로그 수집 시스템 설계 (구조화된 로깅, 실시간 처리)
- ✅ 규정 준수 모니터링 시스템 설계 (GDPR, SOX, PCI-DSS)
- ✅ 다중 리전 배포 시스템 설계 (리전 관리, 배포 자동화)
- ✅ 글로벌 로드 밸런싱 시스템 설계 (지리적 라우팅, 트래픽 관리)
- ✅ 지역별 저장소 시스템 설계 (주 저장소, 복제 저장소, 캐시 저장소)
- ✅ 데이터 동기화 시스템 설계 (실시간 동기화, 충돌 해결)
- ✅ 분산 모니터링 시스템 설계 (지역별 에이전트, 중앙 수집기)
- ✅ 성능 분석 시스템 설계 (메트릭 수집, 트렌드 분석, 용량 예측)
- ✅ 백업 전략 시스템 설계 (다중 리전 백업, 증분 백업, 복구 지점)
- ✅ 재해 감지 시스템 설계 (실시간 모니터링, 장애 패턴 감지, 영향도 평가)

### 🔄 **진행 중인 작업**
- 🔄 복구 자동화 시스템 (자동 복구, 장애 조치, 서비스 복원)
- 🔄 비즈니스 연속성 시스템 (연속성 계획, 재해 테스트, 복구 검증)

### ⏳ **다음 단계**
1. **복구 자동화 시스템** 문서 생성
2. **비즈니스 연속성 시스템** 문서 생성
3. **Phase 7 완료**: 글로벌 확장 시스템 설계 완료

---

**마지막 업데이트**: 2024-01-31
**다음 업데이트**: 2024-02-01 (복구 자동화 시스템)
**재해 복구 목표**: RTO < 15분, RPO < 1분, 백업 복구 < 5분
**재해 복구 성과**: 백업 전략, 재해 감지, 복구 자동화 