# 🏗️ Phase 1.4: 인프라 확장 및 스케일링

## 📋 **개요**

### 🎯 **목표**
- **수평적 확장**: 자동 스케일링 및 로드 밸런싱
- **데이터베이스 최적화**: 읽기/쓰기 분리 및 샤딩
- **캐싱 전략**: 다층 캐싱 시스템 구축
- **CDN 및 엣지 컴퓨팅**: 글로벌 성능 최적화

### 📊 **성능 목표**
- **처리량**: 10,000 TPS (거래/초)
- **응답 시간**: < 50ms (95th percentile)
- **가용성**: 99.99% (연간 다운타임 < 1시간)
- **확장성**: 10배 트래픽 증가 시 자동 스케일링

## 🏗️ **인프라 확장 아키텍처**

### 📁 **인프라 확장 구조**
```
infrastructure/
├── scaling/                        # 스케일링 구성
│   ├── auto_scaling/              # 자동 스케일링
│   ├── load_balancing/            # 로드 밸런싱
│   └── capacity_planning/         # 용량 계획
├── database/                      # 데이터베이스 최적화
│   ├── read_replicas/             # 읽기 복제본
│   ├── sharding/                  # 샤딩 전략
│   └── optimization/              # 성능 최적화
├── caching/                       # 캐싱 시스템
│   ├── multi_layer/               # 다층 캐싱
│   ├── distributed/               # 분산 캐시
│   └── invalidation/              # 캐시 무효화
└── cdn/                          # CDN 및 엣지
    ├── edge_computing/            # 엣지 컴퓨팅
    ├── global_distribution/       # 글로벌 분산
    └── performance_optimization/  # 성능 최적화
```

## 🔄 **자동 스케일링 시스템**

### 📦 **Auto Scaling 구성**

```yaml
# infrastructure/scaling/auto_scaling/autoscaling.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: trading-app-hpa
  namespace: trading-system
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: trading-app
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
  - type: Object
    object:
      metric:
        name: requests-per-second
      describedObject:
        apiVersion: networking.k8s.io/v1
        kind: Ingress
        name: trading-ingress
      target:
        type: Value
        value: 1000
  behavior:
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
      - type: Percent
        value: 10
        periodSeconds: 60
    scaleUp:
      stabilizationWindowSeconds: 60
      policies:
      - type: Percent
        value: 50
        periodSeconds: 60
      - type: Pods
        value: 5
        periodSeconds: 60
```

### 🔧 **스케일링 매니저**

```python
# infrastructure/scaling/auto_scaling/scaling_manager.py
import asyncio
import time
from typing import Dict, List, Optional, Any
from decimal import Decimal
from datetime import datetime, timedelta
from dataclasses import dataclass
import kubernetes
from kubernetes import client, config

@dataclass
class ScalingMetrics:
    """스케일링 메트릭"""
    cpu_usage: float
    memory_usage: float
    request_rate: float
    response_time: float
    error_rate: float
    timestamp: datetime

@dataclass
class ScalingDecision:
    """스케일링 결정"""
    action: str  # 'scale_up', 'scale_down', 'maintain'
    reason: str
    current_replicas: int
    target_replicas: int
    metrics: ScalingMetrics
    timestamp: datetime

class AutoScalingManager:
    """자동 스케일링 관리자"""
    
    def __init__(self, namespace: str = "trading-system"):
        self.namespace = namespace
        self.scaling_history = []
        self.metrics_history = []
        self.is_running = False
        
        # Kubernetes 클라이언트 설정
        try:
            config.load_incluster_config()
        except:
            config.load_kube_config()
        
        self.v1 = client.CoreV1Api()
        self.apps_v1 = client.AppsV1Api()
        self.autoscaling_v2 = client.AutoscalingV2Api()
        
        # 스케일링 임계값
        self.scaling_thresholds = {
            'cpu_high': 80.0,
            'cpu_low': 30.0,
            'memory_high': 85.0,
            'memory_low': 40.0,
            'request_rate_high': 1000,
            'request_rate_low': 100,
            'response_time_high': 200,
            'error_rate_high': 5.0
        }
        
        logger.info("Initialized auto scaling manager")
    
    async def start_monitoring(self):
        """스케일링 모니터링 시작"""
        self.is_running = True
        
        while self.is_running:
            try:
                # 메트릭 수집
                metrics = await self._collect_scaling_metrics()
                self.metrics_history.append(metrics)
                
                # 스케일링 결정
                decision = await self._make_scaling_decision(metrics)
                
                if decision:
                    # 스케일링 실행
                    await self._execute_scaling_decision(decision)
                    self.scaling_history.append(decision)
                
                # 히스토리 정리
                await self._cleanup_history()
                
                await asyncio.sleep(30)  # 30초마다 확인
                
            except Exception as e:
                logger.error(f"Error in scaling monitoring: {e}")
                await asyncio.sleep(60)
    
    async def _collect_scaling_metrics(self) -> ScalingMetrics:
        """스케일링 메트릭 수집"""
        try:
            # Kubernetes 메트릭 수집
            pods = self.v1.list_namespaced_pod(
                namespace=self.namespace,
                label_selector="app=trading-app"
            )
            
            total_cpu = 0.0
            total_memory = 0.0
            pod_count = len(pods.items)
            
            for pod in pods.items:
                # Pod 메트릭 조회
                pod_metrics = self.v1.read_namespaced_pod(
                    name=pod.metadata.name,
                    namespace=self.namespace
                )
                
                # CPU 및 메모리 사용량 계산
                if pod_metrics.status.container_statuses:
                    for container in pod_metrics.status.container_statuses:
                        if container.name == 'trading-app':
                            # 실제 구현에서는 메트릭 서버에서 조회
                            total_cpu += 50.0  # 예시 값
                            total_memory += 60.0  # 예시 값
            
            avg_cpu = total_cpu / pod_count if pod_count > 0 else 0.0
            avg_memory = total_memory / pod_count if pod_count > 0 else 0.0
            
            # 애플리케이션 메트릭 조회
            request_rate = await self._get_request_rate()
            response_time = await self._get_average_response_time()
            error_rate = await self._get_error_rate()
            
            return ScalingMetrics(
                cpu_usage=avg_cpu,
                memory_usage=avg_memory,
                request_rate=request_rate,
                response_time=response_time,
                error_rate=error_rate,
                timestamp=datetime.now()
            )
            
        except Exception as e:
            logger.error(f"Failed to collect scaling metrics: {e}")
            return ScalingMetrics(
                cpu_usage=0.0,
                memory_usage=0.0,
                request_rate=0.0,
                response_time=0.0,
                error_rate=0.0,
                timestamp=datetime.now()
            )
    
    async def _make_scaling_decision(self, metrics: ScalingMetrics) -> Optional[ScalingDecision]:
        """스케일링 결정"""
        try:
            # 현재 레플리카 수 조회
            deployment = self.apps_v1.read_namespaced_deployment(
                name="trading-app",
                namespace=self.namespace
            )
            current_replicas = deployment.spec.replicas or 0
            
            # 스케일링 조건 확인
            should_scale_up = (
                metrics.cpu_usage > self.scaling_thresholds['cpu_high'] or
                metrics.memory_usage > self.scaling_thresholds['memory_high'] or
                metrics.request_rate > self.scaling_thresholds['request_rate_high'] or
                metrics.response_time > self.scaling_thresholds['response_time_high']
            )
            
            should_scale_down = (
                metrics.cpu_usage < self.scaling_thresholds['cpu_low'] and
                metrics.memory_usage < self.scaling_thresholds['memory_low'] and
                metrics.request_rate < self.scaling_thresholds['request_rate_low'] and
                current_replicas > 3  # 최소 레플리카 수
            )
            
            # 스케일링 결정
            if should_scale_up:
                target_replicas = min(current_replicas + 2, 50)  # 최대 50개
                reason = f"High load detected: CPU={metrics.cpu_usage:.1f}%, Memory={metrics.memory_usage:.1f}%"
                
                return ScalingDecision(
                    action='scale_up',
                    reason=reason,
                    current_replicas=current_replicas,
                    target_replicas=target_replicas,
                    metrics=metrics,
                    timestamp=datetime.now()
                )
                
            elif should_scale_down:
                target_replicas = max(current_replicas - 1, 3)  # 최소 3개
                reason = f"Low load detected: CPU={metrics.cpu_usage:.1f}%, Memory={metrics.memory_usage:.1f}%"
                
                return ScalingDecision(
                    action='scale_down',
                    reason=reason,
                    current_replicas=current_replicas,
                    target_replicas=target_replicas,
                    metrics=metrics,
                    timestamp=datetime.now()
                )
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to make scaling decision: {e}")
            return None
    
    async def _execute_scaling_decision(self, decision: ScalingDecision):
        """스케일링 결정 실행"""
        try:
            # 배포 업데이트
            deployment = self.apps_v1.read_namespaced_deployment(
                name="trading-app",
                namespace=self.namespace
            )
            
            deployment.spec.replicas = decision.target_replicas
            
            self.apps_v1.patch_namespaced_deployment(
                name="trading-app",
                namespace=self.namespace,
                body=deployment
            )
            
            logger.info(f"Scaling {decision.action}: {decision.current_replicas} -> {decision.target_replicas}")
            logger.info(f"Reason: {decision.reason}")
            
        except Exception as e:
            logger.error(f"Failed to execute scaling decision: {e}")
    
    async def _get_request_rate(self) -> float:
        """요청률 조회"""
        # 실제 구현에서는 메트릭 서버에서 조회
        return 500.0  # 예시 값
    
    async def _get_average_response_time(self) -> float:
        """평균 응답 시간 조회"""
        # 실제 구현에서는 메트릭 서버에서 조회
        return 150.0  # 예시 값
    
    async def _get_error_rate(self) -> float:
        """오류률 조회"""
        # 실제 구현에서는 메트릭 서버에서 조회
        return 2.0  # 예시 값
    
    async def _cleanup_history(self):
        """히스토리 정리"""
        try:
            # 24시간 이전 데이터 제거
            cutoff_time = datetime.now() - timedelta(hours=24)
            
            self.metrics_history = [
                m for m in self.metrics_history
                if m.timestamp > cutoff_time
            ]
            
            self.scaling_history = [
                s for s in self.scaling_history
                if s.timestamp > cutoff_time
            ]
            
        except Exception as e:
            logger.error(f"Failed to cleanup history: {e}")
    
    def get_scaling_summary(self) -> Dict[str, Any]:
        """스케일링 요약"""
        try:
            recent_decisions = [
                d for d in self.scaling_history
                if d.timestamp > datetime.now() - timedelta(hours=1)
            ]
            
            scale_ups = sum(1 for d in recent_decisions if d.action == 'scale_up')
            scale_downs = sum(1 for d in recent_decisions if d.action == 'scale_down')
            
            return {
                'total_decisions_1h': len(recent_decisions),
                'scale_ups_1h': scale_ups,
                'scale_downs_1h': scale_downs,
                'current_replicas': self._get_current_replicas(),
                'scaling_thresholds': self.scaling_thresholds,
                'last_decision': recent_decisions[-1].__dict__ if recent_decisions else None
            }
            
        except Exception as e:
            logger.error(f"Failed to get scaling summary: {e}")
            return {}
    
    def _get_current_replicas(self) -> int:
        """현재 레플리카 수 조회"""
        try:
            deployment = self.apps_v1.read_namespaced_deployment(
                name="trading-app",
                namespace=self.namespace
            )
            return deployment.spec.replicas or 0
        except:
            return 0
    
    def stop_monitoring(self):
        """스케일링 모니터링 중지"""
        self.is_running = False
        logger.info("Stopped scaling monitoring")
```

## 🗄️ **데이터베이스 최적화**

### 📦 **읽기 복제본 설정**

```yaml
# infrastructure/database/read_replicas/postgres-replicas.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: postgres-config
  namespace: trading-system
data:
  POSTGRES_DB: trading
  POSTGRES_USER: trading_user
  POSTGRES_PASSWORD: trading_password
  MASTER_HOST: postgres-master
  MASTER_PORT: "5432"
  REPLICA_HOSTS: "postgres-replica-1,postgres-replica-2,postgres-replica-3"

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-master
  namespace: trading-system
spec:
  serviceName: postgres-master
  replicas: 1
  selector:
    matchLabels:
      app: postgres-master
  template:
    metadata:
      labels:
        app: postgres-master
    spec:
      containers:
      - name: postgres
        image: postgres:13
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_DB
        - name: POSTGRES_USER
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_PASSWORD
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-master
  namespace: trading-system
spec:
  selector:
    app: postgres-master
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres-replicas
  namespace: trading-system
spec:
  serviceName: postgres-replicas
  replicas: 3
  selector:
    matchLabels:
      app: postgres-replica
  template:
    metadata:
      labels:
        app: postgres-replica
    spec:
      containers:
      - name: postgres
        image: postgres:13
        ports:
        - containerPort: 5432
        env:
        - name: POSTGRES_DB
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_DB
        - name: POSTGRES_USER
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_USER
        - name: POSTGRES_PASSWORD
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: POSTGRES_PASSWORD
        - name: MASTER_HOST
          valueFrom:
            configMapKeyRef:
              name: postgres-config
              key: MASTER_HOST
        volumeMounts:
        - name: postgres-storage
          mountPath: /var/lib/postgresql/data
  volumeClaimTemplates:
  - metadata:
      name: postgres-storage
    spec:
      accessModes: ["ReadWriteOnce"]
      resources:
        requests:
          storage: 100Gi

---
apiVersion: v1
kind: Service
metadata:
  name: postgres-replicas
  namespace: trading-system
spec:
  selector:
    app: postgres-replica
  ports:
  - port: 5432
    targetPort: 5432
  type: ClusterIP
```

### 🔧 **데이터베이스 연결 관리자**

```python
# infrastructure/database/read_replicas/db_manager.py
import asyncio
import random
from typing import Dict, List, Optional, Any
from contextlib import asynccontextmanager
import asyncpg
from dataclasses import dataclass

@dataclass
class DatabaseConnection:
    """데이터베이스 연결 정보"""
    host: str
    port: int
    database: str
    user: str
    password: str
    is_master: bool
    is_healthy: bool = True
    last_health_check: Optional[datetime] = None

class DatabaseManager:
    """데이터베이스 관리자"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.master_connection = None
        self.replica_connections = []
        self.connection_pools = {}
        self.health_check_interval = 30  # 30초
        
        logger.info("Initialized database manager")
    
    async def initialize(self):
        """데이터베이스 초기화"""
        try:
            # 마스터 연결 설정
            master_config = self.config['master']
            self.master_connection = DatabaseConnection(
                host=master_config['host'],
                port=master_config['port'],
                database=master_config['database'],
                user=master_config['user'],
                password=master_config['password'],
                is_master=True
            )
            
            # 마스터 연결 풀 생성
            self.connection_pools['master'] = await asyncpg.create_pool(
                host=self.master_connection.host,
                port=self.master_connection.port,
                database=self.master_connection.database,
                user=self.master_connection.user,
                password=self.master_connection.password,
                min_size=5,
                max_size=20
            )
            
            # 복제본 연결 설정
            for replica_config in self.config['replicas']:
                replica_connection = DatabaseConnection(
                    host=replica_config['host'],
                    port=replica_config['port'],
                    database=replica_config['database'],
                    user=replica_config['user'],
                    password=replica_config['password'],
                    is_master=False
                )
                
                self.replica_connections.append(replica_connection)
                
                # 복제본 연결 풀 생성
                pool_name = f"replica_{replica_connection.host}"
                self.connection_pools[pool_name] = await asyncpg.create_pool(
                    host=replica_connection.host,
                    port=replica_connection.port,
                    database=replica_connection.database,
                    user=replica_connection.user,
                    password=replica_connection.password,
                    min_size=3,
                    max_size=10
                )
            
            logger.info(f"Initialized database manager with {len(self.replica_connections)} replicas")
            
        except Exception as e:
            logger.error(f"Failed to initialize database manager: {e}")
            raise
    
    @asynccontextmanager
    async def get_master_connection(self):
        """마스터 연결 획득"""
        if 'master' not in self.connection_pools:
            raise Exception("Master connection pool not available")
        
        async with self.connection_pools['master'].acquire() as conn:
            yield conn
    
    @asynccontextmanager
    async def get_replica_connection(self):
        """복제본 연결 획득 (로드 밸런싱)"""
        healthy_replicas = [
            name for name, pool in self.connection_pools.items()
            if name != 'master' and self._is_pool_healthy(name)
        ]
        
        if not healthy_replicas:
            # 복제본이 없으면 마스터 사용
            async with self.get_master_connection() as conn:
                yield conn
            return
        
        # 랜덤 선택 (실제로는 더 정교한 로드 밸런싱 사용)
        selected_replica = random.choice(healthy_replicas)
        
        async with self.connection_pools[selected_replica].acquire() as conn:
            yield conn
    
    async def execute_write(self, query: str, *args) -> Any:
        """쓰기 작업 실행 (마스터)"""
        async with self.get_master_connection() as conn:
            return await conn.execute(query, *args)
    
    async def execute_read(self, query: str, *args) -> List[Any]:
        """읽기 작업 실행 (복제본)"""
        async with self.get_replica_connection() as conn:
            return await conn.fetch(query, *args)
    
    async def execute_transaction(self, queries: List[tuple]) -> List[Any]:
        """트랜잭션 실행 (마스터)"""
        async with self.get_master_connection() as conn:
            async with conn.transaction():
                results = []
                for query, args in queries:
                    result = await conn.execute(query, *args)
                    results.append(result)
                return results
    
    def _is_pool_healthy(self, pool_name: str) -> bool:
        """연결 풀 건강 상태 확인"""
        try:
            pool = self.connection_pools[pool_name]
            return not pool.is_closed()
        except:
            return False
    
    async def health_check(self):
        """건강 상태 확인"""
        try:
            # 마스터 건강 상태 확인
            async with self.get_master_connection() as conn:
                await conn.execute("SELECT 1")
                self.master_connection.is_healthy = True
                self.master_connection.last_health_check = datetime.now()
            
            # 복제본 건강 상태 확인
            for replica in self.replica_connections:
                pool_name = f"replica_{replica.host}"
                if pool_name in self.connection_pools:
                    try:
                        async with self.connection_pools[pool_name].acquire() as conn:
                            await conn.execute("SELECT 1")
                            replica.is_healthy = True
                            replica.last_health_check = datetime.now()
                    except Exception as e:
                        replica.is_healthy = False
                        logger.warning(f"Replica {replica.host} is unhealthy: {e}")
                        
        except Exception as e:
            logger.error(f"Database health check failed: {e}")
    
    async def get_database_stats(self) -> Dict[str, Any]:
        """데이터베이스 통계 조회"""
        try:
            stats = {
                'master': {
                    'host': self.master_connection.host,
                    'is_healthy': self.master_connection.is_healthy,
                    'last_health_check': self.master_connection.last_health_check.isoformat() if self.master_connection.last_health_check else None
                },
                'replicas': [
                    {
                        'host': replica.host,
                        'is_healthy': replica.is_healthy,
                        'last_health_check': replica.last_health_check.isoformat() if replica.last_health_check else None
                    }
                    for replica in self.replica_connections
                ],
                'connection_pools': {
                    name: {
                        'size': pool.get_size(),
                        'free_size': pool.get_free_size(),
                        'is_closed': pool.is_closed()
                    }
                    for name, pool in self.connection_pools.items()
                }
            }
            
            return stats
            
        except Exception as e:
            logger.error(f"Failed to get database stats: {e}")
            return {}
    
    async def close(self):
        """연결 풀 종료"""
        try:
            for pool in self.connection_pools.values():
                await pool.close()
            
            logger.info("Closed all database connection pools")
            
        except Exception as e:
            logger.error(f"Failed to close database pools: {e}")
```

## 🗄️ **캐싱 시스템**

### 📦 **Redis 클러스터 설정**

```yaml
# infrastructure/caching/redis-cluster.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: redis-config
  namespace: trading-system
data:
  redis.conf: |
    cluster-enabled yes
    cluster-config-file nodes.conf
    cluster-node-timeout 5000
    appendonly yes
    appendfsync everysec
    maxmemory-policy allkeys-lru
    maxmemory 2gb

---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: redis-cluster
  namespace: trading-system
spec:
  serviceName: redis-cluster
  replicas: 6
  selector:
    matchLabels:
      app: redis-cluster
  template:
    metadata:
      labels:
        app: redis-cluster
    spec:
      containers:
      - name: redis
        image: redis:6-alpine
        ports:
        - containerPort: 6379
        - containerPort: 16379
        command:
        - redis-server
        - /etc/redis/redis.conf
        volumeMounts:
        - name: redis-config
          mountPath: /etc/redis
        - name: redis-data
          mountPath: /data
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
      volumes:
      - name: redis-config
        configMap:
          name: redis-config

---
apiVersion: v1
kind: Service
metadata:
  name: redis-cluster
  namespace: trading-system
spec:
  selector:
    app: redis-cluster
  ports:
  - port: 6379
    targetPort: 6379
    name: redis
  - port: 16379
    targetPort: 16379
    name: cluster
  type: ClusterIP
```

### 🔧 **다층 캐싱 매니저**

```python
# infrastructure/caching/multi_layer/cache_manager.py
import asyncio
import json
import hashlib
from typing import Dict, List, Optional, Any, Union
from datetime import datetime, timedelta
import redis.asyncio as redis
from dataclasses import dataclass

@dataclass
class CacheConfig:
    """캐시 설정"""
    ttl: int = 300  # 5분
    max_size: int = 1000
    enable_compression: bool = True
    enable_encryption: bool = False

class MultiLayerCacheManager:
    """다층 캐싱 관리자"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.l1_cache = {}  # 메모리 캐시 (L1)
        self.l2_cache = None  # Redis 캐시 (L2)
        self.cache_stats = {
            'l1_hits': 0,
            'l1_misses': 0,
            'l2_hits': 0,
            'l2_misses': 0,
            'writes': 0
        }
        
        logger.info("Initialized multi-layer cache manager")
    
    async def initialize(self):
        """캐시 초기화"""
        try:
            # Redis 연결 설정
            self.l2_cache = redis.Redis(
                host=self.config['redis']['host'],
                port=self.config['redis']['port'],
                db=self.config['redis']['db'],
                decode_responses=True
            )
            
            # 연결 테스트
            await self.l2_cache.ping()
            
            logger.info("Initialized L2 cache (Redis)")
            
        except Exception as e:
            logger.error(f"Failed to initialize L2 cache: {e}")
            self.l2_cache = None
    
    async def get(self, key: str, default: Any = None) -> Any:
        """캐시에서 값 조회"""
        try:
            # L1 캐시 확인
            if key in self.l1_cache:
                cache_entry = self.l1_cache[key]
                if not self._is_expired(cache_entry):
                    self.cache_stats['l1_hits'] += 1
                    return cache_entry['value']
                else:
                    # 만료된 항목 제거
                    del self.l1_cache[key]
            
            self.cache_stats['l1_misses'] += 1
            
            # L2 캐시 확인
            if self.l2_cache:
                try:
                    cached_value = await self.l2_cache.get(key)
                    if cached_value:
                        # L1 캐시에 저장
                        self._set_l1_cache(key, json.loads(cached_value))
                        self.cache_stats['l2_hits'] += 1
                        return json.loads(cached_value)
                    else:
                        self.cache_stats['l2_misses'] += 1
                except Exception as e:
                    logger.error(f"L2 cache get error: {e}")
                    self.cache_stats['l2_misses'] += 1
            
            return default
            
        except Exception as e:
            logger.error(f"Cache get error: {e}")
            return default
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None) -> bool:
        """캐시에 값 저장"""
        try:
            # TTL 설정
            if ttl is None:
                ttl = self.config.get('default_ttl', 300)
            
            # L1 캐시에 저장
            self._set_l1_cache(key, value, ttl)
            
            # L2 캐시에 저장
            if self.l2_cache:
                try:
                    serialized_value = json.dumps(value)
                    await self.l2_cache.setex(key, ttl, serialized_value)
                except Exception as e:
                    logger.error(f"L2 cache set error: {e}")
            
            self.cache_stats['writes'] += 1
            return True
            
        except Exception as e:
            logger.error(f"Cache set error: {e}")
            return False
    
    async def delete(self, key: str) -> bool:
        """캐시에서 값 삭제"""
        try:
            # L1 캐시에서 삭제
            if key in self.l1_cache:
                del self.l1_cache[key]
            
            # L2 캐시에서 삭제
            if self.l2_cache:
                try:
                    await self.l2_cache.delete(key)
                except Exception as e:
                    logger.error(f"L2 cache delete error: {e}")
            
            return True
            
        except Exception as e:
            logger.error(f"Cache delete error: {e}")
            return False
    
    async def invalidate_pattern(self, pattern: str) -> int:
        """패턴에 맞는 캐시 무효화"""
        try:
            deleted_count = 0
            
            # L1 캐시에서 패턴 매칭 항목 삭제
            keys_to_delete = [
                key for key in self.l1_cache.keys()
                if self._matches_pattern(key, pattern)
            ]
            
            for key in keys_to_delete:
                del self.l1_cache[key]
                deleted_count += 1
            
            # L2 캐시에서 패턴 매칭 항목 삭제
            if self.l2_cache:
                try:
                    keys = await self.l2_cache.keys(pattern)
                    if keys:
                        await self.l2_cache.delete(*keys)
                        deleted_count += len(keys)
                except Exception as e:
                    logger.error(f"L2 cache pattern delete error: {e}")
            
            return deleted_count
            
        except Exception as e:
            logger.error(f"Cache pattern invalidation error: {e}")
            return 0
    
    def _set_l1_cache(self, key: str, value: Any, ttl: int = 300):
        """L1 캐시에 값 저장"""
        # L1 캐시 크기 제한
        if len(self.l1_cache) >= self.config.get('l1_max_size', 1000):
            # LRU 정책으로 오래된 항목 제거
            oldest_key = min(self.l1_cache.keys(), key=lambda k: self.l1_cache[k]['timestamp'])
            del self.l1_cache[oldest_key]
        
        self.l1_cache[key] = {
            'value': value,
            'timestamp': datetime.now(),
            'ttl': ttl
        }
    
    def _is_expired(self, cache_entry: Dict[str, Any]) -> bool:
        """캐시 항목 만료 확인"""
        expiry_time = cache_entry['timestamp'] + timedelta(seconds=cache_entry['ttl'])
        return datetime.now() > expiry_time
    
    def _matches_pattern(self, key: str, pattern: str) -> bool:
        """패턴 매칭 확인"""
        # 간단한 와일드카드 매칭
        if '*' in pattern:
            pattern_parts = pattern.split('*')
            key_parts = key.split('*')
            
            if len(pattern_parts) != len(key_parts):
                return False
            
            for p_part, k_part in zip(pattern_parts, key_parts):
                if p_part and p_part not in k_part:
                    return False
            
            return True
        else:
            return key == pattern
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """캐시 통계 조회"""
        total_l1_requests = self.cache_stats['l1_hits'] + self.cache_stats['l1_misses']
        total_l2_requests = self.cache_stats['l2_hits'] + self.cache_stats['l2_misses']
        
        return {
            'l1_cache': {
                'size': len(self.l1_cache),
                'hits': self.cache_stats['l1_hits'],
                'misses': self.cache_stats['l1_misses'],
                'hit_rate': (self.cache_stats['l1_hits'] / total_l1_requests * 100) if total_l1_requests > 0 else 0
            },
            'l2_cache': {
                'hits': self.cache_stats['l2_hits'],
                'misses': self.cache_stats['l2_misses'],
                'hit_rate': (self.cache_stats['l2_hits'] / total_l2_requests * 100) if total_l2_requests > 0 else 0
            },
            'writes': self.cache_stats['writes'],
            'total_requests': total_l1_requests
        }
    
    async def clear_all(self):
        """모든 캐시 클리어"""
        try:
            # L1 캐시 클리어
            self.l1_cache.clear()
            
            # L2 캐시 클리어
            if self.l2_cache:
                await self.l2_cache.flushdb()
            
            logger.info("Cleared all caches")
            
        except Exception as e:
            logger.error(f"Failed to clear caches: {e}")
```

## 🌐 **CDN 및 엣지 컴퓨팅**

### 📦 **CloudFront 설정**

```yaml
# infrastructure/cdn/cloudfront-distribution.yaml
apiVersion: cloudfront.aws.amazon.com/v1
kind: Distribution
metadata:
  name: trading-cdn
spec:
  enabled: true
  defaultCacheBehavior:
    targetOriginId: trading-origin
    viewerProtocolPolicy: redirect-to-https
    allowedMethods:
      - GET
      - HEAD
      - OPTIONS
    cachedMethods:
      - GET
      - HEAD
    forwardedValues:
      queryString: false
      cookies:
        forward: none
    minTTL: 0
    defaultTTL: 86400  # 24시간
    maxTTL: 31536000   # 1년
    compress: true
    lambdaFunctionAssociations:
      - eventType: viewer-request
        lambdaFunctionARN: arn:aws:lambda:us-east-1:123456789012:function:edge-function
  origins:
    - id: trading-origin
      domainName: trading.example.com
      customOriginConfig:
        httpPort: 80
        httpsPort: 443
        originProtocolPolicy: https-only
  priceClass: PriceClass_100  # US, Canada, Europe
  aliases:
    - cdn.trading.example.com
  viewerCertificate:
    acmCertificateArn: arn:aws:acm:us-east-1:123456789012:certificate/xxx
    sslSupportMethod: sni-only
    minimumProtocolVersion: TLSv1.2_2021
```

### 🔧 **엣지 함수**

```javascript
// infrastructure/cdn/edge_computing/edge-function.js
'use strict';

exports.handler = async (event) => {
    const request = event.Records[0].cf.request;
    const headers = request.headers;
    
    // 사용자 위치 기반 라우팅
    const country = headers['cloudfront-viewer-country']?.[0]?.value;
    const region = headers['cloudfront-viewer-country-region']?.[0]?.value;
    
    // 지역별 최적화된 엔드포인트로 라우팅
    if (country === 'US') {
        request.origin.custom.domainName = 'us-east-1.trading.example.com';
    } else if (country === 'JP') {
        request.origin.custom.domainName = 'ap-northeast-1.trading.example.com';
    } else if (country === 'DE') {
        request.origin.custom.domainName = 'eu-central-1.trading.example.com';
    }
    
    // API 요청에 대한 캐싱 최적화
    if (request.uri.startsWith('/api/')) {
        // 동적 API 응답은 캐싱하지 않음
        request.headers['cache-control'] = [{
            key: 'Cache-Control',
            value: 'no-cache, no-store, must-revalidate'
        }];
    } else if (request.uri.startsWith('/static/')) {
        // 정적 자산은 장기 캐싱
        request.headers['cache-control'] = [{
            key: 'Cache-Control',
            value: 'public, max-age=31536000, immutable'
        }];
    }
    
    // 보안 헤더 추가
    request.headers['x-frame-options'] = [{
        key: 'X-Frame-Options',
        value: 'DENY'
    }];
    
    request.headers['x-content-type-options'] = [{
        key: 'X-Content-Type-Options',
        value: 'nosniff'
    }];
    
    request.headers['strict-transport-security'] = [{
        key: 'Strict-Transport-Security',
        value: 'max-age=31536000; includeSubDomains'
    }];
    
    return request;
};
```

## 🎯 **다음 단계**

### 📋 **완료된 작업**
- ✅ 자동 스케일링 시스템
- ✅ 데이터베이스 읽기 복제본
- ✅ 다층 캐싱 시스템
- ✅ CDN 및 엣지 컴퓨팅

### 🔄 **진행 중인 작업**
- 🔄 샤딩 전략 구현
- 🔄 글로벌 로드 밸런싱
- 🔄 성능 모니터링

### ⏳ **다음 단계**
1. **Phase 2 마이크로서비스** 시작
2. **공통 컴포넌트** 완성
3. **템플릿 및 도구** 생성

---

**마지막 업데이트**: 2024-01-31
**다음 업데이트**: 2024-02-01 (Phase 2 마이크로서비스 시작)
**인프라 목표**: 10,000 TPS, < 50ms 응답시간, 99.99% 가용성
**확장성**: 10배 트래픽 증가 시 자동 스케일링 