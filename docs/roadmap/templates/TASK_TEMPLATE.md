# ğŸ“ ì‘ì—… í…œí”Œë¦¿

## ğŸ“‹ **ì‘ì—… ê°œìš”**

### ğŸ¯ **ì‘ì—… ëª©í‘œ**
- **ì‘ì—…ëª…**: [ì‘ì—… ì´ë¦„]
- **ì‘ì—… ID**: [ì‘ì—… ID]
- **ìš°ì„ ìˆœìœ„**: [High/Medium/Low]
- **ì˜ˆìƒ ì†Œìš” ì‹œê°„**: [ì‹œê°„]
- **ë‹´ë‹¹ì**: [ë‹´ë‹¹ìëª…]

### ğŸ“Š **ì„±ê³¼ ì§€í‘œ**
- **ì™„ë£Œ ê¸°ì¤€**: ëª…í™•í•œ ì™„ë£Œ ê¸°ì¤€ ì •ì˜
- **ì„±ëŠ¥ ëª©í‘œ**: ì„±ëŠ¥ ì§€í‘œ ë° ëª©í‘œê°’
- **í’ˆì§ˆ ê¸°ì¤€**: í’ˆì§ˆ ìš”êµ¬ì‚¬í•­

## ğŸ”§ **êµ¬í˜„ ê³„íš**

### ğŸ“‹ **êµ¬í˜„ ë‹¨ê³„**
1. **ë¶„ì„ ë‹¨ê³„**: ìš”êµ¬ì‚¬í•­ ë¶„ì„ ë° ì„¤ê³„
2. **êµ¬í˜„ ë‹¨ê³„**: ì½”ë“œ êµ¬í˜„
3. **í…ŒìŠ¤íŠ¸ ë‹¨ê³„**: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë° í†µí•© í…ŒìŠ¤íŠ¸
4. **ê²€ì¦ ë‹¨ê³„**: ì„±ëŠ¥ ë° í’ˆì§ˆ ê²€ì¦
5. **ë°°í¬ ë‹¨ê³„**: ë°°í¬ ë° ëª¨ë‹ˆí„°ë§

### ğŸ—ï¸ **ê¸°ìˆ  ìŠ¤íƒ**
- **ì–¸ì–´**: Python 3.11+
- **í”„ë ˆì„ì›Œí¬**: FastAPI, SQLAlchemy
- **ë°ì´í„°ë² ì´ìŠ¤**: PostgreSQL, Redis
- **í…ŒìŠ¤íŠ¸**: pytest, pytest-asyncio
- **ëª¨ë‹ˆí„°ë§**: Prometheus, Grafana

## ğŸ’» **ì½”ë“œ êµ¬í˜„**

### ğŸ“¦ **ì£¼ìš” í´ë˜ìŠ¤**

```python
# ì£¼ìš” í´ë˜ìŠ¤ ì˜ˆì‹œ
class TaskComponent:
    """ì‘ì—… ì»´í¬ë„ŒíŠ¸"""
    
    def __init__(self, config: dict):
        """ì´ˆê¸°í™”"""
        self.config = config
        self.logger = logging.getLogger(__name__)
        self.metrics = MetricsCollector()
    
    async def execute_task(self, task_data: dict) -> dict:
        """ì‘ì—… ì‹¤í–‰"""
        try:
            # 1. ì…ë ¥ ê²€ì¦
            self._validate_input(task_data)
            
            # 2. ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì‹¤í–‰
            result = await self._process_business_logic(task_data)
            
            # 3. ê²°ê³¼ ê²€ì¦
            self._validate_result(result)
            
            # 4. ë©”íŠ¸ë¦­ ê¸°ë¡
            self.metrics.record_success()
            
            return result
            
        except Exception as e:
            self.logger.error(f"Task execution failed: {e}")
            self.metrics.record_error()
            raise
    
    def _validate_input(self, task_data: dict) -> bool:
        """ì…ë ¥ ê²€ì¦"""
        # ì…ë ¥ ë°ì´í„° ê²€ì¦ ë¡œì§
        required_fields = ['field1', 'field2', 'field3']
        
        for field in required_fields:
            if field not in task_data:
                raise ValueError(f"Missing required field: {field}")
        
        return True
    
    async def _process_business_logic(self, task_data: dict) -> dict:
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬"""
        # ì‹¤ì œ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ êµ¬í˜„
        result = {
            'status': 'success',
            'data': task_data,
            'processed_at': datetime.now().isoformat()
        }
        
        return result
    
    def _validate_result(self, result: dict) -> bool:
        """ê²°ê³¼ ê²€ì¦"""
        # ê²°ê³¼ ë°ì´í„° ê²€ì¦ ë¡œì§
        if 'status' not in result:
            raise ValueError("Missing status in result")
        
        return True
```

### ğŸ”§ **ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜**

```python
# ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì˜ˆì‹œ
def format_task_data(raw_data: dict) -> dict:
    """ì‘ì—… ë°ì´í„° í¬ë§·íŒ…"""
    formatted_data = {}
    
    # ë°ì´í„° ì •ê·œí™”
    for key, value in raw_data.items():
        formatted_key = key.lower().replace(' ', '_')
        formatted_data[formatted_key] = value
    
    return formatted_data

def calculate_task_metrics(task_results: List[dict]) -> dict:
    """ì‘ì—… ë©”íŠ¸ë¦­ ê³„ì‚°"""
    total_tasks = len(task_results)
    successful_tasks = len([r for r in task_results if r.get('status') == 'success'])
    
    return {
        'total_tasks': total_tasks,
        'successful_tasks': successful_tasks,
        'success_rate': (successful_tasks / total_tasks * 100) if total_tasks > 0 else 0,
        'avg_processing_time': calculate_avg_processing_time(task_results)
    }

def calculate_avg_processing_time(task_results: List[dict]) -> float:
    """í‰ê·  ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°"""
    processing_times = []
    
    for result in task_results:
        if 'processing_time' in result:
            processing_times.append(result['processing_time'])
    
    return sum(processing_times) / len(processing_times) if processing_times else 0.0
```

## ğŸ§ª **í…ŒìŠ¤íŠ¸ êµ¬í˜„**

### ğŸ“‹ **í…ŒìŠ¤íŠ¸ ê³„íš**
- **ë‹¨ìœ„ í…ŒìŠ¤íŠ¸**: ê° í•¨ìˆ˜ë³„ í…ŒìŠ¤íŠ¸
- **í†µí•© í…ŒìŠ¤íŠ¸**: ì „ì²´ ì›Œí¬í”Œë¡œìš° í…ŒìŠ¤íŠ¸
- **ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**: ì„±ëŠ¥ ë° ë¶€í•˜ í…ŒìŠ¤íŠ¸
- **ì˜ˆì™¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸**: ì˜¤ë¥˜ ìƒí™© í…ŒìŠ¤íŠ¸

### ğŸ”§ **í…ŒìŠ¤íŠ¸ ì½”ë“œ**

```python
# í…ŒìŠ¤íŠ¸ ì˜ˆì‹œ
import pytest
from unittest.mock import Mock, patch
from datetime import datetime

class TestTaskComponent:
    """ì‘ì—… ì»´í¬ë„ŒíŠ¸ í…ŒìŠ¤íŠ¸"""
    
    def setup_method(self):
        """í…ŒìŠ¤íŠ¸ ì„¤ì •"""
        self.config = {
            'timeout': 30,
            'retry_count': 3,
            'max_concurrent': 10
        }
        self.component = TaskComponent(self.config)
    
    def test_validate_input_success(self):
        """ì…ë ¥ ê²€ì¦ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        valid_data = {
            'field1': 'value1',
            'field2': 'value2',
            'field3': 'value3'
        }
        
        result = self.component._validate_input(valid_data)
        assert result is True
    
    def test_validate_input_missing_field(self):
        """ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ - í•„ìˆ˜ í•„ë“œ ëˆ„ë½"""
        invalid_data = {
            'field1': 'value1',
            'field2': 'value2'
            # field3 ëˆ„ë½
        }
        
        with pytest.raises(ValueError, match="Missing required field: field3"):
            self.component._validate_input(invalid_data)
    
    @pytest.mark.asyncio
    async def test_process_business_logic_success(self):
        """ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§ ì²˜ë¦¬ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        task_data = {
            'field1': 'value1',
            'field2': 'value2',
            'field3': 'value3'
        }
        
        result = await self.component._process_business_logic(task_data)
        
        assert result['status'] == 'success'
        assert result['data'] == task_data
        assert 'processed_at' in result
    
    @pytest.mark.asyncio
    async def test_execute_task_success(self):
        """ì‘ì—… ì‹¤í–‰ ì„±ê³µ í…ŒìŠ¤íŠ¸"""
        task_data = {
            'field1': 'value1',
            'field2': 'value2',
            'field3': 'value3'
        }
        
        result = await self.component.execute_task(task_data)
        
        assert result['status'] == 'success'
        assert result['data'] == task_data
    
    @pytest.mark.asyncio
    async def test_execute_task_validation_failure(self):
        """ì‘ì—… ì‹¤í–‰ ì‹¤íŒ¨ í…ŒìŠ¤íŠ¸ - ê²€ì¦ ì‹¤íŒ¨"""
        invalid_data = {
            'field1': 'value1'
            # í•„ìˆ˜ í•„ë“œ ëˆ„ë½
        }
        
        with pytest.raises(ValueError):
            await self.component.execute_task(invalid_data)

class TestUtilityFunctions:
    """ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í…ŒìŠ¤íŠ¸"""
    
    def test_format_task_data(self):
        """ì‘ì—… ë°ì´í„° í¬ë§·íŒ… í…ŒìŠ¤íŠ¸"""
        raw_data = {
            'User Name': 'John Doe',
            'Email Address': 'john@example.com',
            'Phone Number': '123-456-7890'
        }
        
        formatted_data = format_task_data(raw_data)
        
        expected_data = {
            'user_name': 'John Doe',
            'email_address': 'john@example.com',
            'phone_number': '123-456-7890'
        }
        
        assert formatted_data == expected_data
    
    def test_calculate_task_metrics(self):
        """ì‘ì—… ë©”íŠ¸ë¦­ ê³„ì‚° í…ŒìŠ¤íŠ¸"""
        task_results = [
            {'status': 'success', 'processing_time': 1.0},
            {'status': 'success', 'processing_time': 2.0},
            {'status': 'error', 'processing_time': 0.5},
            {'status': 'success', 'processing_time': 1.5}
        ]
        
        metrics = calculate_task_metrics(task_results)
        
        assert metrics['total_tasks'] == 4
        assert metrics['successful_tasks'] == 3
        assert metrics['success_rate'] == 75.0
        assert metrics['avg_processing_time'] == 1.25
```

## ğŸ“Š **ì„±ëŠ¥ ìµœì í™”**

### ğŸ¯ **ì„±ëŠ¥ ëª©í‘œ**
- **ì‘ë‹µ ì‹œê°„**: < 50ms
- **ì²˜ë¦¬ëŸ‰**: > 1000 TPS
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: < 100MB
- **CPU ì‚¬ìš©ë¥ **: < 70%

### ğŸ”§ **ìµœì í™” ê¸°ë²•**
- **ë¹„ë™ê¸° ì²˜ë¦¬**: asyncio í™œìš©
- **ìºì‹±**: Redis ìºì‹± êµ¬í˜„
- **ë©”ëª¨ë¦¬ í’€**: ê°ì²´ ì¬ì‚¬ìš©
- **ë°°ì¹˜ ì²˜ë¦¬**: ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìµœì í™”

```python
# ì„±ëŠ¥ ìµœì í™” ì˜ˆì‹œ
import asyncio
from typing import List
import redis

class OptimizedTaskProcessor:
    """ìµœì í™”ëœ ì‘ì—… í”„ë¡œì„¸ì„œ"""
    
    def __init__(self):
        self.redis_client = redis.Redis(host='localhost', port=6379, db=0)
        self.cache_ttl = 300  # 5ë¶„
    
    async def process_batch_tasks(self, tasks: List[dict]) -> List[dict]:
        """ë°°ì¹˜ ì‘ì—… ì²˜ë¦¬"""
        # ìºì‹œ í™•ì¸
        cached_results = await self._get_cached_results(tasks)
        
        # ìºì‹œë˜ì§€ ì•Šì€ ì‘ì—…ë§Œ ì²˜ë¦¬
        uncached_tasks = [task for task in tasks if task['id'] not in cached_results]
        
        if uncached_tasks:
            # ë³‘ë ¬ ì²˜ë¦¬
            processing_tasks = [
                self._process_single_task(task) for task in uncached_tasks
            ]
            
            new_results = await asyncio.gather(*processing_tasks)
            
            # ê²°ê³¼ ìºì‹±
            await self._cache_results(new_results)
            
            # ìºì‹œëœ ê²°ê³¼ì™€ ìƒˆ ê²°ê³¼ ë³‘í•©
            all_results = cached_results + new_results
        else:
            all_results = cached_results
        
        return all_results
    
    async def _process_single_task(self, task: dict) -> dict:
        """ë‹¨ì¼ ì‘ì—… ì²˜ë¦¬"""
        # ì‹¤ì œ ì‘ì—… ì²˜ë¦¬ ë¡œì§
        await asyncio.sleep(0.01)  # ì‹œë®¬ë ˆì´ì…˜
        
        return {
            'id': task['id'],
            'status': 'success',
            'result': f"Processed {task['id']}",
            'processing_time': 0.01
        }
    
    async def _get_cached_results(self, tasks: List[dict]) -> List[dict]:
        """ìºì‹œëœ ê²°ê³¼ ì¡°íšŒ"""
        cached_results = []
        
        for task in tasks:
            cache_key = f"task_result:{task['id']}"
            cached_data = self.redis_client.get(cache_key)
            
            if cached_data:
                cached_results.append(json.loads(cached_data))
        
        return cached_results
    
    async def _cache_results(self, results: List[dict]):
        """ê²°ê³¼ ìºì‹±"""
        for result in results:
            cache_key = f"task_result:{result['id']}"
            self.redis_client.setex(
                cache_key,
                self.cache_ttl,
                json.dumps(result)
            )
```

## ğŸ”’ **ë³´ì•ˆ ê³ ë ¤ì‚¬í•­**

### ğŸ›¡ï¸ **ë³´ì•ˆ ìš”êµ¬ì‚¬í•­**
- **ì…ë ¥ ê²€ì¦**: ëª¨ë“  ì…ë ¥ ë°ì´í„° ê²€ì¦
- **ì¸ì¦**: ì‚¬ìš©ì ì¸ì¦ í™•ì¸
- **ê¶Œí•œ**: ì‘ì—… ì‹¤í–‰ ê¶Œí•œ í™•ì¸
- **ë°ì´í„° ë³´í˜¸**: ë¯¼ê°í•œ ë°ì´í„° ì•”í˜¸í™”

### ğŸ”§ **ë³´ì•ˆ êµ¬í˜„**

```python
# ë³´ì•ˆ êµ¬í˜„ ì˜ˆì‹œ
import hashlib
import hmac
from cryptography.fernet import Fernet

class SecureTaskProcessor:
    """ë³´ì•ˆ ì‘ì—… í”„ë¡œì„¸ì„œ"""
    
    def __init__(self, secret_key: str):
        self.secret_key = secret_key.encode()
        self.cipher = Fernet(Fernet.generate_key())
    
    def validate_task_signature(self, task_data: dict, signature: str) -> bool:
        """ì‘ì—… ì„œëª… ê²€ì¦"""
        expected_signature = self._calculate_signature(task_data)
        return hmac.compare_digest(signature, expected_signature)
    
    def _calculate_signature(self, task_data: dict) -> str:
        """ì„œëª… ê³„ì‚°"""
        data_string = json.dumps(task_data, sort_keys=True)
        return hmac.new(
            self.secret_key,
            data_string.encode(),
            hashlib.sha256
        ).hexdigest()
    
    def encrypt_sensitive_data(self, data: str) -> str:
        """ë¯¼ê°í•œ ë°ì´í„° ì•”í˜¸í™”"""
        return self.cipher.encrypt(data.encode()).decode()
    
    def decrypt_sensitive_data(self, encrypted_data: str) -> str:
        """ë¯¼ê°í•œ ë°ì´í„° ë³µí˜¸í™”"""
        return self.cipher.decrypt(encrypted_data.encode()).decode()
```

## ğŸ“ˆ **ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…**

### ğŸ“Š **ëª¨ë‹ˆí„°ë§ ì§€í‘œ**
- **ì‘ì—… ì²˜ë¦¬ëŸ‰**: ì´ˆë‹¹ ì²˜ë¦¬ëœ ì‘ì—… ìˆ˜
- **ì„±ê³µë¥ **: ì‘ì—… ì„±ê³µ ë¹„ìœ¨
- **ì‘ë‹µ ì‹œê°„**: ì‘ì—… ì²˜ë¦¬ ì‹œê°„
- **ì—ëŸ¬ìœ¨**: ì‘ì—… ì‹¤íŒ¨ ë¹„ìœ¨

### ğŸ”§ **ëª¨ë‹ˆí„°ë§ êµ¬í˜„**

```python
# ëª¨ë‹ˆí„°ë§ êµ¬í˜„ ì˜ˆì‹œ
import time
from dataclasses import dataclass
from typing import Dict, List

@dataclass
class TaskMetrics:
    """ì‘ì—… ë©”íŠ¸ë¦­"""
    total_tasks: int
    successful_tasks: int
    failed_tasks: int
    avg_processing_time: float
    success_rate: float

class TaskMonitor:
    """ì‘ì—… ëª¨ë‹ˆí„°"""
    
    def __init__(self):
        self.metrics_history: List[TaskMetrics] = []
        self.current_metrics = TaskMetrics(0, 0, 0, 0.0, 0.0)
        self.lock = threading.Lock()
    
    def record_task_start(self, task_id: str):
        """ì‘ì—… ì‹œì‘ ê¸°ë¡"""
        with self.lock:
            self.current_metrics.total_tasks += 1
    
    def record_task_success(self, task_id: str, processing_time: float):
        """ì‘ì—… ì„±ê³µ ê¸°ë¡"""
        with self.lock:
            self.current_metrics.successful_tasks += 1
            self._update_avg_processing_time(processing_time)
            self._update_success_rate()
    
    def record_task_failure(self, task_id: str, processing_time: float):
        """ì‘ì—… ì‹¤íŒ¨ ê¸°ë¡"""
        with self.lock:
            self.current_metrics.failed_tasks += 1
            self._update_avg_processing_time(processing_time)
            self._update_success_rate()
    
    def _update_avg_processing_time(self, processing_time: float):
        """í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸"""
        total_tasks = self.current_metrics.successful_tasks + self.current_metrics.failed_tasks
        if total_tasks > 0:
            current_avg = self.current_metrics.avg_processing_time
            self.current_metrics.avg_processing_time = (
                (current_avg * (total_tasks - 1) + processing_time) / total_tasks
            )
    
    def _update_success_rate(self):
        """ì„±ê³µë¥  ì—…ë°ì´íŠ¸"""
        total_tasks = self.current_metrics.total_tasks
        if total_tasks > 0:
            self.current_metrics.success_rate = (
                self.current_metrics.successful_tasks / total_tasks * 100
            )
    
    def get_current_metrics(self) -> TaskMetrics:
        """í˜„ì¬ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        with self.lock:
            return TaskMetrics(
                self.current_metrics.total_tasks,
                self.current_metrics.successful_tasks,
                self.current_metrics.failed_tasks,
                self.current_metrics.avg_processing_time,
                self.current_metrics.success_rate
            )
    
    def save_metrics_snapshot(self):
        """ë©”íŠ¸ë¦­ ìŠ¤ëƒ…ìƒ· ì €ì¥"""
        with self.lock:
            self.metrics_history.append(
                TaskMetrics(
                    self.current_metrics.total_tasks,
                    self.current_metrics.successful_tasks,
                    self.current_metrics.failed_tasks,
                    self.current_metrics.avg_processing_time,
                    self.current_metrics.success_rate
                )
            )
```

## ğŸ“‹ **ì²´í¬ë¦¬ìŠ¤íŠ¸**

### âœ… **ì™„ë£Œ ê¸°ì¤€**
- [ ] ì½”ë“œ êµ¬í˜„ ì™„ë£Œ
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] í†µí•© í…ŒìŠ¤íŠ¸ ì‘ì„± ë° í†µê³¼
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë³´ì•ˆ ê²€ì¦ ì™„ë£Œ
- [ ] ë¬¸ì„œí™” ì™„ë£Œ
- [ ] ì½”ë“œ ë¦¬ë·° ì™„ë£Œ
- [ ] ë°°í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

### ğŸ“Š **í’ˆì§ˆ ì§€í‘œ**
- **ì½”ë“œ ì»¤ë²„ë¦¬ì§€**: > 90%
- **í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨**: 100%
- **ì„±ëŠ¥ ëª©í‘œ ë‹¬ì„±**: ëª¨ë“  ì„±ëŠ¥ ì§€í‘œ ë‹¬ì„±
- **ë³´ì•ˆ ì·¨ì•½ì **: 0ê±´
- **ë¬¸ì„œ ì™„ì„±ë„**: 100%

---

**í…œí”Œë¦¿ ë²„ì „**: 1.0
**ìµœì¢… ì—…ë°ì´íŠ¸**: 2024-01-31
**ë‹¤ìŒ ê²€í† **: 2024-02-01 