# ğŸ¤– Phase 3: AI/ML ê¸°ë°˜ ê±°ë˜ ì‹œìŠ¤í…œ

## ğŸ“‹ **ê°œìš”**

### ğŸ¯ **ëª©í‘œ**
- **AI ê¸°ë°˜ ì˜ˆì¸¡**: LSTM, Transformer ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸
- **ê°•í™”í•™ìŠµ ê±°ë˜**: Q-Learning, DDPG ê¸°ë°˜ ê±°ë˜ ì—ì´ì „íŠ¸
- **ê°ì • ë¶„ì„**: NLP ê¸°ë°˜ ë‰´ìŠ¤/ì†Œì…œ ê°ì • ë¶„ì„
- **í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”**: Modern Portfolio Theory + AI
- **ìë™í™” ê±°ë˜**: ì™„ì „ ìë™í™”ëœ ê±°ë˜ ì‹œìŠ¤í…œ

### ğŸ“Š **ì„±ëŠ¥ ëª©í‘œ**
- **ì˜ˆì¸¡ ì •í™•ë„**: > 65% (ì‹œì¥ í‰ê·  ëŒ€ë¹„)
- **ìˆ˜ìµë¥ **: > 20% ì—°ê°„ (ë¦¬ìŠ¤í¬ ì¡°ì •)
- **ìƒ¤í”„ ë¹„ìœ¨**: > 2.0
- **ìµœëŒ€ ë‚™í­**: < 15%
- **ëª¨ë¸ í•™ìŠµ ì‹œê°„**: < 2ì‹œê°„ (ì¼ì¼ ì¬í•™ìŠµ)

## ğŸ—ï¸ **AI/ML ì•„í‚¤í…ì²˜**

### ğŸ“ **AI/ML ì‹œìŠ¤í…œ êµ¬ì¡°**
```
ai-ml-system/
â”œâ”€â”€ prediction-models/              # ì˜ˆì¸¡ ëª¨ë¸
â”‚   â”œâ”€â”€ lstm/                      # LSTM ê¸°ë°˜ ì˜ˆì¸¡
â”‚   â”œâ”€â”€ transformer/               # Transformer ê¸°ë°˜ ì˜ˆì¸¡
â”‚   â”œâ”€â”€ ensemble/                  # ì•™ìƒë¸” ëª¨ë¸
â”‚   â””â”€â”€ time-series/               # ì‹œê³„ì—´ ë¶„ì„
â”œâ”€â”€ reinforcement-learning/         # ê°•í™”í•™ìŠµ
â”‚   â”œâ”€â”€ q-learning/                # Q-Learning ì—ì´ì „íŠ¸
â”‚   â”œâ”€â”€ ddpg/                      # DDPG ì—ì´ì „íŠ¸
â”‚   â”œâ”€â”€ ppo/                       # PPO ì—ì´ì „íŠ¸
â”‚   â””â”€â”€ multi-agent/               # ë‹¤ì¤‘ ì—ì´ì „íŠ¸
â”œâ”€â”€ sentiment-analysis/            # ê°ì • ë¶„ì„
â”‚   â”œâ”€â”€ news-analysis/             # ë‰´ìŠ¤ ë¶„ì„
â”‚   â”œâ”€â”€ social-media/              # ì†Œì…œ ë¯¸ë””ì–´ ë¶„ì„
â”‚   â”œâ”€â”€ nlp-models/                # NLP ëª¨ë¸
â”‚   â””â”€â”€ real-time/                 # ì‹¤ì‹œê°„ ë¶„ì„
â”œâ”€â”€ portfolio-optimization/        # í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
â”‚   â”œâ”€â”€ modern-portfolio/          # Modern Portfolio Theory
â”‚   â”œâ”€â”€ risk-management/           # ë¦¬ìŠ¤í¬ ê´€ë¦¬
â”‚   â”œâ”€â”€ rebalancing/               # ìë™ ë¦¬ë°¸ëŸ°ì‹±
â”‚   â””â”€â”€ optimization/              # ìµœì í™” ì•Œê³ ë¦¬ì¦˜
â”œâ”€â”€ data-pipeline/                 # ë°ì´í„° íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ data-collection/           # ë°ì´í„° ìˆ˜ì§‘
â”‚   â”œâ”€â”€ data-preprocessing/        # ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ feature-engineering/       # íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§
â”‚   â””â”€â”€ data-validation/           # ë°ì´í„° ê²€ì¦
â””â”€â”€ trading-execution/             # ê±°ë˜ ì‹¤í–‰
    â”œâ”€â”€ signal-generation/         # ì‹ í˜¸ ìƒì„±
    â”œâ”€â”€ order-execution/           # ì£¼ë¬¸ ì‹¤í–‰
    â”œâ”€â”€ risk-control/              # ë¦¬ìŠ¤í¬ ì œì–´
    â””â”€â”€ performance-tracking/      # ì„±ê³¼ ì¶”ì 
```

## ğŸ”§ **ì˜ˆì¸¡ ëª¨ë¸ ì‹œìŠ¤í…œ**

### ğŸ“¦ **LSTM ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡**

```python
# ai-ml-system/prediction-models/lstm/price_predictor.py
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class LSTMPredictor:
    """LSTM ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, sequence_length: int = 60, prediction_horizon: int = 1):
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.model = None
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.feature_columns = [
            'open', 'high', 'low', 'close', 'volume',
            'rsi', 'macd', 'bollinger_upper', 'bollinger_lower',
            'sma_20', 'sma_50', 'ema_12', 'ema_26'
        ]
        
        logger.info(f"Initialized LSTM predictor with sequence length: {sequence_length}")
    
    def build_model(self, input_shape: Tuple[int, int]) -> Sequential:
        """LSTM ëª¨ë¸ êµ¬ì¶•"""
        model = Sequential([
            # ì²« ë²ˆì§¸ LSTM ë ˆì´ì–´
            LSTM(units=50, return_sequences=True, input_shape=input_shape),
            Dropout(0.2),
            
            # ë‘ ë²ˆì§¸ LSTM ë ˆì´ì–´
            LSTM(units=50, return_sequences=True),
            Dropout(0.2),
            
            # ì„¸ ë²ˆì§¸ LSTM ë ˆì´ì–´
            LSTM(units=50, return_sequences=False),
            Dropout(0.2),
            
            # ì¶œë ¥ ë ˆì´ì–´
            Dense(units=25),
            Dense(units=self.prediction_horizon)
        ])
        
        # ëª¨ë¸ ì»´íŒŒì¼
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='mean_squared_error',
            metrics=['mae']
        )
        
        logger.info("LSTM model built successfully")
        return model
    
    def prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """ë°ì´í„° ì¤€ë¹„"""
        try:
            # íŠ¹ì„± ì„ íƒ
            features = data[self.feature_columns].values
            
            # ì •ê·œí™”
            scaled_features = self.scaler.fit_transform(features)
            
            # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
            X, y = [], []
            
            for i in range(self.sequence_length, len(scaled_features) - self.prediction_horizon + 1):
                X.append(scaled_features[i-self.sequence_length:i])
                y.append(scaled_features[i:i+self.prediction_horizon, 3])  # close price
            
            X = np.array(X)
            y = np.array(y)
            
            logger.info(f"Prepared data: X shape {X.shape}, y shape {y.shape}")
            return X, y
            
        except Exception as e:
            logger.error(f"Data preparation failed: {e}")
            raise
    
    def train(self, data: pd.DataFrame, epochs: int = 100, batch_size: int = 32,
              validation_split: float = 0.2) -> Dict[str, List[float]]:
        """ëª¨ë¸ í•™ìŠµ"""
        try:
            # ë°ì´í„° ì¤€ë¹„
            X, y = self.prepare_data(data)
            
            # ëª¨ë¸ êµ¬ì¶•
            self.model = self.build_model((X.shape[1], X.shape[2]))
            
            # ì¡°ê¸° ì¢…ë£Œ ì½œë°±
            early_stopping = tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=10,
                restore_best_weights=True
            )
            
            # í•™ìŠµ
            history = self.model.fit(
                X, y,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=validation_split,
                callbacks=[early_stopping],
                verbose=1
            )
            
            logger.info("LSTM model training completed")
            return history.history
            
        except Exception as e:
            logger.error(f"Model training failed: {e}")
            raise
    
    def predict(self, data: pd.DataFrame) -> np.ndarray:
        """ê°€ê²© ì˜ˆì¸¡"""
        try:
            if self.model is None:
                raise ValueError("Model not trained. Call train() first.")
            
            # ë°ì´í„° ì¤€ë¹„
            features = data[self.feature_columns].values
            scaled_features = self.scaler.transform(features)
            
            # ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œí€€ìŠ¤ ìƒì„±
            last_sequence = scaled_features[-self.sequence_length:]
            X_pred = last_sequence.reshape(1, self.sequence_length, len(self.feature_columns))
            
            # ì˜ˆì¸¡
            scaled_prediction = self.model.predict(X_pred)
            
            # ì—­ì •ê·œí™”
            prediction = self.scaler.inverse_transform(
                np.zeros((1, len(self.feature_columns)))
            )
            prediction[0, 3] = scaled_prediction[0, 0]  # close price
            
            logger.info(f"Prediction completed: {prediction[0, 3]}")
            return prediction[0, 3]
            
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            raise
    
    def evaluate(self, test_data: pd.DataFrame) -> Dict[str, float]:
        """ëª¨ë¸ í‰ê°€"""
        try:
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            X_test, y_test = self.prepare_data(test_data)
            
            # ì˜ˆì¸¡
            predictions = self.model.predict(X_test)
            
            # ì—­ì •ê·œí™”
            y_test_actual = self.scaler.inverse_transform(
                np.zeros((len(y_test), len(self.feature_columns)))
            )
            y_test_actual[:, 3] = y_test.flatten()
            
            predictions_actual = self.scaler.inverse_transform(
                np.zeros((len(predictions), len(self.feature_columns)))
            )
            predictions_actual[:, 3] = predictions.flatten()
            
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            mse = np.mean((y_test_actual[:, 3] - predictions_actual[:, 3]) ** 2)
            mae = np.mean(np.abs(y_test_actual[:, 3] - predictions_actual[:, 3]))
            rmse = np.sqrt(mse)
            
            # ë°©í–¥ ì •í™•ë„
            direction_accuracy = np.mean(
                np.sign(np.diff(y_test_actual[:, 3])) == 
                np.sign(np.diff(predictions_actual[:, 3]))
            )
            
            metrics = {
                'mse': mse,
                'mae': mae,
                'rmse': rmse,
                'direction_accuracy': direction_accuracy
            }
            
            logger.info(f"Model evaluation completed: {metrics}")
            return metrics
            
        except Exception as e:
            logger.error(f"Model evaluation failed: {e}")
            raise
    
    def save_model(self, filepath: str):
        """ëª¨ë¸ ì €ì¥"""
        try:
            self.model.save(filepath)
            logger.info(f"Model saved to: {filepath}")
        except Exception as e:
            logger.error(f"Model save failed: {e}")
            raise
    
    def load_model(self, filepath: str):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            self.model = tf.keras.models.load_model(filepath)
            logger.info(f"Model loaded from: {filepath}")
        except Exception as e:
            logger.error(f"Model load failed: {e}")
            raise
```

### ğŸ“¦ **Transformer ê¸°ë°˜ ì˜ˆì¸¡**

```python
# ai-ml-system/prediction-models/transformer/transformer_predictor.py
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras import layers
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class MultiHeadAttention(layers.Layer):
    """ë©€í‹°í—¤ë“œ ì–´í…ì…˜ ë ˆì´ì–´"""
    
    def __init__(self, d_model: int, num_heads: int):
        super(MultiHeadAttention, self).__init__()
        self.num_heads = num_heads
        self.d_model = d_model
        
        assert d_model % self.num_heads == 0
        
        self.depth = d_model // self.num_heads
        
        self.wq = layers.Dense(d_model)
        self.wk = layers.Dense(d_model)
        self.wv = layers.Dense(d_model)
        
        self.dense = layers.Dense(d_model)
    
    def split_heads(self, x, batch_size):
        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))
        return tf.transpose(x, perm=[0, 2, 1, 3])
    
    def call(self, v, k, q, mask):
        batch_size = tf.shape(q)[0]
        
        q = self.wq(q)
        k = self.wk(k)
        v = self.wv(v)
        
        q = self.split_heads(q, batch_size)
        k = self.split_heads(k, batch_size)
        v = self.split_heads(v, batch_size)
        
        scaled_attention = scaled_dot_product_attention(q, k, v, mask)
        
        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])
        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))
        
        output = self.dense(concat_attention)
        
        return output

def scaled_dot_product_attention(q, k, v, mask):
    """ìŠ¤ì¼€ì¼ë“œ ë‹· í”„ë¡œë•íŠ¸ ì–´í…ì…˜"""
    matmul_qk = tf.matmul(q, k, transpose_b=True)
    
    dk = tf.cast(tf.shape(k)[-1], tf.float32)
    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)
    
    if mask is not None:
        scaled_attention_logits += (mask * -1e9)
    
    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)
    output = tf.matmul(attention_weights, v)
    
    return output

class TransformerPredictor:
    """Transformer ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸"""
    
    def __init__(self, d_model: int = 128, num_heads: int = 8, num_layers: int = 4,
                 sequence_length: int = 60, prediction_horizon: int = 1):
        self.d_model = d_model
        self.num_heads = num_heads
        self.num_layers = num_layers
        self.sequence_length = sequence_length
        self.prediction_horizon = prediction_horizon
        self.model = None
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        self.feature_columns = [
            'open', 'high', 'low', 'close', 'volume',
            'rsi', 'macd', 'bollinger_upper', 'bollinger_lower',
            'sma_20', 'sma_50', 'ema_12', 'ema_26'
        ]
        
        logger.info(f"Initialized Transformer predictor: d_model={d_model}, heads={num_heads}")
    
    def positional_encoding(self, position, d_model):
        """í¬ì§€ì…”ë„ ì¸ì½”ë”©"""
        angle_rads = self.get_angles(np.arange(position)[:, np.newaxis],
                                   np.arange(d_model)[np.newaxis, :],
                                   d_model)
        
        angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])
        angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])
        
        pos_encoding = angle_rads[np.newaxis, ...]
        
        return tf.cast(pos_encoding, dtype=tf.float32)
    
    def get_angles(self, pos, i, d_model):
        angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))
        return pos * angle_rates
    
    def build_model(self, input_shape: Tuple[int, int]) -> tf.keras.Model:
        """Transformer ëª¨ë¸ êµ¬ì¶•"""
        inputs = layers.Input(shape=input_shape)
        
        # ì„ë² ë”© ë ˆì´ì–´
        embedding = layers.Dense(self.d_model)(inputs)
        
        # í¬ì§€ì…”ë„ ì¸ì½”ë”©
        pos_encoding = self.positional_encoding(input_shape[0], self.d_model)
        embedding += pos_encoding
        
        # Transformer ë¸”ë¡
        x = embedding
        for _ in range(self.num_layers):
            # ë©€í‹°í—¤ë“œ ì–´í…ì…˜
            attention_output = MultiHeadAttention(self.d_model, self.num_heads)(
                x, x, x, mask=None
            )
            x = layers.LayerNormalization(epsilon=1e-6)(x + attention_output)
            
            # í”¼ë“œí¬ì›Œë“œ ë„¤íŠ¸ì›Œí¬
            ffn_output = layers.Dense(self.d_model * 4, activation='relu')(x)
            ffn_output = layers.Dense(self.d_model)(ffn_output)
            x = layers.LayerNormalization(epsilon=1e-6)(x + ffn_output)
        
        # ì¶œë ¥ ë ˆì´ì–´
        x = layers.GlobalAveragePooling1D()(x)
        x = layers.Dropout(0.1)(x)
        x = layers.Dense(64, activation='relu')(x)
        x = layers.Dropout(0.1)(x)
        outputs = layers.Dense(self.prediction_horizon)(x)
        
        model = tf.keras.Model(inputs=inputs, outputs=outputs)
        
        # ëª¨ë¸ ì»´íŒŒì¼
        model.compile(
            optimizer=Adam(learning_rate=0.0001),
            loss='mean_squared_error',
            metrics=['mae']
        )
        
        logger.info("Transformer model built successfully")
        return model
    
    def prepare_data(self, data: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray]:
        """ë°ì´í„° ì¤€ë¹„"""
        try:
            # íŠ¹ì„± ì„ íƒ
            features = data[self.feature_columns].values
            
            # ì •ê·œí™”
            scaled_features = self.scaler.fit_transform(features)
            
            # ì‹œí€€ìŠ¤ ë°ì´í„° ìƒì„±
            X, y = [], []
            
            for i in range(self.sequence_length, len(scaled_features) - self.prediction_horizon + 1):
                X.append(scaled_features[i-self.sequence_length:i])
                y.append(scaled_features[i:i+self.prediction_horizon, 3])  # close price
            
            X = np.array(X)
            y = np.array(y)
            
            logger.info(f"Prepared data: X shape {X.shape}, y shape {y.shape}")
            return X, y
            
        except Exception as e:
            logger.error(f"Data preparation failed: {e}")
            raise
    
    def train(self, data: pd.DataFrame, epochs: int = 100, batch_size: int = 32,
              validation_split: float = 0.2) -> Dict[str, List[float]]:
        """ëª¨ë¸ í•™ìŠµ"""
        try:
            # ë°ì´í„° ì¤€ë¹„
            X, y = self.prepare_data(data)
            
            # ëª¨ë¸ êµ¬ì¶•
            self.model = self.build_model((X.shape[1], X.shape[2]))
            
            # ì¡°ê¸° ì¢…ë£Œ ì½œë°±
            early_stopping = tf.keras.callbacks.EarlyStopping(
                monitor='val_loss',
                patience=15,
                restore_best_weights=True
            )
            
            # í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ë§
            lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=5,
                min_lr=1e-7
            )
            
            # í•™ìŠµ
            history = self.model.fit(
                X, y,
                epochs=epochs,
                batch_size=batch_size,
                validation_split=validation_split,
                callbacks=[early_stopping, lr_scheduler],
                verbose=1
            )
            
            logger.info("Transformer model training completed")
            return history.history
            
        except Exception as e:
            logger.error(f"Model training failed: {e}")
            raise
    
    def predict(self, data: pd.DataFrame) -> np.ndarray:
        """ê°€ê²© ì˜ˆì¸¡"""
        try:
            if self.model is None:
                raise ValueError("Model not trained. Call train() first.")
            
            # ë°ì´í„° ì¤€ë¹„
            features = data[self.feature_columns].values
            scaled_features = self.scaler.transform(features)
            
            # ì˜ˆì¸¡ì„ ìœ„í•œ ì‹œí€€ìŠ¤ ìƒì„±
            last_sequence = scaled_features[-self.sequence_length:]
            X_pred = last_sequence.reshape(1, self.sequence_length, len(self.feature_columns))
            
            # ì˜ˆì¸¡
            scaled_prediction = self.model.predict(X_pred)
            
            # ì—­ì •ê·œí™”
            prediction = self.scaler.inverse_transform(
                np.zeros((1, len(self.feature_columns)))
            )
            prediction[0, 3] = scaled_prediction[0, 0]  # close price
            
            logger.info(f"Transformer prediction completed: {prediction[0, 3]}")
            return prediction[0, 3]
            
        except Exception as e:
            logger.error(f"Prediction failed: {e}")
            raise
```

## ğŸ”§ **ê°•í™”í•™ìŠµ ê±°ë˜ ì—ì´ì „íŠ¸**

### ğŸ“¦ **Q-Learning ê±°ë˜ ì—ì´ì „íŠ¸**

```python
# ai-ml-system/reinforcement-learning/q-learning/trading_agent.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import logging
import random

logger = logging.getLogger(__name__)

@dataclass
class TradingState:
    """ê±°ë˜ ìƒíƒœ"""
    position: float  # í˜„ì¬ í¬ì§€ì…˜ (-1: ìˆ, 0: ì¤‘ë¦½, 1: ë¡±)
    cash: float     # í˜„ê¸ˆ
    shares: float   # ë³´ìœ  ì£¼ì‹ ìˆ˜
    price: float    # í˜„ì¬ ê°€ê²©
    timestamp: int  # ì‹œê°„ ìŠ¤íƒ¬í”„

@dataclass
class TradingAction:
    """ê±°ë˜ ì•¡ì…˜"""
    action: int     # 0: í™€ë“œ, 1: ë§¤ìˆ˜, 2: ë§¤ë„
    amount: float   # ê±°ë˜ëŸ‰

class QLearningTradingAgent:
    """Q-Learning ê¸°ë°˜ ê±°ë˜ ì—ì´ì „íŠ¸"""
    
    def __init__(self, state_size: int, action_size: int, learning_rate: float = 0.1,
                 discount_factor: float = 0.95, epsilon: float = 0.1):
        self.state_size = state_size
        self.action_size = action_size
        self.learning_rate = learning_rate
        self.discount_factor = discount_factor
        self.epsilon = epsilon
        
        # Q-í…Œì´ë¸” ì´ˆê¸°í™”
        self.q_table = {}
        
        # ê±°ë˜ íŒŒë¼ë¯¸í„°
        self.initial_cash = 10000
        self.commission = 0.001  # 0.1% ìˆ˜ìˆ˜ë£Œ
        
        logger.info(f"Initialized Q-Learning agent: states={state_size}, actions={action_size}")
    
    def get_state_key(self, state: TradingState) -> str:
        """ìƒíƒœë¥¼ í‚¤ë¡œ ë³€í™˜"""
        # ìƒíƒœë¥¼ ì´ì‚°í™”
        position_bin = int(state.position * 2)  # -2, -1, 0, 1, 2
        cash_bin = int(state.cash / 1000)       # 1000 ë‹¨ìœ„ë¡œ ì´ì‚°í™”
        price_bin = int(state.price / 10)       # 10 ë‹¨ìœ„ë¡œ ì´ì‚°í™”
        
        return f"{position_bin}_{cash_bin}_{price_bin}"
    
    def get_action(self, state: TradingState) -> TradingAction:
        """ì•¡ì…˜ ì„ íƒ (Îµ-greedy ì •ì±…)"""
        state_key = self.get_state_key(state)
        
        # Q-í…Œì´ë¸”ì— ìƒíƒœê°€ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
        if state_key not in self.q_table:
            self.q_table[state_key] = np.zeros(self.action_size)
        
        # Îµ-greedy ì •ì±…
        if random.random() < self.epsilon:
            # íƒí—˜: ëœë¤ ì•¡ì…˜
            action = random.randint(0, self.action_size - 1)
        else:
            # í™œìš©: ìµœì  ì•¡ì…˜
            action = np.argmax(self.q_table[state_key])
        
        # ì•¡ì…˜ì„ ê±°ë˜ëŸ‰ìœ¼ë¡œ ë³€í™˜
        amount = self._action_to_amount(action, state)
        
        return TradingAction(action=action, amount=amount)
    
    def _action_to_amount(self, action: int, state: TradingState) -> float:
        """ì•¡ì…˜ì„ ê±°ë˜ëŸ‰ìœ¼ë¡œ ë³€í™˜"""
        if action == 0:  # í™€ë“œ
            return 0.0
        elif action == 1:  # ë§¤ìˆ˜
            # í˜„ê¸ˆì˜ 20% ë§¤ìˆ˜
            return min(state.cash * 0.2 / state.price, state.cash / state.price)
        elif action == 2:  # ë§¤ë„
            # ë³´ìœ  ì£¼ì‹ì˜ 20% ë§¤ë„
            return state.shares * 0.2
        else:
            return 0.0
    
    def execute_trade(self, state: TradingState, action: TradingAction) -> Tuple[TradingState, float]:
        """ê±°ë˜ ì‹¤í–‰"""
        new_state = TradingState(
            position=state.position,
            cash=state.cash,
            shares=state.shares,
            price=state.price,
            timestamp=state.timestamp + 1
        )
        
        reward = 0.0
        
        if action.action == 1:  # ë§¤ìˆ˜
            if action.amount > 0 and new_state.cash >= action.amount * new_state.price:
                cost = action.amount * new_state.price * (1 + self.commission)
                new_state.cash -= cost
                new_state.shares += action.amount
                new_state.position = 1 if new_state.shares > 0 else 0
                
        elif action.action == 2:  # ë§¤ë„
            if action.amount > 0 and new_state.shares >= action.amount:
                revenue = action.amount * new_state.price * (1 - self.commission)
                new_state.cash += revenue
                new_state.shares -= action.amount
                new_state.position = -1 if new_state.shares < 0 else 0
        
        # ë³´ìƒ ê³„ì‚° (í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ë³€í™”)
        old_value = state.cash + state.shares * state.price
        new_value = new_state.cash + new_state.shares * new_state.price
        reward = (new_value - old_value) / old_value
        
        return new_state, reward
    
    def update_q_value(self, state: TradingState, action: TradingAction, 
                      reward: float, next_state: TradingState):
        """Q-ê°’ ì—…ë°ì´íŠ¸"""
        state_key = self.get_state_key(state)
        next_state_key = self.get_state_key(next_state)
        
        # Q-í…Œì´ë¸” ì´ˆê¸°í™”
        if state_key not in self.q_table:
            self.q_table[state_key] = np.zeros(self.action_size)
        if next_state_key not in self.q_table:
            self.q_table[next_state_key] = np.zeros(self.action_size)
        
        # Q-ëŸ¬ë‹ ì—…ë°ì´íŠ¸ ê³µì‹
        current_q = self.q_table[state_key][action.action]
        max_next_q = np.max(self.q_table[next_state_key])
        
        new_q = current_q + self.learning_rate * (
            reward + self.discount_factor * max_next_q - current_q
        )
        
        self.q_table[state_key][action.action] = new_q
    
    def train(self, price_data: pd.DataFrame, episodes: int = 1000) -> List[float]:
        """ì—ì´ì „íŠ¸ í•™ìŠµ"""
        episode_rewards = []
        
        for episode in range(episodes):
            # ì´ˆê¸° ìƒíƒœ
            state = TradingState(
                position=0,
                cash=self.initial_cash,
                shares=0,
                price=price_data.iloc[0]['close'],
                timestamp=0
            )
            
            total_reward = 0.0
            
            for i in range(len(price_data) - 1):
                # í˜„ì¬ ê°€ê²© ì—…ë°ì´íŠ¸
                state.price = price_data.iloc[i]['close']
                
                # ì•¡ì…˜ ì„ íƒ
                action = self.get_action(state)
                
                # ê±°ë˜ ì‹¤í–‰
                next_state, reward = self.execute_trade(state, action)
                
                # ë‹¤ìŒ ê°€ê²©ìœ¼ë¡œ ì—…ë°ì´íŠ¸
                next_state.price = price_data.iloc[i + 1]['close']
                
                # Q-ê°’ ì—…ë°ì´íŠ¸
                self.update_q_value(state, action, reward, next_state)
                
                state = next_state
                total_reward += reward
            
            episode_rewards.append(total_reward)
            
            if episode % 100 == 0:
                avg_reward = np.mean(episode_rewards[-100:])
                logger.info(f"Episode {episode}, Average Reward: {avg_reward:.4f}")
        
        logger.info("Q-Learning training completed")
        return episode_rewards
    
    def get_portfolio_value(self, state: TradingState) -> float:
        """í¬íŠ¸í´ë¦¬ì˜¤ ê°€ì¹˜ ê³„ì‚°"""
        return state.cash + state.shares * state.price
    
    def save_q_table(self, filepath: str):
        """Q-í…Œì´ë¸” ì €ì¥"""
        try:
            np.save(filepath, self.q_table)
            logger.info(f"Q-table saved to: {filepath}")
        except Exception as e:
            logger.error(f"Q-table save failed: {e}")
            raise
    
    def load_q_table(self, filepath: str):
        """Q-í…Œì´ë¸” ë¡œë“œ"""
        try:
            self.q_table = np.load(filepath, allow_pickle=True).item()
            logger.info(f"Q-table loaded from: {filepath}")
        except Exception as e:
            logger.error(f"Q-table load failed: {e}")
            raise
```

## ğŸ”§ **ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ**

### ğŸ“¦ **ë‰´ìŠ¤ ê°ì • ë¶„ì„**

```python
# ai-ml-system/sentiment-analysis/news-analysis/news_sentiment_analyzer.py
import pandas as pd
import numpy as np
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from typing import Dict, List, Tuple, Optional
import requests
import json
from datetime import datetime, timedelta
import logging

logger = logging.getLogger(__name__)

class NewsSentimentAnalyzer:
    """ë‰´ìŠ¤ ê°ì • ë¶„ì„ê¸°"""
    
    def __init__(self, model_name: str = "ProsusAI/finbert"):
        self.model_name = model_name
        self.tokenizer = None
        self.model = None
        self.sentiment_pipeline = None
        
        # ê°ì • ë ˆì´ë¸”
        self.sentiment_labels = ['negative', 'neutral', 'positive']
        
        logger.info(f"Initialized news sentiment analyzer with model: {model_name}")
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)
            
            self.sentiment_pipeline = pipeline(
                "sentiment-analysis",
                model=self.model,
                tokenizer=self.tokenizer
            )
            
            logger.info("Sentiment analysis model loaded successfully")
            
        except Exception as e:
            logger.error(f"Model loading failed: {e}")
            raise
    
    def analyze_text(self, text: str) -> Dict[str, float]:
        """í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„"""
        try:
            if self.sentiment_pipeline is None:
                self.load_model()
            
            # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            cleaned_text = self._preprocess_text(text)
            
            # ê°ì • ë¶„ì„
            result = self.sentiment_pipeline(cleaned_text)
            
            # ê²°ê³¼ ì •ê·œí™”
            sentiment_scores = {
                'negative': 0.0,
                'neutral': 0.0,
                'positive': 0.0
            }
            
            for item in result:
                label = item['label'].lower()
                score = item['score']
                sentiment_scores[label] = score
            
            # ì¢…í•© ê°ì • ì ìˆ˜ (-1 ~ 1)
            composite_score = (
                sentiment_scores['positive'] - sentiment_scores['negative']
            )
            
            sentiment_scores['composite'] = composite_score
            
            logger.debug(f"Sentiment analysis completed: {composite_score:.3f}")
            return sentiment_scores
            
        except Exception as e:
            logger.error(f"Sentiment analysis failed: {e}")
            return {
                'negative': 0.33,
                'neutral': 0.34,
                'positive': 0.33,
                'composite': 0.0
            }
    
    def _preprocess_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        # íŠ¹ìˆ˜ ë¬¸ì ì œê±°
        import re
        text = re.sub(r'[^\w\s]', '', text)
        
        # ì—¬ëŸ¬ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        text = re.sub(r'\s+', ' ', text)
        
        # ëŒ€ì†Œë¬¸ì ì •ê·œí™”
        text = text.lower().strip()
        
        return text
    
    def fetch_crypto_news(self, symbol: str, hours: int = 24) -> List[Dict[str, any]]:
        """ì•”í˜¸í™”í ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            # NewsAPI ì‚¬ìš© (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” API í‚¤ í•„ìš”)
            api_key = "YOUR_NEWS_API_KEY"
            url = f"https://newsapi.org/v2/everything"
            
            # ê²€ìƒ‰ ì¿¼ë¦¬
            query = f"{symbol} cryptocurrency"
            
            # ì‹œê°„ ë²”ìœ„
            from_date = (datetime.now() - timedelta(hours=hours)).strftime('%Y-%m-%d')
            
            params = {
                'q': query,
                'from': from_date,
                'sortBy': 'publishedAt',
                'apiKey': api_key,
                'language': 'en'
            }
            
            response = requests.get(url, params=params)
            
            if response.status_code == 200:
                data = response.json()
                articles = data.get('articles', [])
                
                # ë‰´ìŠ¤ ë°ì´í„° ì •ë¦¬
                news_data = []
                for article in articles:
                    news_item = {
                        'title': article.get('title', ''),
                        'description': article.get('description', ''),
                        'content': article.get('content', ''),
                        'published_at': article.get('publishedAt', ''),
                        'source': article.get('source', {}).get('name', ''),
                        'url': article.get('url', '')
                    }
                    news_data.append(news_item)
                
                logger.info(f"Fetched {len(news_data)} news articles for {symbol}")
                return news_data
                
            else:
                logger.error(f"News API request failed: {response.status_code}")
                return []
                
        except Exception as e:
            logger.error(f"News fetching failed: {e}")
            return []
    
    def analyze_news_sentiment(self, symbol: str, hours: int = 24) -> Dict[str, any]:
        """ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹¤í–‰"""
        try:
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            news_articles = self.fetch_crypto_news(symbol, hours)
            
            if not news_articles:
                return {
                    'symbol': symbol,
                    'sentiment_score': 0.0,
                    'confidence': 0.0,
                    'article_count': 0,
                    'timestamp': datetime.now().isoformat()
                }
            
            # ê° ê¸°ì‚¬ ê°ì • ë¶„ì„
            sentiment_scores = []
            for article in news_articles:
                # ì œëª©ê³¼ ì„¤ëª… ê²°í•©
                text = f"{article['title']} {article['description']}"
                
                sentiment = self.analyze_text(text)
                sentiment_scores.append(sentiment['composite'])
            
            # ì¢…í•© ê°ì • ì ìˆ˜ ê³„ì‚°
            avg_sentiment = np.mean(sentiment_scores)
            sentiment_std = np.std(sentiment_scores)
            confidence = 1.0 - sentiment_std  # í‘œì¤€í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë†’ìŒ
            
            result = {
                'symbol': symbol,
                'sentiment_score': avg_sentiment,
                'confidence': max(0.0, min(1.0, confidence)),
                'article_count': len(news_articles),
                'sentiment_distribution': {
                    'negative': len([s for s in sentiment_scores if s < -0.1]),
                    'neutral': len([s for s in sentiment_scores if -0.1 <= s <= 0.1]),
                    'positive': len([s for s in sentiment_scores if s > 0.1])
                },
                'timestamp': datetime.now().isoformat()
            }
            
            logger.info(f"News sentiment analysis completed for {symbol}: {avg_sentiment:.3f}")
            return result
            
        except Exception as e:
            logger.error(f"News sentiment analysis failed: {e}")
            return {
                'symbol': symbol,
                'sentiment_score': 0.0,
                'confidence': 0.0,
                'article_count': 0,
                'timestamp': datetime.now().isoformat()
            }
```

## ğŸ¯ **ë‹¤ìŒ ë‹¨ê³„**

### ğŸ“‹ **ì™„ë£Œëœ ì‘ì—…**
- âœ… LSTM ê¸°ë°˜ ê°€ê²© ì˜ˆì¸¡ ëª¨ë¸
- âœ… Transformer ê¸°ë°˜ ì˜ˆì¸¡ ëª¨ë¸
- âœ… Q-Learning ê±°ë˜ ì—ì´ì „íŠ¸
- âœ… ë‰´ìŠ¤ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ

### ğŸ”„ **ì§„í–‰ ì¤‘ì¸ ì‘ì—…**
- ğŸ”„ DDPG ê°•í™”í•™ìŠµ ì—ì´ì „íŠ¸
- ğŸ”„ ì†Œì…œ ë¯¸ë””ì–´ ê°ì • ë¶„ì„
- ğŸ”„ í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”

### â³ **ë‹¤ìŒ ë‹¨ê³„**
1. **Phase 3.1 ì˜ˆì¸¡ ëª¨ë¸** ë¬¸ì„œ ìƒì„±
2. **Phase 3.2 ê°•í™”í•™ìŠµ** ë¬¸ì„œ ìƒì„±
3. **Phase 3.3 ê°ì • ë¶„ì„** ë¬¸ì„œ ìƒì„±

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024-01-31
**ë‹¤ìŒ ì—…ë°ì´íŠ¸**: 2024-02-01 (Phase 3.1 ì˜ˆì¸¡ ëª¨ë¸)
**AI/ML ëª©í‘œ**: > 65% ì˜ˆì¸¡ ì •í™•ë„, > 20% ì—°ê°„ ìˆ˜ìµë¥ , > 2.0 ìƒ¤í”„ ë¹„ìœ¨
**ëª¨ë¸ ì„±ëŠ¥**: < 2ì‹œê°„ í•™ìŠµ ì‹œê°„, ì‹¤ì‹œê°„ ì˜ˆì¸¡ < 1ì´ˆ 